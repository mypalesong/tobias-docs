"use strict";(globalThis.webpackChunkgithub_docs=globalThis.webpackChunkgithub_docs||[]).push([[3433],{6017:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"crawling/examples/scenario-01-news-scraper","title":"\uc2dc\ub098\ub9ac\uc624 1: \ub274\uc2a4 \uc2a4\ud06c\ub798\ud37c","description":"Hacker News\uc758 \ucd5c\uc2e0 \uae30\uc0ac\ub97c \uc790\ub3d9\uc73c\ub85c \uc218\uc9d1\ud558\ub294 \uc2a4\ud06c\ub798\ud37c\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!","source":"@site/docs/crawling/examples/scenario-01-news-scraper.md","sourceDirName":"crawling/examples","slug":"/crawling/examples/scenario-01-news-scraper","permalink":"/tobias-docs/comp-0/docs/crawling/examples/scenario-01-news-scraper","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/crawling/examples/scenario-01-news-scraper.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"crawlingSidebar","previous":{"title":"\uc2e4\uc804 \uc608\uc81c \uc18c\uac1c","permalink":"/tobias-docs/comp-0/docs/crawling/examples/intro"},"next":{"title":"\uc2dc\ub098\ub9ac\uc624 2: \uc1fc\ud551\ubab0 \uac00\uaca9 \ubaa8\ub2c8\ud130\ub9c1","permalink":"/tobias-docs/comp-0/docs/crawling/examples/scenario-02-ecommerce-scraper"}}');var t=r(4848),i=r(8453);const o={sidebar_position:2},l="\uc2dc\ub098\ub9ac\uc624 1: \ub274\uc2a4 \uc2a4\ud06c\ub798\ud37c",a={},c=[{value:"\ud83c\udfaf \ubaa9\ud45c",id:"-\ubaa9\ud45c",level:2},{value:"\ud83d\udcdd \uc644\uc804\ud55c \uad6c\ud604",id:"-\uc644\uc804\ud55c-\uad6c\ud604",level:2},{value:"\ud504\ub85c\uc81d\ud2b8 \uad6c\uc870",id:"\ud504\ub85c\uc81d\ud2b8-\uad6c\uc870",level:3},{value:"requirements.txt",id:"requirementstxt",level:3},{value:"config.py",id:"configpy",level:3},{value:"scraper/hn_scraper.py",id:"scraperhn_scraperpy",level:3},{value:"scraper/parser.py",id:"scraperparserpy",level:3},{value:"main.py",id:"mainpy",level:3},{value:"\uc2a4\ucf00\uc904\ub9c1 (\uc120\ud0dd\uc0ac\ud56d)",id:"\uc2a4\ucf00\uc904\ub9c1-\uc120\ud0dd\uc0ac\ud56d",level:3},{value:"\ud83d\ude80 \uc2e4\ud589 \ubc29\ubc95",id:"-\uc2e4\ud589-\ubc29\ubc95",level:2},{value:"\ud83d\udcca \ucd9c\ub825 \uc608\uc2dc",id:"-\ucd9c\ub825-\uc608\uc2dc",level:2},{value:"CSV \ud30c\uc77c",id:"csv-\ud30c\uc77c",level:3},{value:"JSON \ud30c\uc77c",id:"json-\ud30c\uc77c",level:3},{value:"\ud83d\udd0d \ud655\uc7a5 \uc544\uc774\ub514\uc5b4",id:"-\ud655\uc7a5-\uc544\uc774\ub514\uc5b4",level:2},{value:"\ud83d\udcda \ub2e4\uc74c \ub2e8\uacc4",id:"-\ub2e4\uc74c-\ub2e8\uacc4",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"\uc2dc\ub098\ub9ac\uc624-1-\ub274\uc2a4-\uc2a4\ud06c\ub798\ud37c",children:"\uc2dc\ub098\ub9ac\uc624 1: \ub274\uc2a4 \uc2a4\ud06c\ub798\ud37c"})}),"\n",(0,t.jsx)(n.p,{children:"Hacker News\uc758 \ucd5c\uc2e0 \uae30\uc0ac\ub97c \uc790\ub3d9\uc73c\ub85c \uc218\uc9d1\ud558\ub294 \uc2a4\ud06c\ub798\ud37c\ub97c \ub9cc\ub4e4\uc5b4\ubd05\uc2dc\ub2e4!"}),"\n",(0,t.jsx)(n.h2,{id:"-\ubaa9\ud45c",children:"\ud83c\udfaf \ubaa9\ud45c"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Hacker News \uc0c1\uc704 30\uac1c \uae30\uc0ac \uc218\uc9d1"}),"\n",(0,t.jsx)(n.li,{children:"\uc81c\ubaa9, URL, \uc810\uc218, \ub313\uae00 \uc218, \uc791\uc131\uc790, \uc2dc\uac04 \ucd94\ucd9c"}),"\n",(0,t.jsx)(n.li,{children:"CSV \ubc0f JSON \ud615\uc2dd\uc73c\ub85c \uc800\uc7a5"}),"\n",(0,t.jsx)(n.li,{children:"\uc2a4\ucf00\uc904\ub9c1\uc73c\ub85c \uc815\uae30\uc801 \uc218\uc9d1"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-\uc644\uc804\ud55c-\uad6c\ud604",children:"\ud83d\udcdd \uc644\uc804\ud55c \uad6c\ud604"}),"\n",(0,t.jsx)(n.h3,{id:"\ud504\ub85c\uc81d\ud2b8-\uad6c\uc870",children:"\ud504\ub85c\uc81d\ud2b8 \uad6c\uc870"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"hackernews_scraper/\n\u251c\u2500\u2500 scraper/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 hn_scraper.py\n\u2502   \u2514\u2500\u2500 parser.py\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 csv/\n\u2502   \u2514\u2500\u2500 json/\n\u251c\u2500\u2500 logs/\n\u251c\u2500\u2500 config.py\n\u251c\u2500\u2500 main.py\n\u2514\u2500\u2500 requirements.txt\n"})}),"\n",(0,t.jsx)(n.h3,{id:"requirementstxt",children:"requirements.txt"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-txt",children:"playwright==1.40.0\npandas==2.1.0\npython-dotenv==1.0.0\nschedule==1.2.0\ntenacity==8.2.3\n"})}),"\n",(0,t.jsx)(n.h3,{id:"configpy",children:"config.py"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import os\nfrom datetime import datetime\n\nclass Config:\n    # \ube0c\ub77c\uc6b0\uc800 \uc124\uc815\n    HEADLESS = True\n    TIMEOUT = 30000\n\n    # \ud0c0\uac9f URL\n    BASE_URL = 'https://news.ycombinator.com'\n\n    # \uc218\uc9d1 \uc124\uc815\n    MAX_ITEMS = 30\n    DELAY_BETWEEN_PAGES = 2  # \ucd08\n\n    # \uc800\uc7a5 \uacbd\ub85c\n    OUTPUT_DIR = 'data'\n    CSV_DIR = os.path.join(OUTPUT_DIR, 'csv')\n    JSON_DIR = os.path.join(OUTPUT_DIR, 'json')\n    LOG_DIR = 'logs'\n\n    # \ud30c\uc77c\uba85\n    TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n    CSV_FILE = os.path.join(CSV_DIR, f'hackernews_{TIMESTAMP}.csv')\n    JSON_FILE = os.path.join(JSON_DIR, f'hackernews_{TIMESTAMP}.json')\n\n    @classmethod\n    def ensure_directories(cls):\n        \"\"\"\ud544\uc694\ud55c \ub514\ub809\ud1a0\ub9ac \uc0dd\uc131\"\"\"\n        os.makedirs(cls.CSV_DIR, exist_ok=True)\n        os.makedirs(cls.JSON_DIR, exist_ok=True)\n        os.makedirs(cls.LOG_DIR, exist_ok=True)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"scraperhn_scraperpy",children:"scraper/hn_scraper.py"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from playwright.sync_api import sync_playwright\nimport logging\nfrom typing import List, Dict\nimport time\n\nlogger = logging.getLogger(__name__)\n\nclass HackerNewsScraper:\n    def __init__(self, config):\n        self.config = config\n\n    def scrape(self) -> List[Dict]:\n        \"\"\"Hacker News \uc2a4\ud06c\ub798\ud551\"\"\"\n        logger.info(\"Hacker News \uc2a4\ud06c\ub798\ud551 \uc2dc\uc791\")\n\n        with sync_playwright() as p:\n            # \ube0c\ub77c\uc6b0\uc800 \uc2e4\ud589\n            browser = p.chromium.launch(headless=self.config.HEADLESS)\n            page = browser.new_page()\n\n            try:\n                # \ud398\uc774\uc9c0 \ubc29\ubb38\n                page.goto(self.config.BASE_URL, timeout=self.config.TIMEOUT)\n                logger.info(f\"\ud398\uc774\uc9c0 \ub85c\ub4dc \uc644\ub8cc: {self.config.BASE_URL}\")\n\n                # \ub370\uc774\ud130 \ucd94\ucd9c\n                stories = self._extract_stories(page)\n\n                logger.info(f\"\u2705 {len(stories)}\uac1c \uae30\uc0ac \uc218\uc9d1 \uc644\ub8cc\")\n                return stories\n\n            except Exception as e:\n                logger.error(f\"\uc2a4\ud06c\ub798\ud551 \uc911 \uc5d0\ub7ec: {e}\")\n                raise\n\n            finally:\n                browser.close()\n\n    def _extract_stories(self, page) -> List[Dict]:\n        \"\"\"\uae30\uc0ac \ub370\uc774\ud130 \ucd94\ucd9c\"\"\"\n        stories = []\n\n        # \uae30\uc0ac \ud589 \ucd94\ucd9c\n        story_rows = page.query_selector_all('.athing')\n\n        for idx, row in enumerate(story_rows[:self.config.MAX_ITEMS], 1):\n            try:\n                story = self._parse_story(row, page, idx)\n                stories.append(story)\n\n                logger.info(f\"[{idx}] {story['title']}\")\n\n            except Exception as e:\n                logger.error(f\"\uae30\uc0ac \ud30c\uc2f1 \uc2e4\ud328 (#{idx}): {e}\")\n                continue\n\n        return stories\n\n    def _parse_story(self, row, page, rank: int) -> Dict:\n        \"\"\"\uac1c\ubcc4 \uae30\uc0ac \ud30c\uc2f1\"\"\"\n        # \uae30\uc0ac ID\n        story_id = row.get_attribute('id')\n\n        # \uc81c\ubaa9 & URL\n        title_elem = row.query_selector('.titleline > a')\n        title = title_elem.inner_text() if title_elem else 'N/A'\n        url = title_elem.get_attribute('href') if title_elem else 'N/A'\n\n        # \uc0ac\uc774\ud2b8 \uc815\ubcf4\n        site_elem = row.query_selector('.sitebit')\n        site = site_elem.inner_text().strip('()') if site_elem else 'N/A'\n\n        # \uba54\ud0c0 \uc815\ubcf4 (\ub2e4\uc74c \ud589)\n        meta_row = page.query_selector(f'#score_{story_id}').evaluate_handle(\n            'el => el.closest(\"tr\")'\n        )\n\n        # \uc810\uc218\n        score_elem = page.query_selector(f'#score_{story_id}')\n        score_text = score_elem.inner_text() if score_elem else '0 points'\n        score = int(score_text.split()[0]) if score_text != '0 points' else 0\n\n        # \uc791\uc131\uc790\n        author_elem = page.query_selector(f'#score_{story_id} ~ .hnuser')\n        author = author_elem.inner_text() if author_elem else 'unknown'\n\n        # \uc2dc\uac04\n        time_elem = page.query_selector(f'#score_{story_id} ~ .age')\n        time_ago = time_elem.get_attribute('title') if time_elem else 'N/A'\n\n        # \ub313\uae00 \uc218\n        comments_elem = page.query_selector(f'#score_{story_id} ~ a:has-text(\"comment\")')\n        comments_text = comments_elem.inner_text() if comments_elem else '0 comments'\n\n        if 'comment' in comments_text:\n            comments = int(comments_text.split()[0])\n        else:\n            comments = 0\n\n        return {\n            'rank': rank,\n            'id': story_id,\n            'title': title,\n            'url': url,\n            'site': site,\n            'score': score,\n            'author': author,\n            'time': time_ago,\n            'comments': comments\n        }\n"})}),"\n",(0,t.jsx)(n.h3,{id:"scraperparserpy",children:"scraper/parser.py"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import pandas as pd\nimport json\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass DataSaver:\n    @staticmethod\n    def save_csv(data: list, filename: str):\n        """CSV\ub85c \uc800\uc7a5"""\n        try:\n            df = pd.DataFrame(data)\n            df.to_csv(filename, index=False, encoding=\'utf-8-sig\')\n            logger.info(f"\u2705 CSV \uc800\uc7a5 \uc644\ub8cc: {filename}")\n        except Exception as e:\n            logger.error(f"CSV \uc800\uc7a5 \uc2e4\ud328: {e}")\n            raise\n\n    @staticmethod\n    def save_json(data: list, filename: str):\n        """JSON\uc73c\ub85c \uc800\uc7a5"""\n        try:\n            with open(filename, \'w\', encoding=\'utf-8\') as f:\n                json.dump(data, f, ensure_ascii=False, indent=2)\n            logger.info(f"\u2705 JSON \uc800\uc7a5 \uc644\ub8cc: {filename}")\n        except Exception as e:\n            logger.error(f"JSON \uc800\uc7a5 \uc2e4\ud328: {e}")\n            raise\n\n    @staticmethod\n    def print_summary(data: list):\n        """\uc218\uc9d1 \uc694\uc57d \ucd9c\ub825"""\n        if not data:\n            logger.warning("\uc218\uc9d1\ub41c \ub370\uc774\ud130\uac00 \uc5c6\uc2b5\ub2c8\ub2e4")\n            return\n\n        df = pd.DataFrame(data)\n\n        print("\\n" + "="*60)\n        print("\ud83d\udcca \uc218\uc9d1 \uc694\uc57d")\n        print("="*60)\n        print(f"\ucd1d \uae30\uc0ac \uc218: {len(df)}")\n        print(f"\ud3c9\uade0 \uc810\uc218: {df[\'score\'].mean():.1f}")\n        print(f"\ud3c9\uade0 \ub313\uae00 \uc218: {df[\'comments\'].mean():.1f}")\n        print(f"\\n\uc0c1\uc704 5\uac1c \uae30\uc0ac:")\n        print("-"*60)\n\n        for idx, row in df.head(5).iterrows():\n            print(f"{row[\'rank\']}. {row[\'title\']}")\n            print(f"   \uc810\uc218: {row[\'score\']} | \ub313\uae00: {row[\'comments\']} | \uc791\uc131\uc790: {row[\'author\']}")\n\n        print("="*60 + "\\n")\n'})}),"\n",(0,t.jsx)(n.h3,{id:"mainpy",children:"main.py"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import logging\nfrom datetime import datetime\nfrom config import Config\nfrom scraper.hn_scraper import HackerNewsScraper\nfrom scraper.parser import DataSaver\n\ndef setup_logger():\n    """\ub85c\uac70 \uc124\uc815"""\n    Config.ensure_directories()\n\n    logging.basicConfig(\n        level=logging.INFO,\n        format=\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\',\n        handlers=[\n            logging.FileHandler(\n                f\'{Config.LOG_DIR}/scraper_{datetime.now().strftime("%Y%m%d")}.log\'\n            ),\n            logging.StreamHandler()\n        ]\n    )\n\ndef main():\n    """\uba54\uc778 \uc2e4\ud589 \ud568\uc218"""\n    setup_logger()\n    logger = logging.getLogger(__name__)\n\n    try:\n        logger.info("=" * 60)\n        logger.info("Hacker News \uc2a4\ud06c\ub798\ud37c \uc2dc\uc791")\n        logger.info("=" * 60)\n\n        # \uc2a4\ud06c\ub798\ud551\n        scraper = HackerNewsScraper(Config)\n        stories = scraper.scrape()\n\n        if not stories:\n            logger.warning("\uc218\uc9d1\ub41c \ub370\uc774\ud130\uac00 \uc5c6\uc2b5\ub2c8\ub2e4")\n            return\n\n        # \uc800\uc7a5\n        saver = DataSaver()\n        saver.save_csv(stories, Config.CSV_FILE)\n        saver.save_json(stories, Config.JSON_FILE)\n\n        # \uc694\uc57d \ucd9c\ub825\n        saver.print_summary(stories)\n\n        logger.info("=" * 60)\n        logger.info("\u2705 \ubaa8\ub4e0 \uc791\uc5c5 \uc644\ub8cc!")\n        logger.info("=" * 60)\n\n    except Exception as e:\n        logger.error(f"\u274c \uc5d0\ub7ec \ubc1c\uc0dd: {e}", exc_info=True)\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,t.jsx)(n.h3,{id:"\uc2a4\ucf00\uc904\ub9c1-\uc120\ud0dd\uc0ac\ud56d",children:"\uc2a4\ucf00\uc904\ub9c1 (\uc120\ud0dd\uc0ac\ud56d)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# scheduler.py\nimport schedule\nimport time\nfrom main import main\nimport logging\n\nlogger = logging.getLogger(__name__)\n\ndef job():\n    """\uc2a4\ucf00\uc904\ub41c \uc791\uc5c5"""\n    logger.info("\ud83d\udd50 \uc2a4\ucf00\uc904\ub41c \uc2a4\ud06c\ub798\ud551 \uc2dc\uc791")\n    main()\n\n# \ub9e4 \uc2dc\uac04\ub9c8\ub2e4 \uc2e4\ud589\nschedule.every().hour.do(job)\n\n# \ub9e4\uc77c \uc624\uc804 9\uc2dc \uc2e4\ud589\nschedule.every().day.at("09:00").do(job)\n\nlogger.info("\uc2a4\ucf00\uc904\ub7ec \uc2dc\uc791 - Ctrl+C\ub85c \uc911\uc9c0")\n\nwhile True:\n    schedule.run_pending()\n    time.sleep(60)\n'})}),"\n",(0,t.jsx)(n.h2,{id:"-\uc2e4\ud589-\ubc29\ubc95",children:"\ud83d\ude80 \uc2e4\ud589 \ubc29\ubc95"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# \uc758\uc874\uc131 \uc124\uce58\npip install -r requirements.txt\n\n# \ube0c\ub77c\uc6b0\uc800 \uc124\uce58\nplaywright install chromium\n\n# \ub2e8\uc77c \uc2e4\ud589\npython main.py\n\n# \uc2a4\ucf00\uc904\ub9c1 \uc2e4\ud589\npython scheduler.py\n"})}),"\n",(0,t.jsx)(n.h2,{id:"-\ucd9c\ub825-\uc608\uc2dc",children:"\ud83d\udcca \ucd9c\ub825 \uc608\uc2dc"}),"\n",(0,t.jsx)(n.h3,{id:"csv-\ud30c\uc77c",children:"CSV \ud30c\uc77c"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"rank"}),(0,t.jsx)(n.th,{children:"id"}),(0,t.jsx)(n.th,{children:"title"}),(0,t.jsx)(n.th,{children:"url"}),(0,t.jsx)(n.th,{children:"site"}),(0,t.jsx)(n.th,{children:"score"}),(0,t.jsx)(n.th,{children:"author"}),(0,t.jsx)(n.th,{children:"time"}),(0,t.jsx)(n.th,{children:"comments"})]})}),(0,t.jsx)(n.tbody,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"1"}),(0,t.jsx)(n.td,{children:"12345"}),(0,t.jsx)(n.td,{children:"Example Title"}),(0,t.jsx)(n.td,{children:"https://..."}),(0,t.jsx)(n.td,{children:"example.com"}),(0,t.jsx)(n.td,{children:"234"}),(0,t.jsx)(n.td,{children:"user1"}),(0,t.jsx)(n.td,{children:"2024-01-01"}),(0,t.jsx)(n.td,{children:"45"})]})})]}),"\n",(0,t.jsx)(n.h3,{id:"json-\ud30c\uc77c",children:"JSON \ud30c\uc77c"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'[\n  {\n    "rank": 1,\n    "id": "12345",\n    "title": "Example Title",\n    "url": "https://...",\n    "site": "example.com",\n    "score": 234,\n    "author": "user1",\n    "time": "2024-01-01T10:00:00",\n    "comments": 45\n  }\n]\n'})}),"\n",(0,t.jsx)(n.h2,{id:"-\ud655\uc7a5-\uc544\uc774\ub514\uc5b4",children:"\ud83d\udd0d \ud655\uc7a5 \uc544\uc774\ub514\uc5b4"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"\ub313\uae00 \uc218\uc9d1"}),": \uac01 \uae30\uc0ac\uc758 \ub313\uae00\uae4c\uc9c0 \uc218\uc9d1"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"\ud2b8\ub80c\ub4dc \ubd84\uc11d"}),": \uc2dc\uac04\ub300\ubcc4 \uc778\uae30 \uc8fc\uc81c \ubd84\uc11d"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"\uc54c\ub9bc \uae30\ub2a5"}),": \ud2b9\uc815 \ud0a4\uc6cc\ub4dc \ubc1c\uacac \uc2dc \uc54c\ub9bc"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"\ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc800\uc7a5"}),": PostgreSQL/MongoDB \uc5f0\ub3d9"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"\ub300\uc2dc\ubcf4\ub4dc"}),": Streamlit\uc73c\ub85c \uc2dc\uac01\ud654"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-\ub2e4\uc74c-\ub2e8\uacc4",children:"\ud83d\udcda \ub2e4\uc74c \ub2e8\uacc4"}),"\n",(0,t.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,t.jsx)(n.a,{href:"./scenario-02-ecommerce-scraper",children:"\uc1fc\ud551\ubab0 \uac00\uaca9 \ubaa8\ub2c8\ud130\ub9c1"})]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>l});var s=r(6540);const t={},i=s.createContext(t);function o(e){const n=s.useContext(i);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),s.createElement(i.Provider,{value:n},e.children)}}}]);