"use strict";(globalThis.webpackChunkgithub_docs=globalThis.webpackChunkgithub_docs||[]).push([[5363],{8098:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>d});const o=JSON.parse('{"id":"rabbitmq/examples/scenario-04-job-scheduler","title":"\uc2dc\ub098\ub9ac\uc624 4: \ubd84\uc0b0 \uc791\uc5c5 \uc2a4\ucf00\uc904\ub7ec","description":"\ub300\uaddc\ubaa8 \ubc31\uadf8\ub77c\uc6b4\ub4dc \uc791\uc5c5\uc744 \ubd84\uc0b0 \ucc98\ub9ac\ud558\ub294 \uc2dc\uc2a4\ud15c\uc744 \uad6c\ud604\ud574\ubd05\uc2dc\ub2e4!","source":"@site/docs/rabbitmq/examples/scenario-04-job-scheduler.md","sourceDirName":"rabbitmq/examples","slug":"/rabbitmq/examples/scenario-04-job-scheduler","permalink":"/docs/rabbitmq/examples/scenario-04-job-scheduler","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/rabbitmq/examples/scenario-04-job-scheduler.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"rabbitmqSidebar","previous":{"title":"\uc2dc\ub098\ub9ac\uc624 3: \uc774\ubca4\ud2b8 \uae30\ubc18 \ub9c8\uc774\ud06c\ub85c\uc11c\ube44\uc2a4","permalink":"/docs/rabbitmq/examples/scenario-03-event-driven"},"next":{"title":"\uc2dc\ub098\ub9ac\uc624 5: IoT \ud154\ub808\uba54\ud2b8\ub9ac \ucc98\ub9ac","permalink":"/docs/rabbitmq/examples/scenario-05-iot-telemetry"}}');var i=r(4848),t=r(8453);const s={sidebar_position:5},a="\uc2dc\ub098\ub9ac\uc624 4: \ubd84\uc0b0 \uc791\uc5c5 \uc2a4\ucf00\uc904\ub7ec",l={},d=[{value:"\ud83d\udccc \uc0c1\ud669 \uc124\uba85",id:"-\uc0c1\ud669-\uc124\uba85",level:2},{value:"\ud83c\udfd7\ufe0f \uc544\ud0a4\ud14d\ucc98",id:"\ufe0f-\uc544\ud0a4\ud14d\ucc98",level:2},{value:"\ud83d\udcdd \uad6c\ud604",id:"-\uad6c\ud604",level:2},{value:"\uc791\uc5c5 \ubaa8\ub378",id:"\uc791\uc5c5-\ubaa8\ub378",level:3},{value:"Queue \uc124\uc815",id:"queue-\uc124\uc815",level:3},{value:"Job Scheduler",id:"job-scheduler",level:3},{value:"Worker",id:"worker",level:3},{value:"Failed Job Handler",id:"failed-job-handler",level:3},{value:"Job Monitor",id:"job-monitor",level:3},{value:"\ud83d\ude80 \uc2e4\ud589 \ubc29\ubc95",id:"-\uc2e4\ud589-\ubc29\ubc95",level:2},{value:"1. Queue \uc124\uc815",id:"1-queue-\uc124\uc815",level:3},{value:"2. Worker Pool \uc2dc\uc791 (5\uac1c \uc6cc\ucee4)",id:"2-worker-pool-\uc2dc\uc791-5\uac1c-\uc6cc\ucee4",level:3},{value:"3. Failed Job Handler \uc2dc\uc791",id:"3-failed-job-handler-\uc2dc\uc791",level:3},{value:"4. \uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1",id:"4-\uc791\uc5c5-\uc2a4\ucf00\uc904\ub9c1",level:3},{value:"5. \ubaa8\ub2c8\ud130\ub9c1",id:"5-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"\ud83d\udca1 \uace0\uae09 \uae30\ub2a5",id:"-\uace0\uae09-\uae30\ub2a5",level:2},{value:"1. \uc791\uc5c5 \ucde8\uc18c",id:"1-\uc791\uc5c5-\ucde8\uc18c",level:3},{value:"2. \uc791\uc5c5 \uc6b0\uc120\uc21c\uc704 \ub3d9\uc801 \uc870\uc815",id:"2-\uc791\uc5c5-\uc6b0\uc120\uc21c\uc704-\ub3d9\uc801-\uc870\uc815",level:3},{value:"\ud83d\udcda \ud575\uc2ec \uc815\ub9ac",id:"-\ud575\uc2ec-\uc815\ub9ac",level:2},{value:"\ud83d\udcda \ub2e4\uc74c \ub2e8\uacc4",id:"-\ub2e4\uc74c-\ub2e8\uacc4",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"\uc2dc\ub098\ub9ac\uc624-4-\ubd84\uc0b0-\uc791\uc5c5-\uc2a4\ucf00\uc904\ub7ec",children:"\uc2dc\ub098\ub9ac\uc624 4: \ubd84\uc0b0 \uc791\uc5c5 \uc2a4\ucf00\uc904\ub7ec"})}),"\n",(0,i.jsx)(n.p,{children:"\ub300\uaddc\ubaa8 \ubc31\uadf8\ub77c\uc6b4\ub4dc \uc791\uc5c5\uc744 \ubd84\uc0b0 \ucc98\ub9ac\ud558\ub294 \uc2dc\uc2a4\ud15c\uc744 \uad6c\ud604\ud574\ubd05\uc2dc\ub2e4!"}),"\n",(0,i.jsx)(n.h2,{id:"-\uc0c1\ud669-\uc124\uba85",children:"\ud83d\udccc \uc0c1\ud669 \uc124\uba85"}),"\n",(0,i.jsx)(n.p,{children:"\ub370\uc774\ud130 \ubd84\uc11d \ud50c\ub7ab\ud3fc\uc758 \uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\uc791\uc5c5 \ud0c0\uc785"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\ub370\uc774\ud130 \uc218\uc9d1 (Crawling)"}),"\n",(0,i.jsx)(n.li,{children:"\ub370\uc774\ud130 \ubd84\uc11d (Analysis)"}),"\n",(0,i.jsx)(n.li,{children:"\ub9ac\ud3ec\ud2b8 \uc0dd\uc131 (Report)"}),"\n",(0,i.jsx)(n.li,{children:"\ub370\uc774\ud130 \uc815\ub9ac (Cleanup)"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"\uc694\uad6c\uc0ac\ud56d"}),":","\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"\uc6b0\uc120\uc21c\uc704 \uae30\ubc18 \ucc98\ub9ac"}),"\n",(0,i.jsx)(n.li,{children:"\uc7ac\uc2dc\ub3c4 \uba54\ucee4\ub2c8\uc998"}),"\n",(0,i.jsx)(n.li,{children:"\uc791\uc5c5 \uc0c1\ud0dc \ucd94\uc801"}),"\n",(0,i.jsx)(n.li,{children:"\uc6cc\ucee4 \ubd80\ud558 \ubd84\uc0b0"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"\ufe0f-\uc544\ud0a4\ud14d\ucc98",children:"\ud83c\udfd7\ufe0f \uc544\ud0a4\ud14d\ucc98"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"Job Scheduler \u2192 [Priority Queue] \u2192 Worker Pool (N workers)\n                       \u2193\n                  [DLX] \u2192 Failed Jobs \u2192 Manual Review\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"\ud575\uc2ec \uae30\ub2a5"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Priority Queue\ub85c \uae34\uae09 \uc791\uc5c5 \uc6b0\uc120 \ucc98\ub9ac"}),"\n",(0,i.jsx)(n.li,{children:"Dead Letter Exchange\ub85c \uc2e4\ud328 \uc791\uc5c5 \ucc98\ub9ac"}),"\n",(0,i.jsx)(n.li,{children:"Worker Pool\ub85c \ubcd1\ub82c \ucc98\ub9ac"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"-\uad6c\ud604",children:"\ud83d\udcdd \uad6c\ud604"}),"\n",(0,i.jsx)(n.h3,{id:"\uc791\uc5c5-\ubaa8\ub378",children:"\uc791\uc5c5 \ubaa8\ub378"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# models.py\nfrom dataclasses import dataclass, asdict, field\nfrom enum import Enum\nfrom typing import Dict, Any, Optional\nfrom datetime import datetime\nimport json\n\nclass JobType(str, Enum):\n    \"\"\"\uc791\uc5c5 \ud0c0\uc785\"\"\"\n    CRAWLING = 'crawling'\n    ANALYSIS = 'analysis'\n    REPORT = 'report'\n    CLEANUP = 'cleanup'\n\nclass JobPriority(int, Enum):\n    \"\"\"\uc791\uc5c5 \uc6b0\uc120\uc21c\uc704\"\"\"\n    CRITICAL = 10\n    HIGH = 7\n    NORMAL = 5\n    LOW = 1\n\nclass JobStatus(str, Enum):\n    \"\"\"\uc791\uc5c5 \uc0c1\ud0dc\"\"\"\n    PENDING = 'pending'\n    RUNNING = 'running'\n    COMPLETED = 'completed'\n    FAILED = 'failed'\n    RETRY = 'retry'\n\n@dataclass\nclass Job:\n    \"\"\"\uc791\uc5c5\"\"\"\n    job_id: str\n    job_type: JobType\n    priority: JobPriority\n    params: Dict[str, Any]\n    status: JobStatus = JobStatus.PENDING\n    retry_count: int = 0\n    max_retries: int = 3\n    created_at: str = field(default_factory=lambda: datetime.now().isoformat())\n    started_at: Optional[str] = None\n    completed_at: Optional[str] = None\n    error_message: Optional[str] = None\n\n    def to_json(self) -> str:\n        data = asdict(self)\n        # Enum\uc744 \ubb38\uc790\uc5f4\ub85c \ubcc0\ud658\n        data['job_type'] = self.job_type.value\n        data['priority'] = self.priority.value\n        data['status'] = self.status.value\n        return json.dumps(data)\n\n    @classmethod\n    def from_json(cls, json_str: str):\n        data = json.loads(json_str)\n        # \ubb38\uc790\uc5f4\uc744 Enum\uc73c\ub85c \ubcc0\ud658\n        data['job_type'] = JobType(data['job_type'])\n        data['priority'] = JobPriority(data['priority'])\n        data['status'] = JobStatus(data['status'])\n        return cls(**data)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"queue-\uc124\uc815",children:"Queue \uc124\uc815"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# queue_setup.py\nimport pika\n\ndef setup_job_queues():\n    \"\"\"\uc791\uc5c5 \ud050 \uc124\uc815\"\"\"\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters('localhost')\n    )\n    channel = connection.channel()\n\n    # 1. Dead Letter Exchange\n    channel.exchange_declare(\n        exchange='jobs.dlx',\n        exchange_type='direct',\n        durable=True\n    )\n\n    # 2. Failed Jobs Queue\n    channel.queue_declare(\n        queue='jobs.failed',\n        durable=True\n    )\n\n    channel.queue_bind(\n        exchange='jobs.dlx',\n        queue='jobs.failed',\n        routing_key='failed'\n    )\n\n    # 3. Retry Queue (5\ucd08 \ud6c4 \uc7ac\uc2dc\ub3c4)\n    channel.queue_declare(\n        queue='jobs.retry',\n        durable=True,\n        arguments={\n            'x-dead-letter-exchange': '',\n            'x-dead-letter-routing-key': 'jobs.main',\n            'x-message-ttl': 5000  # 5\ucd08\n        }\n    )\n\n    # 4. Main Job Queue (\uc6b0\uc120\uc21c\uc704 + DLX)\n    channel.queue_declare(\n        queue='jobs.main',\n        durable=True,\n        arguments={\n            'x-max-priority': 10,  # \uc6b0\uc120\uc21c\uc704 \uc9c0\uc6d0\n            'x-dead-letter-exchange': 'jobs.dlx',\n            'x-dead-letter-routing-key': 'failed'\n        }\n    )\n\n    print(\" [\u2713] Job queues configured:\")\n    print(\"     - jobs.main (priority queue)\")\n    print(\"     - jobs.retry (5s TTL)\")\n    print(\"     - jobs.failed (DLQ)\")\n\n    connection.close()\n\nif __name__ == '__main__':\n    setup_job_queues()\n"})}),"\n",(0,i.jsx)(n.h3,{id:"job-scheduler",children:"Job Scheduler"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# job_scheduler.py\nimport pika\nfrom models import Job, JobType, JobPriority\nimport uuid\n\nclass JobScheduler:\n    """\uc791\uc5c5 \uc2a4\ucf00\uc904\ub7ec"""\n\n    def __init__(self, host=\'localhost\'):\n        self.host = host\n\n    def schedule(self, job: Job):\n        """\uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1"""\n        connection = pika.BlockingConnection(\n            pika.ConnectionParameters(self.host)\n        )\n        channel = connection.channel()\n\n        # \uc6b0\uc120\uc21c\uc704\uc640 \ud568\uaed8 \ubc1c\ud589\n        channel.basic_publish(\n            exchange=\'\',\n            routing_key=\'jobs.main\',\n            body=job.to_json(),\n            properties=pika.BasicProperties(\n                delivery_mode=2,\n                priority=job.priority.value,\n                content_type=\'application/json\'\n            )\n        )\n\n        print(f" [\u2192] Scheduled job: {job.job_id} "\n              f"(type={job.job_type.value}, priority={job.priority.value})")\n\n        connection.close()\n\n    def schedule_crawling(self, url: str, priority: JobPriority = JobPriority.NORMAL):\n        """\ud06c\ub864\ub9c1 \uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1"""\n        job = Job(\n            job_id=f\'CRAWL-{uuid.uuid4().hex[:8].upper()}\',\n            job_type=JobType.CRAWLING,\n            priority=priority,\n            params={\'url\': url}\n        )\n\n        self.schedule(job)\n        return job.job_id\n\n    def schedule_analysis(self, data_id: str, priority: JobPriority = JobPriority.NORMAL):\n        """\ubd84\uc11d \uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1"""\n        job = Job(\n            job_id=f\'ANALYZE-{uuid.uuid4().hex[:8].upper()}\',\n            job_type=JobType.ANALYSIS,\n            priority=priority,\n            params={\'data_id\': data_id}\n        )\n\n        self.schedule(job)\n        return job.job_id\n\n    def schedule_report(self, user_id: int, priority: JobPriority = JobPriority.HIGH):\n        """\ub9ac\ud3ec\ud2b8 \uc0dd\uc131 \uc2a4\ucf00\uc904\ub9c1"""\n        job = Job(\n            job_id=f\'REPORT-{uuid.uuid4().hex[:8].upper()}\',\n            job_type=JobType.REPORT,\n            priority=priority,\n            params={\'user_id\': user_id}\n        )\n\n        self.schedule(job)\n        return job.job_id\n\n# \uc0ac\uc6a9 \uc608\nif __name__ == \'__main__\':\n    scheduler = JobScheduler()\n\n    # \ub2e4\uc591\ud55c \uc6b0\uc120\uc21c\uc704\uc758 \uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1\n    scheduler.schedule_crawling(\'https://example.com\', JobPriority.LOW)\n    scheduler.schedule_analysis(\'data-001\', JobPriority.NORMAL)\n    scheduler.schedule_report(1001, JobPriority.HIGH)\n    scheduler.schedule_report(1002, JobPriority.CRITICAL)\n\n    print("\\n [i] Jobs scheduled by priority!")\n    print(" [i] Processing order: CRITICAL \u2192 HIGH \u2192 NORMAL \u2192 LOW")\n'})}),"\n",(0,i.jsx)(n.h3,{id:"worker",children:"Worker"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# worker.py\nimport pika\nimport time\nimport random\nfrom models import Job, JobType, JobStatus\nfrom datetime import datetime\n\nclass Worker:\n    """\uc791\uc5c5 \uc6cc\ucee4"""\n\n    def __init__(self, worker_id: int, host=\'localhost\'):\n        self.worker_id = worker_id\n        self.host = host\n        self.connection = None\n        self.channel = None\n\n    def execute_crawling(self, params: dict):\n        """\ud06c\ub864\ub9c1 \uc2e4\ud589"""\n        url = params[\'url\']\n        print(f"   [Worker {self.worker_id}] Crawling: {url}")\n        time.sleep(2)  # \uc2dc\ubbac\ub808\uc774\uc158\n\n        # 10% \ud655\ub960\ub85c \uc2e4\ud328\n        if random.random() < 0.1:\n            raise Exception(f"Failed to crawl {url}")\n\n        print(f"   [Worker {self.worker_id}] \u2713 Crawling completed")\n\n    def execute_analysis(self, params: dict):\n        """\ubd84\uc11d \uc2e4\ud589"""\n        data_id = params[\'data_id\']\n        print(f"   [Worker {self.worker_id}] Analyzing: {data_id}")\n        time.sleep(3)  # \uc2dc\ubbac\ub808\uc774\uc158\n\n        if random.random() < 0.1:\n            raise Exception(f"Analysis failed for {data_id}")\n\n        print(f"   [Worker {self.worker_id}] \u2713 Analysis completed")\n\n    def execute_report(self, params: dict):\n        """\ub9ac\ud3ec\ud2b8 \uc0dd\uc131"""\n        user_id = params[\'user_id\']\n        print(f"   [Worker {self.worker_id}] Generating report for user {user_id}")\n        time.sleep(1)  # \uc2dc\ubbac\ub808\uc774\uc158\n\n        print(f"   [Worker {self.worker_id}] \u2713 Report generated")\n\n    def execute_cleanup(self, params: dict):\n        """\uc815\ub9ac \uc791\uc5c5"""\n        print(f"   [Worker {self.worker_id}] Running cleanup")\n        time.sleep(0.5)  # \uc2dc\ubbac\ub808\uc774\uc158\n\n        print(f"   [Worker {self.worker_id}] \u2713 Cleanup completed")\n\n    def execute_job(self, job: Job):\n        """\uc791\uc5c5 \uc2e4\ud589"""\n        print(f"\\n [Worker {self.worker_id}] Processing job: {job.job_id}")\n        print(f"   Type: {job.job_type.value}")\n        print(f"   Priority: {job.priority.value}")\n\n        # \uc791\uc5c5 \uc2dc\uc791\n        job.status = JobStatus.RUNNING\n        job.started_at = datetime.now().isoformat()\n\n        # \uc791\uc5c5 \ud0c0\uc785\ubcc4 \uc2e4\ud589\n        try:\n            if job.job_type == JobType.CRAWLING:\n                self.execute_crawling(job.params)\n            elif job.job_type == JobType.ANALYSIS:\n                self.execute_analysis(job.params)\n            elif job.job_type == JobType.REPORT:\n                self.execute_report(job.params)\n            elif job.job_type == JobType.CLEANUP:\n                self.execute_cleanup(job.params)\n\n            # \uc131\uacf5\n            job.status = JobStatus.COMPLETED\n            job.completed_at = datetime.now().isoformat()\n\n            return True\n\n        except Exception as e:\n            # \uc2e4\ud328\n            job.status = JobStatus.FAILED\n            job.error_message = str(e)\n\n            print(f"   [Worker {self.worker_id}] \u2717 Job failed: {e}")\n\n            return False\n\n    def send_to_retry(self, job: Job):\n        """\uc7ac\uc2dc\ub3c4 \ud050\ub85c \uc804\uc1a1"""\n        job.retry_count += 1\n\n        print(f"   [Worker {self.worker_id}] \u2192 Sending to retry queue "\n              f"(attempt {job.retry_count}/{job.max_retries})")\n\n        self.channel.basic_publish(\n            exchange=\'\',\n            routing_key=\'jobs.retry\',\n            body=job.to_json(),\n            properties=pika.BasicProperties(\n                delivery_mode=2,\n                content_type=\'application/json\'\n            )\n        )\n\n    def callback(self, ch, method, properties, body):\n        """\uba54\uc2dc\uc9c0 \ucc98\ub9ac \ucf5c\ubc31"""\n        job = Job.from_json(body.decode())\n\n        # \uc791\uc5c5 \uc2e4\ud589\n        success = self.execute_job(job)\n\n        if success:\n            # \uc131\uacf5: ACK\n            ch.basic_ack(delivery_tag=method.delivery_tag)\n\n        else:\n            # \uc2e4\ud328: \uc7ac\uc2dc\ub3c4 \ud655\uc778\n            if job.retry_count < job.max_retries:\n                # \uc7ac\uc2dc\ub3c4 \ud050\ub85c \uc804\uc1a1\n                self.send_to_retry(job)\n\n                # \uc6d0\ubcf8 \uba54\uc2dc\uc9c0 ACK\n                ch.basic_ack(delivery_tag=method.delivery_tag)\n\n            else:\n                # \ucd5c\ub300 \uc7ac\uc2dc\ub3c4 \ucd08\uacfc: NACK \u2192 DLX\ub85c \uc774\ub3d9\n                print(f"   [Worker {self.worker_id}] \u2717 Max retries exceeded")\n\n                ch.basic_nack(\n                    delivery_tag=method.delivery_tag,\n                    requeue=False\n                )\n\n    def start(self):\n        """\uc6cc\ucee4 \uc2dc\uc791"""\n        self.connection = pika.BlockingConnection(\n            pika.ConnectionParameters(self.host)\n        )\n        self.channel = self.connection.channel()\n\n        # Fair dispatch (prefetch_count=1)\n        self.channel.basic_qos(prefetch_count=1)\n\n        self.channel.basic_consume(\n            queue=\'jobs.main\',\n            on_message_callback=self.callback\n        )\n\n        print(f\' [*] Worker {self.worker_id} started\')\n        print(f\' [*] Waiting for jobs...\\n\')\n\n        self.channel.start_consuming()\n\nif __name__ == \'__main__\':\n    import sys\n\n    worker_id = int(sys.argv[1]) if len(sys.argv) > 1 else 1\n\n    worker = Worker(worker_id=worker_id)\n\n    try:\n        worker.start()\n    except KeyboardInterrupt:\n        print(f\'\\nWorker {worker_id} stopped\')\n'})}),"\n",(0,i.jsx)(n.h3,{id:"failed-job-handler",children:"Failed Job Handler"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# failed_job_handler.py\nimport pika\nfrom models import Job\n\nclass FailedJobHandler:\n    """\uc2e4\ud328\ud55c \uc791\uc5c5 \ucc98\ub9ac"""\n\n    def __init__(self, host=\'localhost\'):\n        self.host = host\n\n    def handle_failed_job(self, ch, method, properties, body):\n        """\uc2e4\ud328\ud55c \uc791\uc5c5 \ucc98\ub9ac"""\n        job = Job.from_json(body.decode())\n\n        print(f"""\n        \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n        \u26a0\ufe0f  FAILED JOB\n        \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n        Job ID: {job.job_id}\n        Type: {job.job_type.value}\n        Priority: {job.priority.value}\n        Retry Count: {job.retry_count}\n        Error: {job.error_message}\n\n        Action Required: Manual investigation\n        \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\n        """)\n\n        # \uc2e4\ud328 \ub85c\uadf8 \uc800\uc7a5\n        self.save_to_database(job)\n\n        # \uad00\ub9ac\uc790 \uc54c\ub9bc\n        # send_admin_alert(job)\n\n        ch.basic_ack(delivery_tag=method.delivery_tag)\n\n    def save_to_database(self, job: Job):\n        """DB\uc5d0 \uc800\uc7a5 (\uc2dc\ubbac\ub808\uc774\uc158)"""\n        import json\n\n        with open(\'failed_jobs.jsonl\', \'a\', encoding=\'utf-8\') as f:\n            f.write(job.to_json() + \'\\n\')\n\n    def start(self):\n        """\ud578\ub4e4\ub7ec \uc2dc\uc791"""\n        connection = pika.BlockingConnection(\n            pika.ConnectionParameters(self.host)\n        )\n        channel = connection.channel()\n\n        channel.basic_consume(\n            queue=\'jobs.failed\',\n            on_message_callback=self.handle_failed_job\n        )\n\n        print(\' [*] Failed Job Handler started\')\n        print(\' [*] Waiting for failed jobs...\\n\')\n\n        channel.start_consuming()\n\nif __name__ == \'__main__\':\n    handler = FailedJobHandler()\n\n    try:\n        handler.start()\n    except KeyboardInterrupt:\n        print(\'\\nFailed Job Handler stopped\')\n'})}),"\n",(0,i.jsx)(n.h3,{id:"job-monitor",children:"Job Monitor"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# job_monitor.py\nimport requests\nfrom requests.auth import HTTPBasicAuth\nimport time\n\nclass JobMonitor:\n    """\uc791\uc5c5 \ubaa8\ub2c8\ud130"""\n\n    def __init__(self, host=\'localhost\', user=\'admin\', password=\'admin123\'):\n        self.base_url = f\'http://{host}:15672/api\'\n        self.auth = HTTPBasicAuth(user, password)\n\n    def get_queue_stats(self):\n        """\ud050 \uc0c1\ud0dc \uc870\ud68c"""\n        response = requests.get(\n            f\'{self.base_url}/queues\',\n            auth=self.auth\n        )\n\n        queues = response.json()\n\n        stats = {}\n        for queue in queues:\n            if queue[\'name\'].startswith(\'jobs.\'):\n                stats[queue[\'name\']] = {\n                    \'messages\': queue.get(\'messages\', 0),\n                    \'ready\': queue.get(\'messages_ready\', 0),\n                    \'unacked\': queue.get(\'messages_unacknowledged\', 0),\n                    \'consumers\': queue.get(\'consumers\', 0)\n                }\n\n        return stats\n\n    def print_stats(self):\n        """\ud1b5\uacc4 \ucd9c\ub825"""\n        stats = self.get_queue_stats()\n\n        print(" Job Queue Statistics")\n        print(" " + "="*60)\n\n        for queue_name, data in stats.items():\n            print(f"\\n {queue_name}:")\n            print(f"   Total: {data[\'messages\']:4d} | "\n                  f"Ready: {data[\'ready\']:4d} | "\n                  f"Unacked: {data[\'unacked\']:4d} | "\n                  f"Consumers: {data[\'consumers\']:2d}")\n\n    def monitor(self, interval: int = 5):\n        """\uc2e4\uc2dc\uac04 \ubaa8\ub2c8\ud130\ub9c1"""\n        print(f" Job Monitor (refresh every {interval}s)")\n        print(" Press Ctrl+C to stop\\n")\n\n        try:\n            while True:\n                self.print_stats()\n                print()\n                time.sleep(interval)\n\n        except KeyboardInterrupt:\n            print("\\n Monitoring stopped")\n\n# \uc0ac\uc6a9 \uc608\nif __name__ == \'__main__\':\n    monitor = JobMonitor()\n    monitor.monitor(interval=3)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-\uc2e4\ud589-\ubc29\ubc95",children:"\ud83d\ude80 \uc2e4\ud589 \ubc29\ubc95"}),"\n",(0,i.jsx)(n.h3,{id:"1-queue-\uc124\uc815",children:"1. Queue \uc124\uc815"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python queue_setup.py\n"})}),"\n",(0,i.jsx)(n.h3,{id:"2-worker-pool-\uc2dc\uc791-5\uac1c-\uc6cc\ucee4",children:"2. Worker Pool \uc2dc\uc791 (5\uac1c \uc6cc\ucee4)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# \ud130\ubbf8\ub110 1-5\npython worker.py 1\npython worker.py 2\npython worker.py 3\npython worker.py 4\npython worker.py 5\n"})}),"\n",(0,i.jsx)(n.h3,{id:"3-failed-job-handler-\uc2dc\uc791",children:"3. Failed Job Handler \uc2dc\uc791"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# \ud130\ubbf8\ub110 6\npython failed_job_handler.py\n"})}),"\n",(0,i.jsx)(n.h3,{id:"4-\uc791\uc5c5-\uc2a4\ucf00\uc904\ub9c1",children:"4. \uc791\uc5c5 \uc2a4\ucf00\uc904\ub9c1"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# \ud130\ubbf8\ub110 7\npython job_scheduler.py\n"})}),"\n",(0,i.jsx)(n.h3,{id:"5-\ubaa8\ub2c8\ud130\ub9c1",children:"5. \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# \ud130\ubbf8\ub110 8\npython job_monitor.py\n"})}),"\n",(0,i.jsx)(n.h2,{id:"-\uace0\uae09-\uae30\ub2a5",children:"\ud83d\udca1 \uace0\uae09 \uae30\ub2a5"}),"\n",(0,i.jsx)(n.h3,{id:"1-\uc791\uc5c5-\ucde8\uc18c",children:"1. \uc791\uc5c5 \ucde8\uc18c"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# job_cancel.py\nimport pika\n\ndef cancel_job(job_id: str):\n    """\uc791\uc5c5 \ucde8\uc18c (\ud050\uc5d0\uc11c \uc81c\uac70)"""\n    connection = pika.BlockingConnection(\n        pika.ConnectionParameters(\'localhost\')\n    )\n    channel = connection.channel()\n\n    # \ud050\uc758 \ubaa8\ub4e0 \uba54\uc2dc\uc9c0 \ud655\uc778\n    while True:\n        method, properties, body = channel.basic_get(\n            queue=\'jobs.main\',\n            auto_ack=False\n        )\n\n        if method is None:\n            break\n\n        from models import Job\n        job = Job.from_json(body.decode())\n\n        if job.job_id == job_id:\n            # \ucc3e\uc740 \uc791\uc5c5: NACK (\uc0ad\uc81c)\n            channel.basic_nack(\n                delivery_tag=method.delivery_tag,\n                requeue=False\n            )\n            print(f" [\u2713] Job {job_id} cancelled")\n            break\n        else:\n            # \ub2e4\ub978 \uc791\uc5c5: \ub2e4\uc2dc \ud050\uc5d0\n            channel.basic_nack(\n                delivery_tag=method.delivery_tag,\n                requeue=True\n            )\n\n    connection.close()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"2-\uc791\uc5c5-\uc6b0\uc120\uc21c\uc704-\ub3d9\uc801-\uc870\uc815",children:"2. \uc791\uc5c5 \uc6b0\uc120\uc21c\uc704 \ub3d9\uc801 \uc870\uc815"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# job_reschedule.py\ndef reschedule_with_priority(job_id: str, new_priority: int):\n    """\uc791\uc5c5 \uc6b0\uc120\uc21c\uc704 \uc7ac\uc124\uc815"""\n    # 1. \uae30\uc874 \uc791\uc5c5 \ucde8\uc18c\n    cancel_job(job_id)\n\n    # 2. \uc0c8 \uc6b0\uc120\uc21c\uc704\ub85c \uc7ac\uc2a4\ucf00\uc904\ub9c1\n    # (\uc2e4\uc81c\ub85c\ub294 job \uc815\ubcf4\ub97c \uc800\uc7a5\ud574\uc57c \ud568)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"-\ud575\uc2ec-\uc815\ub9ac",children:"\ud83d\udcda \ud575\uc2ec \uc815\ub9ac"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Priority Queue"}),": \uae34\uae09 \uc791\uc5c5 \uc6b0\uc120 \ucc98\ub9ac"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Retry Mechanism"}),": TTL \uae30\ubc18 \uc790\ub3d9 \uc7ac\uc2dc\ub3c4"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"DLX"}),": \uc601\uad6c \uc2e4\ud328 \uc791\uc5c5 \ubcc4\ub3c4 \ucc98\ub9ac"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Worker Pool"}),": Fair Dispatch\ub85c \ubd80\ud558 \ubd84\uc0b0"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"-\ub2e4\uc74c-\ub2e8\uacc4",children:"\ud83d\udcda \ub2e4\uc74c \ub2e8\uacc4"}),"\n",(0,i.jsxs)(n.p,{children:["\ud83d\udc49 ",(0,i.jsx)(n.a,{href:"./scenario-05-iot-telemetry",children:"\uc2dc\ub098\ub9ac\uc624 5: IoT \ud154\ub808\uba54\ud2b8\ub9ac"})]})]})}function u(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>a});var o=r(6540);const i={},t=o.createContext(i);function s(e){const n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);