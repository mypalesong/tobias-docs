"use strict";(globalThis.webpackChunkgithub_docs=globalThis.webpackChunkgithub_docs||[]).push([[9514],{107:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>d,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>s,toc:()=>_});const s=JSON.parse('{"id":"dagster/schedules-sensors","title":"3. \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c","description":"Dagster\uc758 \uc2a4\ucf00\uc904(Schedule)\uacfc \uc13c\uc11c(Sensor)\ub294 \ud30c\uc774\ud504\ub77c\uc778\uc744 \uc790\ub3d9\uc73c\ub85c \uc2e4\ud589\ud558\ub294 \ub450 \uac00\uc9c0 \uc8fc\uc694 \uba54\ucee4\ub2c8\uc998\uc785\ub2c8\ub2e4. \uc2a4\ucf00\uc904\uc740 \uc2dc\uac04 \uae30\ubc18\uc73c\ub85c \uc791\uc5c5\uc744 \ud2b8\ub9ac\uac70\ud558\uace0, \uc13c\uc11c\ub294 \uc774\ubca4\ud2b8 \uae30\ubc18\uc73c\ub85c \uc791\uc5c5\uc744 \ud2b8\ub9ac\uac70\ud569\ub2c8\ub2e4.","source":"@site/docs/dagster/schedules-sensors.md","sourceDirName":"dagster","slug":"/dagster/schedules-sensors","permalink":"/tobias-docs/comp-2/docs/dagster/schedules-sensors","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/dagster/schedules-sensors.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4},"sidebar":"dagsterSidebar","previous":{"title":"2. Ops\uc640 Jobs","permalink":"/tobias-docs/comp-2/docs/dagster/ops-jobs"},"next":{"title":"4. Resources","permalink":"/tobias-docs/comp-2/docs/dagster/resources"}}');var r=t(4848),o=t(8453);const a={sidebar_position:4},i="3. \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c",d={},_=[{value:"3.1 Schedule \uac1c\ub150",id:"31-schedule-\uac1c\ub150",level:2},{value:"\uae30\ubcf8 \uc2a4\ucf00\uc904 \uc815\uc758",id:"\uae30\ubcf8-\uc2a4\ucf00\uc904-\uc815\uc758",level:3},{value:"\uc2a4\ucf00\uc904\uc758 \uc8fc\uc694 \uad6c\uc131\uc694\uc18c",id:"\uc2a4\ucf00\uc904\uc758-\uc8fc\uc694-\uad6c\uc131\uc694\uc18c",level:3},{value:"\ub3d9\uc801 \uc2a4\ucf00\uc904 \ud3c9\uac00",id:"\ub3d9\uc801-\uc2a4\ucf00\uc904-\ud3c9\uac00",level:3},{value:"\uc2a4\ucf00\uc904 \uc124\uc815 \uc635\uc158",id:"\uc2a4\ucf00\uc904-\uc124\uc815-\uc635\uc158",level:3},{value:"3.2 Cron \uc2a4\ucf00\uc904",id:"32-cron-\uc2a4\ucf00\uc904",level:2},{value:"Cron \ud45c\ud604\uc2dd \uad6c\uc870",id:"cron-\ud45c\ud604\uc2dd-\uad6c\uc870",level:3},{value:"\uc77c\ubc18\uc801\uc778 Cron \ud328\ud134",id:"\uc77c\ubc18\uc801\uc778-cron-\ud328\ud134",level:3},{value:"Cron \ud5ec\ud37c \ud568\uc218",id:"cron-\ud5ec\ud37c-\ud568\uc218",level:3},{value:"\ubcf5\uc7a1\ud55c Cron \ud328\ud134 \uc608\uc81c",id:"\ubcf5\uc7a1\ud55c-cron-\ud328\ud134-\uc608\uc81c",level:3},{value:"\uc2dc\uac04\ub300 \ucc98\ub9ac",id:"\uc2dc\uac04\ub300-\ucc98\ub9ac",level:3},{value:"3.3 Partitioned Schedule",id:"33-partitioned-schedule",level:2},{value:"\uae30\ubcf8 Partitioned Schedule",id:"\uae30\ubcf8-partitioned-schedule",level:3},{value:"\uc8fc\uac04 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904",id:"\uc8fc\uac04-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",level:3},{value:"\uc6d4\uac04 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904",id:"\uc6d4\uac04-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",level:3},{value:"\uc2dc\uac04\ubcc4 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904",id:"\uc2dc\uac04\ubcc4-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",level:3},{value:"\ucee4\uc2a4\ud140 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904",id:"\ucee4\uc2a4\ud140-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",level:3},{value:"\ubc31\ud544(Backfill) \uc2a4\ucf00\uc904",id:"\ubc31\ud544backfill-\uc2a4\ucf00\uc904",level:3},{value:"3.4 Sensor \uac1c\ub150",id:"34-sensor-\uac1c\ub150",level:2},{value:"\uae30\ubcf8 \uc13c\uc11c \uc815\uc758",id:"\uae30\ubcf8-\uc13c\uc11c-\uc815\uc758",level:3},{value:"\uc13c\uc11c\uc758 \uc8fc\uc694 \uad6c\uc131\uc694\uc18c",id:"\uc13c\uc11c\uc758-\uc8fc\uc694-\uad6c\uc131\uc694\uc18c",level:3},{value:"Cursor\ub97c \uc0ac\uc6a9\ud55c \uc0c1\ud0dc \ucd94\uc801",id:"cursor\ub97c-\uc0ac\uc6a9\ud55c-\uc0c1\ud0dc-\ucd94\uc801",level:3},{value:"\ub2e4\uc911 RunRequest",id:"\ub2e4\uc911-runrequest",level:3},{value:"\uc13c\uc11c \uc124\uc815 \uc635\uc158",id:"\uc13c\uc11c-\uc124\uc815-\uc635\uc158",level:3},{value:"3.5 Asset Sensor",id:"35-asset-sensor",level:2},{value:"\uae30\ubcf8 Asset Sensor",id:"\uae30\ubcf8-asset-sensor",level:3},{value:"\ub2e4\uc911 Asset \ubaa8\ub2c8\ud130\ub9c1",id:"\ub2e4\uc911-asset-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"Asset Materialization \uba54\ud0c0\ub370\uc774\ud130 \ud65c\uc6a9",id:"asset-materialization-\uba54\ud0c0\ub370\uc774\ud130-\ud65c\uc6a9",level:3},{value:"Freshness \uae30\ubc18 Asset Sensor",id:"freshness-\uae30\ubc18-asset-sensor",level:3},{value:"Partition \uae30\ubc18 Asset Sensor",id:"partition-\uae30\ubc18-asset-sensor",level:3},{value:"3.6 Run Status Sensor",id:"36-run-status-sensor",level:2},{value:"\uae30\ubcf8 Run Status Sensor",id:"\uae30\ubcf8-run-status-sensor",level:3},{value:"\uc2e4\ud328 \uac10\uc9c0 \ubc0f \uc54c\ub9bc",id:"\uc2e4\ud328-\uac10\uc9c0-\ubc0f-\uc54c\ub9bc",level:3},{value:"\ud2b9\uc815 Job \ubaa8\ub2c8\ud130\ub9c1",id:"\ud2b9\uc815-job-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"\ub2e4\uc911 \uc0c1\ud0dc \ubaa8\ub2c8\ud130\ub9c1",id:"\ub2e4\uc911-\uc0c1\ud0dc-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"\uc7ac\uc2dc\ub3c4 \ub85c\uc9c1\uc774 \ud3ec\ud568\ub41c Run Status Sensor",id:"\uc7ac\uc2dc\ub3c4-\ub85c\uc9c1\uc774-\ud3ec\ud568\ub41c-run-status-sensor",level:3},{value:"\uc2e4\ud589 \uc2dc\uac04 \uae30\ubc18 \uc54c\ub9bc",id:"\uc2e4\ud589-\uc2dc\uac04-\uae30\ubc18-\uc54c\ub9bc",level:3},{value:"3.7 \ucee4\uc2a4\ud140 Sensor",id:"37-\ucee4\uc2a4\ud140-sensor",level:2},{value:"API \uae30\ubc18 \uc13c\uc11c",id:"api-\uae30\ubc18-\uc13c\uc11c",level:3},{value:"\ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc13c\uc11c",id:"\ub370\uc774\ud130\ubca0\uc774\uc2a4-\uc13c\uc11c",level:3},{value:"S3 \ubc84\ud0b7 \uc13c\uc11c",id:"s3-\ubc84\ud0b7-\uc13c\uc11c",level:3},{value:"\uba54\uc2dc\uc9c0 \ud050 \uc13c\uc11c",id:"\uba54\uc2dc\uc9c0-\ud050-\uc13c\uc11c",level:3},{value:"\uc6f9\ud6c5 \uae30\ubc18 \uc13c\uc11c",id:"\uc6f9\ud6c5-\uae30\ubc18-\uc13c\uc11c",level:3},{value:"\uc870\uac74\ubd80 \uc2e4\ud589 \uc13c\uc11c",id:"\uc870\uac74\ubd80-\uc2e4\ud589-\uc13c\uc11c",level:3},{value:"3.8 Sensor \ud3c9\uac00",id:"38-sensor-\ud3c9\uac00",level:2},{value:"\ud3c9\uac00 \uac04\uaca9 \uc124\uc815",id:"\ud3c9\uac00-\uac04\uaca9-\uc124\uc815",level:3},{value:"\uc13c\uc11c \uc131\ub2a5 \ucd5c\uc801\ud654",id:"\uc13c\uc11c-\uc131\ub2a5-\ucd5c\uc801\ud654",level:3},{value:"\ubc30\uce58 \ucc98\ub9ac \uc13c\uc11c",id:"\ubc30\uce58-\ucc98\ub9ac-\uc13c\uc11c",level:3},{value:"\uc13c\uc11c \uc0c1\ud0dc \ucd94\uc801",id:"\uc13c\uc11c-\uc0c1\ud0dc-\ucd94\uc801",level:3},{value:"\uc13c\uc11c \ub85c\uae45 \ubc0f \ubaa8\ub2c8\ud130\ub9c1",id:"\uc13c\uc11c-\ub85c\uae45-\ubc0f-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"\uc13c\uc11c \ud14c\uc2a4\ud2b8",id:"\uc13c\uc11c-\ud14c\uc2a4\ud2b8",level:3},{value:"3.9 \uc2e4\uc2b5: \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c \uad6c\ud604",id:"39-\uc2e4\uc2b5-\uc2a4\ucf00\uc904\uacfc-\uc13c\uc11c-\uad6c\ud604",level:2},{value:"\uc2e4\uc2b5 1: \uc77c\uc77c \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778",id:"\uc2e4\uc2b5-1-\uc77c\uc77c-\ub370\uc774\ud130-\ud30c\uc774\ud504\ub77c\uc778",level:3},{value:"\uc2e4\uc2b5 2: \ud30c\uc77c \uc5c5\ub85c\ub4dc \uac10\uc9c0 \uc13c\uc11c",id:"\uc2e4\uc2b5-2-\ud30c\uc77c-\uc5c5\ub85c\ub4dc-\uac10\uc9c0-\uc13c\uc11c",level:3},{value:"\uc2e4\uc2b5 3: \ub370\uc774\ud130 \ud488\uc9c8 \ubaa8\ub2c8\ud130\ub9c1",id:"\uc2e4\uc2b5-3-\ub370\uc774\ud130-\ud488\uc9c8-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"\uc2e4\uc2b5 4: \uc2e4\ud328 \uc7ac\uc2dc\ub3c4 \ubc0f \uc54c\ub9bc \uc2dc\uc2a4\ud15c",id:"\uc2e4\uc2b5-4-\uc2e4\ud328-\uc7ac\uc2dc\ub3c4-\ubc0f-\uc54c\ub9bc-\uc2dc\uc2a4\ud15c",level:3},{value:"3.10 Asset Freshness\uc640 Run Coordination",id:"310-asset-freshness\uc640-run-coordination",level:2},{value:"Asset Freshness \uc815\uc758",id:"asset-freshness-\uc815\uc758",level:3},{value:"Freshness \uccb4\ud06c \uc13c\uc11c",id:"freshness-\uccb4\ud06c-\uc13c\uc11c",level:3},{value:"Run Coordination - Sequential Jobs",id:"run-coordination---sequential-jobs",level:3},{value:"Run Coordination - Parallel Jobs",id:"run-coordination---parallel-jobs",level:3},{value:"Conditional Run Coordination",id:"conditional-run-coordination",level:3},{value:"\uc2dc\uac04 \uae30\ubc18 Coordination",id:"\uc2dc\uac04-\uae30\ubc18-coordination",level:3},{value:"\uc815\ub9ac",id:"\uc815\ub9ac",level:2}];function l(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"3-\uc2a4\ucf00\uc904\uacfc-\uc13c\uc11c",children:"3. \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c"})}),"\n",(0,r.jsx)(e.p,{children:"Dagster\uc758 \uc2a4\ucf00\uc904(Schedule)\uacfc \uc13c\uc11c(Sensor)\ub294 \ud30c\uc774\ud504\ub77c\uc778\uc744 \uc790\ub3d9\uc73c\ub85c \uc2e4\ud589\ud558\ub294 \ub450 \uac00\uc9c0 \uc8fc\uc694 \uba54\ucee4\ub2c8\uc998\uc785\ub2c8\ub2e4. \uc2a4\ucf00\uc904\uc740 \uc2dc\uac04 \uae30\ubc18\uc73c\ub85c \uc791\uc5c5\uc744 \ud2b8\ub9ac\uac70\ud558\uace0, \uc13c\uc11c\ub294 \uc774\ubca4\ud2b8 \uae30\ubc18\uc73c\ub85c \uc791\uc5c5\uc744 \ud2b8\ub9ac\uac70\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h2,{id:"31-schedule-\uac1c\ub150",children:"3.1 Schedule \uac1c\ub150"}),"\n",(0,r.jsx)(e.p,{children:"\uc2a4\ucf00\uc904\uc740 \uc815\ud574\uc9c4 \uc2dc\uac04\uc5d0 \uc790\ub3d9\uc73c\ub85c job\uc744 \uc2e4\ud589\ud558\ub294 Dagster\uc758 \uc790\ub3d9\ud654 \uba54\ucee4\ub2c8\uc998\uc785\ub2c8\ub2e4. \ud06c\ub860(Cron) \ud45c\ud604\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2e4\ud589 \uc8fc\uae30\ub97c \uc815\uc758\ud558\uba70, \ub9e4\uc77c, \ub9e4\uc8fc, \ub9e4\uc6d4 \ub4f1 \ub2e4\uc591\ud55c \uc8fc\uae30\ub85c \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\uae30\ubcf8-\uc2a4\ucf00\uc904-\uc815\uc758",children:"\uae30\ubcf8 \uc2a4\ucf00\uc904 \uc815\uc758"}),"\n",(0,r.jsx)(e.p,{children:"\uac00\uc7a5 \uac04\ub2e8\ud55c \ud615\ud0dc\uc758 \uc2a4\ucf00\uc904\uc740 \ub2e4\uc74c\uacfc \uac19\uc774 \uc815\uc758\ub429\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, ScheduleEvaluationContext, RunRequest, job, op\n\n@op\ndef process_daily_data():\n    """\ub9e4\uc77c \uc2e4\ud589\ub418\ub294 \ub370\uc774\ud130 \ucc98\ub9ac \uc791\uc5c5"""\n    print("Processing daily data...")\n    return "completed"\n\n@job\ndef daily_job():\n    process_daily_data()\n\n@schedule(\n    job=daily_job,\n    cron_schedule="0 0 * * *",  # \ub9e4\uc77c \uc790\uc815\uc5d0 \uc2e4\ud589\n)\ndef daily_schedule():\n    """\ub9e4\uc77c \uc790\uc815\uc5d0 \uc2e4\ud589\ub418\ub294 \uc2a4\ucf00\uc904"""\n    return RunRequest()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2a4\ucf00\uc904\uc758-\uc8fc\uc694-\uad6c\uc131\uc694\uc18c",children:"\uc2a4\ucf00\uc904\uc758 \uc8fc\uc694 \uad6c\uc131\uc694\uc18c"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Job \ucc38\uc870"}),": \uc2e4\ud589\ud560 job\uc744 \uc9c0\uc815"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Cron \ud45c\ud604\uc2dd"}),": \uc2e4\ud589 \uc8fc\uae30\ub97c \uc815\uc758"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RunRequest"}),": \uc2e4\ud589 \uc694\uccad \uac1d\uccb4 \ubc18\ud658"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\uc2e4\ud589 \ucee8\ud14d\uc2a4\ud2b8"}),": \uc2a4\ucf00\uc904 \ud3c9\uac00 \uc2dc\uc810\uc758 \uc815\ubcf4 \uc81c\uacf5"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\ub3d9\uc801-\uc2a4\ucf00\uc904-\ud3c9\uac00",children:"\ub3d9\uc801 \uc2a4\ucf00\uc904 \ud3c9\uac00"}),"\n",(0,r.jsx)(e.p,{children:"\uc2a4\ucf00\uc904\uc740 \uc2e4\ud589 \uc2dc\uc810\uc758 \ucee8\ud14d\uc2a4\ud2b8\ub97c \ud65c\uc6a9\ud558\uc5ec \ub3d9\uc801\uc73c\ub85c \uc2e4\ud589 \uc5ec\ubd80\ub97c \uacb0\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, ScheduleEvaluationContext, RunRequest\nfrom datetime import datetime\n\n@schedule(\n    job=daily_job,\n    cron_schedule="0 0 * * *",\n)\ndef conditional_schedule(context: ScheduleEvaluationContext):\n    """\uc870\uac74\ubd80\ub85c \uc2e4\ud589\ub418\ub294 \uc2a4\ucf00\uc904"""\n    scheduled_date = context.scheduled_execution_time\n\n    # \uc8fc\ub9d0\uc5d0\ub294 \uc2e4\ud589\ud558\uc9c0 \uc54a\uc74c\n    if scheduled_date.weekday() >= 5:  # \ud1a0\uc694\uc77c(5), \uc77c\uc694\uc77c(6)\n        context.log.info(f"Skipping weekend execution: {scheduled_date}")\n        return []\n\n    context.log.info(f"Running scheduled job for {scheduled_date}")\n    return RunRequest(\n        run_key=f"daily_{scheduled_date.strftime(\'%Y%m%d\')}",\n        tags={\n            "date": scheduled_date.strftime("%Y-%m-%d"),\n            "day_of_week": scheduled_date.strftime("%A"),\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2a4\ucf00\uc904-\uc124\uc815-\uc635\uc158",children:"\uc2a4\ucf00\uc904 \uc124\uc815 \uc635\uc158"}),"\n",(0,r.jsx)(e.p,{children:"\uc2a4\ucf00\uc904 \uc815\uc758 \uc2dc \ub2e4\uc591\ud55c \uc635\uc158\uc744 \uc124\uc815\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, DefaultScheduleStatus\n\n@schedule(\n    job=daily_job,\n    cron_schedule="0 0 * * *",\n    execution_timezone="Asia/Seoul",  # \uc2dc\uac04\ub300 \uc124\uc815\n    default_status=DefaultScheduleStatus.RUNNING,  # \uae30\ubcf8\uc801\uc73c\ub85c \ud65c\uc131\ud654\n    description="\ub9e4\uc77c \uc790\uc815\uc5d0 \uc2e4\ud589\ub418\ub294 \ub370\uc774\ud130 \ucc98\ub9ac \uc2a4\ucf00\uc904",\n)\ndef configured_schedule(context: ScheduleEvaluationContext):\n    """\ub2e4\uc591\ud55c \uc635\uc158\uc774 \uc124\uc815\ub41c \uc2a4\ucf00\uc904"""\n    return RunRequest(\n        run_config={\n            "ops": {\n                "process_daily_data": {\n                    "config": {\n                        "execution_date": context.scheduled_execution_time.strftime("%Y-%m-%d")\n                    }\n                }\n            }\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h2,{id:"32-cron-\uc2a4\ucf00\uc904",children:"3.2 Cron \uc2a4\ucf00\uc904"}),"\n",(0,r.jsx)(e.p,{children:"Cron \ud45c\ud604\uc2dd\uc740 \uc2a4\ucf00\uc904\uc758 \uc2e4\ud589 \uc8fc\uae30\ub97c \uc815\uc758\ud558\ub294 \ud45c\uc900 \ubc29\uc2dd\uc785\ub2c8\ub2e4. Dagster\ub294 \ud45c\uc900 Unix Cron \ud615\uc2dd\uc744 \uc0ac\uc6a9\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"cron-\ud45c\ud604\uc2dd-\uad6c\uc870",children:"Cron \ud45c\ud604\uc2dd \uad6c\uc870"}),"\n",(0,r.jsx)(e.p,{children:"Cron \ud45c\ud604\uc2dd\uc740 5\uac1c\uc758 \ud544\ub4dc\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \ubd84 (0 - 59)\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \uc2dc (0 - 23)\n\u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \uc77c (1 - 31)\n\u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \uc6d4 (1 - 12)\n\u2502 \u2502 \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 \uc694\uc77c (0 - 6) (\uc77c\uc694\uc77c=0)\n\u2502 \u2502 \u2502 \u2502 \u2502\n* * * * *\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\uc77c\ubc18\uc801\uc778-cron-\ud328\ud134",children:"\uc77c\ubc18\uc801\uc778 Cron \ud328\ud134"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, job\n\n# \ub9e4\uc2dc\uac04 \uc815\uac01\n@schedule(job=hourly_job, cron_schedule="0 * * * *")\ndef every_hour_schedule():\n    return RunRequest()\n\n# \ub9e4\uc77c \uc624\uc804 9\uc2dc\n@schedule(job=morning_job, cron_schedule="0 9 * * *")\ndef every_morning_schedule():\n    return RunRequest()\n\n# \ub9e4\uc8fc \uc6d4\uc694\uc77c \uc624\uc804 9\uc2dc\n@schedule(job=weekly_job, cron_schedule="0 9 * * 1")\ndef every_monday_schedule():\n    return RunRequest()\n\n# \ub9e4\uc6d4 1\uc77c \uc624\uc804 9\uc2dc\n@schedule(job=monthly_job, cron_schedule="0 9 1 * *")\ndef first_of_month_schedule():\n    return RunRequest()\n\n# \ud3c9\uc77c \ub9e4\uc77c \uc624\uc804 9\uc2dc\n@schedule(job=weekday_job, cron_schedule="0 9 * * 1-5")\ndef weekday_schedule():\n    return RunRequest()\n\n# 15\ubd84\ub9c8\ub2e4\n@schedule(job=frequent_job, cron_schedule="*/15 * * * *")\ndef every_15_minutes_schedule():\n    return RunRequest()\n\n# \ub9e4\uc77c \uc624\uc804 6\uc2dc, \uc815\uc624, \uc624\ud6c4 6\uc2dc\n@schedule(job=three_times_job, cron_schedule="0 6,12,18 * * *")\ndef three_times_daily_schedule():\n    return RunRequest()\n\n# \ub9e4 2\uc2dc\uac04\ub9c8\ub2e4\n@schedule(job=two_hour_job, cron_schedule="0 */2 * * *")\ndef every_two_hours_schedule():\n    return RunRequest()\n\n# \ubd84\uae30\ubcc4 \uccab\ub0a0 (1\uc6d4, 4\uc6d4, 7\uc6d4, 10\uc6d4 1\uc77c \uc624\uc804 9\uc2dc)\n@schedule(job=quarterly_job, cron_schedule="0 9 1 1,4,7,10 *")\ndef quarterly_schedule():\n    return RunRequest()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"cron-\ud5ec\ud37c-\ud568\uc218",children:"Cron \ud5ec\ud37c \ud568\uc218"}),"\n",(0,r.jsx)(e.p,{children:"Dagster\ub294 \uc77c\ubc18\uc801\uc778 \uc2a4\ucf00\uc904 \ud328\ud134\uc744 \uc704\ud55c \ud5ec\ud37c \ud568\uc218\ub97c \uc81c\uacf5\ud569\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    schedule,\n    ScheduleDefinition,\n    build_schedule_from_partitioned_job,\n)\n\n# \uc2dc\uac04\ubcc4 \uc2a4\ucf00\uc904\n@schedule(\n    job=hourly_job,\n    cron_schedule="@hourly",  # "0 * * * *"\uc640 \ub3d9\uc77c\n)\ndef hourly_schedule():\n    return RunRequest()\n\n# \uc77c\uc77c \uc2a4\ucf00\uc904\n@schedule(\n    job=daily_job,\n    cron_schedule="@daily",  # "0 0 * * *"\uc640 \ub3d9\uc77c\n)\ndef daily_schedule():\n    return RunRequest()\n\n# \uc8fc\uac04 \uc2a4\ucf00\uc904\n@schedule(\n    job=weekly_job,\n    cron_schedule="@weekly",  # "0 0 * * 0"\uc640 \ub3d9\uc77c\n)\ndef weekly_schedule():\n    return RunRequest()\n\n# \uc6d4\uac04 \uc2a4\ucf00\uc904\n@schedule(\n    job=monthly_job,\n    cron_schedule="@monthly",  # "0 0 1 * *"\uc640 \ub3d9\uc77c\n)\ndef monthly_schedule():\n    return RunRequest()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ubcf5\uc7a1\ud55c-cron-\ud328\ud134-\uc608\uc81c",children:"\ubcf5\uc7a1\ud55c Cron \ud328\ud134 \uc608\uc81c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, ScheduleEvaluationContext, RunRequest\nfrom datetime import datetime\n\n@schedule(\n    job=complex_job,\n    cron_schedule="30 9-17 * * 1-5",  # \ud3c9\uc77c \uc624\uc804 9:30\ubd80\ud130 \uc624\ud6c4 5:30\uae4c\uc9c0 \ub9e4\uc2dc\uac04\n    execution_timezone="Asia/Seoul",\n)\ndef business_hours_schedule(context: ScheduleEvaluationContext):\n    """\uc5c5\ubb34 \uc2dc\uac04 \ub3d9\uc548 \ub9e4\uc2dc\uac04 \uc2e4\ud589"""\n    hour = context.scheduled_execution_time.hour\n\n    return RunRequest(\n        run_config={\n            "ops": {\n                "process_data": {\n                    "config": {\n                        "hour": hour,\n                        "is_peak_hour": hour in [9, 12, 15, 17]\n                    }\n                }\n            }\n        },\n        tags={\n            "hour": str(hour),\n            "business_hours": "true"\n        }\n    )\n\n@schedule(\n    job=backup_job,\n    cron_schedule="0 2 * * 0,3",  # \uc218\uc694\uc77c\uacfc \uc77c\uc694\uc77c \uc0c8\ubcbd 2\uc2dc\n    execution_timezone="Asia/Seoul",\n)\ndef biweekly_backup_schedule(context: ScheduleEvaluationContext):\n    """\uc8fc 2\ud68c \ubc31\uc5c5 \uc2a4\ucf00\uc904"""\n    date = context.scheduled_execution_time\n\n    return RunRequest(\n        run_key=f"backup_{date.strftime(\'%Y%m%d\')}",\n        run_config={\n            "ops": {\n                "backup": {\n                    "config": {\n                        "backup_type": "full" if date.weekday() == 6 else "incremental",\n                        "timestamp": date.isoformat()\n                    }\n                }\n            }\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2dc\uac04\ub300-\ucc98\ub9ac",children:"\uc2dc\uac04\ub300 \ucc98\ub9ac"}),"\n",(0,r.jsx)(e.p,{children:"\uc2a4\ucf00\uc904\uc740 \uc2dc\uac04\ub300\ub97c \uace0\ub824\ud558\uc5ec \uc2e4\ud589\ub429\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule\n\n# UTC \uae30\uc900\n@schedule(\n    job=utc_job,\n    cron_schedule="0 0 * * *",\n    execution_timezone="UTC",\n)\ndef utc_schedule():\n    """UTC \uc790\uc815\uc5d0 \uc2e4\ud589"""\n    return RunRequest()\n\n# \ud55c\uad6d \uc2dc\uac04 \uae30\uc900\n@schedule(\n    job=kst_job,\n    cron_schedule="0 0 * * *",\n    execution_timezone="Asia/Seoul",\n)\ndef kst_schedule():\n    """\ud55c\uad6d \uc2dc\uac04 \uc790\uc815\uc5d0 \uc2e4\ud589"""\n    return RunRequest()\n\n# \ub274\uc695 \uc2dc\uac04 \uae30\uc900\n@schedule(\n    job=est_job,\n    cron_schedule="0 9 * * 1-5",\n    execution_timezone="America/New_York",\n)\ndef est_business_schedule():\n    """\ub274\uc695 \uc2dc\uac04 \ud3c9\uc77c \uc624\uc804 9\uc2dc\uc5d0 \uc2e4\ud589"""\n    return RunRequest()\n'})}),"\n",(0,r.jsx)(e.h2,{id:"33-partitioned-schedule",children:"3.3 Partitioned Schedule"}),"\n",(0,r.jsx)(e.p,{children:"\ud30c\ud2f0\uc158\ub41c \uc2a4\ucf00\uc904\uc740 \uc2dc\uac04 \uae30\ubc18 \ud30c\ud2f0\uc158\uacfc \uc790\ub3d9\uc73c\ub85c \uc5f0\ub3d9\ub418\uc5b4 \uac01 \ud30c\ud2f0\uc158\uc744 \uc21c\ucc28\uc801\uc73c\ub85c \ucc98\ub9ac\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\uae30\ubcf8-partitioned-schedule",children:"\uae30\ubcf8 Partitioned Schedule"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    asset,\n    DailyPartitionsDefinition,\n    build_schedule_from_partitioned_job,\n    define_asset_job,\n    AssetSelection,\n)\nfrom datetime import datetime\n\n# \uc77c\uc77c \ud30c\ud2f0\uc158 \uc815\uc758\ndaily_partitions = DailyPartitionsDefinition(\n    start_date="2024-01-01",\n    timezone="Asia/Seoul",\n)\n\n@asset(partitions_def=daily_partitions)\ndef daily_sales_data(context):\n    """\uc77c\uc77c \ub9e4\ucd9c \ub370\uc774\ud130"""\n    partition_date = context.partition_key\n    context.log.info(f"Processing sales data for {partition_date}")\n\n    # \ud574\ub2f9 \ub0a0\uc9dc\uc758 \ub9e4\ucd9c \ub370\uc774\ud130 \ucc98\ub9ac\n    return {"date": partition_date, "sales": 100000}\n\n@asset(partitions_def=daily_partitions)\ndef daily_sales_report(context, daily_sales_data):\n    """\uc77c\uc77c \ub9e4\ucd9c \ub9ac\ud3ec\ud2b8"""\n    partition_date = context.partition_key\n    context.log.info(f"Generating report for {partition_date}")\n\n    return {\n        "date": partition_date,\n        "report": f"Sales report for {daily_sales_data[\'date\']}"\n    }\n\n# \ud30c\ud2f0\uc158\ub41c job \uc815\uc758\ndaily_sales_job = define_asset_job(\n    name="daily_sales_job",\n    selection=AssetSelection.assets(daily_sales_data, daily_sales_report),\n    partitions_def=daily_partitions,\n)\n\n# \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904 \uc790\ub3d9 \uc0dd\uc131\ndaily_sales_schedule = build_schedule_from_partitioned_job(\n    daily_sales_job,\n    hour_of_day=1,  # \uc0c8\ubcbd 1\uc2dc\n    minute_of_day=0,\n    timezone="Asia/Seoul",\n)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc8fc\uac04-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",children:"\uc8fc\uac04 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import WeeklyPartitionsDefinition\n\n# \uc8fc\uac04 \ud30c\ud2f0\uc158 \uc815\uc758\nweekly_partitions = WeeklyPartitionsDefinition(\n    start_date="2024-01-01",\n    timezone="Asia/Seoul",\n    day_offset=0,  # 0=\uc6d4\uc694\uc77c \uc2dc\uc791\n)\n\n@asset(partitions_def=weekly_partitions)\ndef weekly_user_metrics(context):\n    """\uc8fc\uac04 \uc0ac\uc6a9\uc790 \uc9c0\ud45c"""\n    week_start = context.partition_key\n    context.log.info(f"Processing metrics for week starting {week_start}")\n\n    return {\n        "week": week_start,\n        "active_users": 5000,\n        "new_users": 500\n    }\n\n# \uc8fc\uac04 job\nweekly_metrics_job = define_asset_job(\n    name="weekly_metrics_job",\n    selection=AssetSelection.assets(weekly_user_metrics),\n    partitions_def=weekly_partitions,\n)\n\n# \ub9e4\uc8fc \uc6d4\uc694\uc77c \uc624\uc804 2\uc2dc\uc5d0 \uc2e4\ud589\nweekly_metrics_schedule = build_schedule_from_partitioned_job(\n    weekly_metrics_job,\n    hour_of_day=2,\n    minute_of_day=0,\n    timezone="Asia/Seoul",\n)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc6d4\uac04-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",children:"\uc6d4\uac04 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import MonthlyPartitionsDefinition\n\n# \uc6d4\uac04 \ud30c\ud2f0\uc158 \uc815\uc758\nmonthly_partitions = MonthlyPartitionsDefinition(\n    start_date="2024-01-01",\n    timezone="Asia/Seoul",\n)\n\n@asset(partitions_def=monthly_partitions)\ndef monthly_revenue_summary(context):\n    """\uc6d4\uac04 \uc218\uc775 \uc694\uc57d"""\n    month = context.partition_key\n    context.log.info(f"Processing revenue summary for {month}")\n\n    return {\n        "month": month,\n        "revenue": 30000000,\n        "expenses": 20000000,\n        "profit": 10000000\n    }\n\n@asset(partitions_def=monthly_partitions)\ndef monthly_executive_report(context, monthly_revenue_summary):\n    """\uc6d4\uac04 \uacbd\uc601\uc9c4 \ub9ac\ud3ec\ud2b8"""\n    month = context.partition_key\n\n    return {\n        "month": month,\n        "report": f"Executive report for {monthly_revenue_summary[\'month\']}",\n        "profit_margin": monthly_revenue_summary[\'profit\'] / monthly_revenue_summary[\'revenue\']\n    }\n\n# \uc6d4\uac04 job\nmonthly_report_job = define_asset_job(\n    name="monthly_report_job",\n    selection=AssetSelection.all(),\n    partitions_def=monthly_partitions,\n)\n\n# \ub9e4\uc6d4 1\uc77c \uc624\uc804 3\uc2dc\uc5d0 \uc2e4\ud589\nmonthly_report_schedule = build_schedule_from_partitioned_job(\n    monthly_report_job,\n    hour_of_day=3,\n    minute_of_day=0,\n    timezone="Asia/Seoul",\n)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2dc\uac04\ubcc4-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",children:"\uc2dc\uac04\ubcc4 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import HourlyPartitionsDefinition\n\n# \uc2dc\uac04\ubcc4 \ud30c\ud2f0\uc158\nhourly_partitions = HourlyPartitionsDefinition(\n    start_date="2024-01-01-00:00",\n    timezone="Asia/Seoul",\n)\n\n@asset(partitions_def=hourly_partitions)\ndef hourly_api_logs(context):\n    """\uc2dc\uac04\ubcc4 API \ub85c\uadf8 \uc9d1\uacc4"""\n    hour = context.partition_key\n    context.log.info(f"Processing API logs for {hour}")\n\n    return {\n        "hour": hour,\n        "requests": 10000,\n        "errors": 50,\n        "avg_response_time": 250\n    }\n\nhourly_logs_job = define_asset_job(\n    name="hourly_logs_job",\n    selection=AssetSelection.assets(hourly_api_logs),\n    partitions_def=hourly_partitions,\n)\n\n# \ub9e4\uc2dc\uac04 5\ubd84\uc5d0 \uc2e4\ud589\nhourly_logs_schedule = build_schedule_from_partitioned_job(\n    hourly_logs_job,\n    minute_of_hour=5,\n    timezone="Asia/Seoul",\n)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ucee4\uc2a4\ud140-\ud30c\ud2f0\uc158-\uc2a4\ucf00\uc904",children:"\ucee4\uc2a4\ud140 \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, ScheduleEvaluationContext, RunRequest\n\n@schedule(\n    job=daily_sales_job,\n    cron_schedule="0 1 * * *",\n    execution_timezone="Asia/Seoul",\n)\ndef custom_partitioned_schedule(context: ScheduleEvaluationContext):\n    """\ucee4\uc2a4\ud140 \ub85c\uc9c1\uc774 \ud3ec\ud568\ub41c \ud30c\ud2f0\uc158 \uc2a4\ucf00\uc904"""\n    from datetime import timedelta\n\n    # \uc804\ub0a0 \ud30c\ud2f0\uc158 \uc2e4\ud589\n    scheduled_date = context.scheduled_execution_time\n    partition_date = (scheduled_date - timedelta(days=1)).strftime("%Y-%m-%d")\n\n    # \ud2b9\uc815 \uc870\uac74\uc5d0\uc11c\ub9cc \uc2e4\ud589\n    if scheduled_date.day == 1:\n        # \uc6d4\ucd08\uc5d0\ub294 \uc804\uc6d4 \uc804\uccb4 \uc7ac\ucc98\ub9ac\n        context.log.info("Running monthly reconciliation")\n        return [\n            RunRequest(\n                partition_key=partition_date,\n                tags={"type": "monthly_reconciliation"}\n            )\n        ]\n\n    # \uc77c\ubc18\uc801\uc778 \uc77c\uc77c \ucc98\ub9ac\n    return RunRequest(\n        partition_key=partition_date,\n        tags={"type": "daily_processing"}\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ubc31\ud544backfill-\uc2a4\ucf00\uc904",children:"\ubc31\ud544(Backfill) \uc2a4\ucf00\uc904"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import schedule, ScheduleEvaluationContext, RunRequest\nfrom datetime import datetime, timedelta\n\n@schedule(\n    job=daily_sales_job,\n    cron_schedule="0 2 * * 0",  # \ub9e4\uc8fc \uc77c\uc694\uc77c \uc0c8\ubcbd 2\uc2dc\n    execution_timezone="Asia/Seoul",\n)\ndef weekly_backfill_schedule(context: ScheduleEvaluationContext):\n    """\uc8fc\uac04 \ubc31\ud544 \uc2a4\ucf00\uc904 - \uc9c0\ub09c \uc8fc \ub370\uc774\ud130 \uc7ac\ucc98\ub9ac"""\n    scheduled_date = context.scheduled_execution_time\n\n    # \uc9c0\ub09c 7\uc77c\uac04\uc758 \ud30c\ud2f0\uc158 \uc2e4\ud589\n    run_requests = []\n    for i in range(7):\n        partition_date = (scheduled_date - timedelta(days=i+1)).strftime("%Y-%m-%d")\n        run_requests.append(\n            RunRequest(\n                partition_key=partition_date,\n                run_key=f"backfill_{partition_date}",\n                tags={\n                    "type": "backfill",\n                    "week": scheduled_date.strftime("%Y-W%W")\n                }\n            )\n        )\n\n    return run_requests\n'})}),"\n",(0,r.jsx)(e.h2,{id:"34-sensor-\uac1c\ub150",children:"3.4 Sensor \uac1c\ub150"}),"\n",(0,r.jsx)(e.p,{children:"\uc13c\uc11c(Sensor)\ub294 \uc678\ubd80 \uc774\ubca4\ud2b8\ub098 \uc870\uac74\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud558\uc5ec job\uc744 \ud2b8\ub9ac\uac70\ud558\ub294 Dagster\uc758 \uc774\ubca4\ud2b8 \uae30\ubc18 \uc790\ub3d9\ud654 \uba54\ucee4\ub2c8\uc998\uc785\ub2c8\ub2e4. \uc2a4\ucf00\uc904\uacfc \ub2ec\ub9ac \uc2dc\uac04\uc774 \uc544\ub2cc \uc0c1\ud0dc \ubcc0\ud654\uc5d0 \ubc18\uc751\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\uae30\ubcf8-\uc13c\uc11c-\uc815\uc758",children:"\uae30\ubcf8 \uc13c\uc11c \uc815\uc758"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SensorEvaluationContext, job, op\nimport os\n\n@op\ndef process_new_file(context):\n    """\uc0c8 \ud30c\uc77c \ucc98\ub9ac"""\n    file_path = context.op_config["file_path"]\n    context.log.info(f"Processing file: {file_path}")\n    return file_path\n\n@job\ndef file_processing_job():\n    process_new_file()\n\n@sensor(\n    job=file_processing_job,\n    minimum_interval_seconds=30,  # \ucd5c\uc18c 30\ucd08 \uac04\uaca9\uc73c\ub85c \uccb4\ud06c\n)\ndef new_file_sensor(context: SensorEvaluationContext):\n    """\uc0c8 \ud30c\uc77c\uc744 \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n    watch_directory = "/data/incoming"\n\n    # \ub514\ub809\ud1a0\ub9ac\uc758 \ud30c\uc77c \ubaa9\ub85d \ud655\uc778\n    if not os.path.exists(watch_directory):\n        return\n\n    files = os.listdir(watch_directory)\n\n    for file_name in files:\n        if file_name.endswith(".csv"):\n            file_path = os.path.join(watch_directory, file_name)\n\n            # \uc774\ubbf8 \ucc98\ub9ac\ud55c \ud30c\uc77c\uc778\uc9c0 \ud655\uc778\n            cursor_key = f"processed_{file_name}"\n            if context.cursor == cursor_key:\n                continue\n\n            # \uc0c8 \ud30c\uc77c \ucc98\ub9ac \uc694\uccad\n            yield RunRequest(\n                run_key=file_name,\n                run_config={\n                    "ops": {\n                        "process_new_file": {\n                            "config": {"file_path": file_path}\n                        }\n                    }\n                },\n                tags={"file_name": file_name}\n            )\n\n            # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n            context.update_cursor(cursor_key)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc13c\uc11c\uc758-\uc8fc\uc694-\uad6c\uc131\uc694\uc18c",children:"\uc13c\uc11c\uc758 \uc8fc\uc694 \uad6c\uc131\uc694\uc18c"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Job \ucc38\uc870"}),": \ud2b8\ub9ac\uac70\ud560 job \uc9c0\uc815"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\ud3c9\uac00 \ud568\uc218"}),": \uc13c\uc11c\uac00 \uc2e4\ud589\ub420 \ub54c \ud638\ucd9c\ub418\ub294 \ud568\uc218"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Cursor"}),": \uc13c\uc11c\uc758 \uc0c1\ud0dc\ub97c \ucd94\uc801\ud558\ub294 \uba54\ucee4\ub2c8\uc998"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RunRequest"}),": \uc2e4\ud589 \uc694\uccad\uc744 \uc0dd\uc131\ud558\uc5ec yield"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\ud3c9\uac00 \uac04\uaca9"}),": \uc13c\uc11c\uac00 \uc2e4\ud589\ub418\ub294 \ucd5c\uc18c \uac04\uaca9"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"cursor\ub97c-\uc0ac\uc6a9\ud55c-\uc0c1\ud0dc-\ucd94\uc801",children:"Cursor\ub97c \uc0ac\uc6a9\ud55c \uc0c1\ud0dc \ucd94\uc801"}),"\n",(0,r.jsx)(e.p,{children:"\ucee4\uc11c\ub294 \uc13c\uc11c\uac00 \ub9c8\uc9c0\ub9c9\uc73c\ub85c \ucc98\ub9ac\ud55c \uc2dc\uc810\uc744 \ucd94\uc801\ud569\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SensorEvaluationContext\nfrom datetime import datetime\nimport json\n\n@sensor(\n    job=data_processing_job,\n    minimum_interval_seconds=60,\n)\ndef incremental_data_sensor(context: SensorEvaluationContext):\n    """\uc99d\ubd84 \ub370\uc774\ud130\ub97c \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n\n    # \ucee4\uc11c\uc5d0\uc11c \ub9c8\uc9c0\ub9c9 \ucc98\ub9ac \uc2dc\uac04 \ub85c\ub4dc\n    last_processed_time = context.cursor\n    if last_processed_time:\n        last_time = datetime.fromisoformat(last_processed_time)\n        context.log.info(f"Last processed: {last_time}")\n    else:\n        # \uccab \uc2e4\ud589\uc2dc \uae30\ubcf8 \uc2dc\uc791 \uc2dc\uac04\n        last_time = datetime(2024, 1, 1)\n\n    # \uc0c8\ub85c\uc6b4 \ub370\uc774\ud130 \ud655\uc778 (\uc608: \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ucffc\ub9ac)\n    current_time = datetime.now()\n    new_records = check_new_records(last_time, current_time)\n\n    if new_records:\n        context.log.info(f"Found {len(new_records)} new records")\n\n        yield RunRequest(\n            run_key=f"data_{current_time.isoformat()}",\n            run_config={\n                "ops": {\n                    "process_data": {\n                        "config": {\n                            "start_time": last_time.isoformat(),\n                            "end_time": current_time.isoformat(),\n                            "record_count": len(new_records)\n                        }\n                    }\n                }\n            }\n        )\n\n        # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n        context.update_cursor(current_time.isoformat())\n\ndef check_new_records(start_time, end_time):\n    """\uc0c8\ub85c\uc6b4 \ub808\ucf54\ub4dc\ub97c \ud655\uc778\ud558\ub294 \ud5ec\ud37c \ud568\uc218"""\n    # \uc2e4\uc81c \uad6c\ud604\uc5d0\uc11c\ub294 \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ucffc\ub9ac \ub4f1\uc744 \uc218\ud589\n    return []\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ub2e4\uc911-runrequest",children:"\ub2e4\uc911 RunRequest"}),"\n",(0,r.jsx)(e.p,{children:"\uc13c\uc11c\ub294 \ud55c \ubc88\uc758 \ud3c9\uac00\uc5d0\uc11c \uc5ec\ub7ec RunRequest\ub97c \uc0dd\uc131\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@sensor(\n    job=file_processing_job,\n    minimum_interval_seconds=60,\n)\ndef batch_file_sensor(context: SensorEvaluationContext):\n    """\uc5ec\ub7ec \ud30c\uc77c\uc744 \ud55c \ubc88\uc5d0 \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n    watch_directory = "/data/batch"\n\n    # \ucc98\ub9ac\ub41c \ud30c\uc77c \ubaa9\ub85d \ub85c\ub4dc\n    processed_files = set()\n    if context.cursor:\n        processed_files = set(json.loads(context.cursor))\n\n    # \uc0c8 \ud30c\uc77c \ud655\uc778\n    current_files = set(os.listdir(watch_directory))\n    new_files = current_files - processed_files\n\n    if new_files:\n        context.log.info(f"Found {len(new_files)} new files")\n\n        # \uac01 \ud30c\uc77c\uc5d0 \ub300\ud574 RunRequest \uc0dd\uc131\n        for file_name in new_files:\n            yield RunRequest(\n                run_key=file_name,\n                run_config={\n                    "ops": {\n                        "process_new_file": {\n                            "config": {\n                                "file_path": os.path.join(watch_directory, file_name)\n                            }\n                        }\n                    }\n                },\n                tags={"file": file_name, "batch": "true"}\n            )\n\n        # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n        updated_files = processed_files.union(new_files)\n        context.update_cursor(json.dumps(list(updated_files)))\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc13c\uc11c-\uc124\uc815-\uc635\uc158",children:"\uc13c\uc11c \uc124\uc815 \uc635\uc158"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, DefaultSensorStatus\n\n@sensor(\n    job=monitoring_job,\n    minimum_interval_seconds=10,  # \ucd5c\uc18c \ud3c9\uac00 \uac04\uaca9\n    description="\uc2dc\uc2a4\ud15c \uba54\ud2b8\ub9ad\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uc13c\uc11c",\n    default_status=DefaultSensorStatus.RUNNING,  # \uae30\ubcf8\uc801\uc73c\ub85c \ud65c\uc131\ud654\n)\ndef system_monitoring_sensor(context: SensorEvaluationContext):\n    """\uc2dc\uc2a4\ud15c \ubaa8\ub2c8\ud130\ub9c1 \uc13c\uc11c"""\n\n    # \uc2dc\uc2a4\ud15c \uba54\ud2b8\ub9ad \ud655\uc778\n    cpu_usage = get_cpu_usage()\n    memory_usage = get_memory_usage()\n\n    # \uc784\uacc4\uac12 \ucd08\uacfc \uc2dc job \ud2b8\ub9ac\uac70\n    if cpu_usage > 80 or memory_usage > 90:\n        context.log.warning(\n            f"High resource usage detected - CPU: {cpu_usage}%, Memory: {memory_usage}%"\n        )\n\n        yield RunRequest(\n            run_key=f"alert_{datetime.now().isoformat()}",\n            run_config={\n                "ops": {\n                    "send_alert": {\n                        "config": {\n                            "cpu_usage": cpu_usage,\n                            "memory_usage": memory_usage,\n                            "severity": "high"\n                        }\n                    }\n                }\n            },\n            tags={"alert_type": "resource_usage"}\n        )\n\ndef get_cpu_usage():\n    """CPU \uc0ac\uc6a9\ub960 \uc870\ud68c"""\n    return 75.0\n\ndef get_memory_usage():\n    """\uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub960 \uc870\ud68c"""\n    return 85.0\n'})}),"\n",(0,r.jsx)(e.h2,{id:"35-asset-sensor",children:"3.5 Asset Sensor"}),"\n",(0,r.jsx)(e.p,{children:"Asset Sensor\ub294 \ud2b9\uc815 asset\uc758 materialization\uc744 \uac10\uc9c0\ud558\uc5ec downstream \uc791\uc5c5\uc744 \ud2b8\ub9ac\uac70\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\uae30\ubcf8-asset-sensor",children:"\uae30\ubcf8 Asset Sensor"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    asset,\n    asset_sensor,\n    AssetKey,\n    EventLogEntry,\n    SensorEvaluationContext,\n    RunRequest,\n)\n\n@asset\ndef source_data():\n    """\uc18c\uc2a4 \ub370\uc774\ud130 asset"""\n    return {"data": [1, 2, 3, 4, 5]}\n\n@asset\ndef processed_data(source_data):\n    """\ucc98\ub9ac\ub41c \ub370\uc774\ud130 asset"""\n    return {"processed": sum(source_data["data"])}\n\n@asset_sensor(\n    asset_key=AssetKey("source_data"),\n    job=downstream_job,\n)\ndef source_data_sensor(context: SensorEvaluationContext, asset_event: EventLogEntry):\n    """source_data\uac00 \uc5c5\ub370\uc774\ud2b8\ub418\uba74 \ud2b8\ub9ac\uac70\ub418\ub294 \uc13c\uc11c"""\n\n    context.log.info(f"Source data was updated: {asset_event}")\n\n    yield RunRequest(\n        run_key=f"source_update_{asset_event.dagster_event.event_specific_data.materialization.metadata.get(\'run_id\')}",\n        tags={\n            "triggered_by": "source_data",\n            "event_id": str(asset_event.dagster_event_type)\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ub2e4\uc911-asset-\ubaa8\ub2c8\ud130\ub9c1",children:"\ub2e4\uc911 Asset \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import MultiAssetSensorEvaluationContext, multi_asset_sensor\n\n@asset\ndef sales_data():\n    """\ub9e4\ucd9c \ub370\uc774\ud130"""\n    return {"sales": 100000}\n\n@asset\ndef inventory_data():\n    """\uc7ac\uace0 \ub370\uc774\ud130"""\n    return {"inventory": 5000}\n\n@asset\ndef customer_data():\n    """\uace0\uac1d \ub370\uc774\ud130"""\n    return {"customers": 1000}\n\n@multi_asset_sensor(\n    monitored_assets=[\n        AssetKey("sales_data"),\n        AssetKey("inventory_data"),\n        AssetKey("customer_data"),\n    ],\n    job=analytics_job,\n)\ndef multi_data_sensor(context: MultiAssetSensorEvaluationContext):\n    """\uc5ec\ub7ec asset\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uc13c\uc11c"""\n\n    # \uac01 asset\uc758 \ucd5c\uc2e0 materialization \ud655\uc778\n    asset_events = context.latest_materialization_records_by_key()\n\n    all_assets_updated = all(\n        asset_key in asset_events\n        for asset_key in [\n            AssetKey("sales_data"),\n            AssetKey("inventory_data"),\n            AssetKey("customer_data"),\n        ]\n    )\n\n    if all_assets_updated:\n        context.log.info("All required assets have been updated")\n\n        # \ucee4\uc11c \ud655\uc778 - \uc774\ubbf8 \ucc98\ub9ac\ud588\ub294\uc9c0 \uac80\uc99d\n        cursor_data = {}\n        if context.cursor:\n            cursor_data = json.loads(context.cursor)\n\n        # \uac01 asset\uc758 \ud0c0\uc784\uc2a4\ud0ec\ud504 \ud655\uc778\n        current_timestamps = {\n            str(asset_key): event.event_log_entry.timestamp\n            for asset_key, event in asset_events.items()\n        }\n\n        # \uc0c8\ub85c\uc6b4 \uc5c5\ub370\uc774\ud2b8\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n        if current_timestamps != cursor_data:\n            yield RunRequest(\n                run_key=f"analytics_{datetime.now().isoformat()}",\n                tags={\n                    "triggered_assets": ",".join(str(k) for k in asset_events.keys())\n                }\n            )\n\n            # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n            context.update_cursor(json.dumps(current_timestamps))\n'})}),"\n",(0,r.jsx)(e.h3,{id:"asset-materialization-\uba54\ud0c0\ub370\uc774\ud130-\ud65c\uc6a9",children:"Asset Materialization \uba54\ud0c0\ub370\uc774\ud130 \ud65c\uc6a9"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import MetadataValue\n\n@asset\ndef data_with_metadata():\n    """\uba54\ud0c0\ub370\uc774\ud130\ub97c \ud3ec\ud568\ud55c \ub370\uc774\ud130"""\n    return {"value": 42}\n\n@asset_sensor(\n    asset_key=AssetKey("data_with_metadata"),\n    job=validation_job,\n)\ndef metadata_based_sensor(context: SensorEvaluationContext, asset_event: EventLogEntry):\n    """\uba54\ud0c0\ub370\uc774\ud130\ub97c \uae30\ubc18\uc73c\ub85c \uc870\uac74\ubd80 \ud2b8\ub9ac\uac70"""\n\n    # materialization \uba54\ud0c0\ub370\uc774\ud130 \ucd94\ucd9c\n    materialization = asset_event.dagster_event.event_specific_data.materialization\n    metadata = materialization.metadata\n\n    # \uba54\ud0c0\ub370\uc774\ud130 \uae30\ubc18 \uc870\uac74 \ud655\uc778\n    row_count = metadata.get("row_count")\n    if row_count and row_count.value > 1000:\n        context.log.info(f"Large dataset detected: {row_count.value} rows")\n\n        yield RunRequest(\n            run_key=f"validation_{asset_event.run_id}",\n            run_config={\n                "ops": {\n                    "validate_data": {\n                        "config": {\n                            "row_count": row_count.value,\n                            "validation_level": "thorough"\n                        }\n                    }\n                }\n            },\n            tags={"validation_type": "large_dataset"}\n        )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"freshness-\uae30\ubc18-asset-sensor",children:"Freshness \uae30\ubc18 Asset Sensor"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import AssetSelection, define_asset_job\nfrom datetime import timedelta\n\n@asset\ndef upstream_data():\n    """\uc5c5\uc2a4\ud2b8\ub9bc \ub370\uc774\ud130"""\n    return {"timestamp": datetime.now().isoformat()}\n\nfreshness_check_job = define_asset_job(\n    name="freshness_check_job",\n    selection=AssetSelection.keys("upstream_data"),\n)\n\n@asset_sensor(\n    asset_key=AssetKey("upstream_data"),\n    job=freshness_check_job,\n)\ndef freshness_sensor(context: SensorEvaluationContext, asset_event: EventLogEntry):\n    """\ub370\uc774\ud130 freshness\ub97c \uccb4\ud06c\ud558\ub294 \uc13c\uc11c"""\n\n    # \ub9c8\uc9c0\ub9c9 materialization \uc2dc\uac04 \ud655\uc778\n    last_materialization_time = datetime.fromtimestamp(\n        asset_event.event_log_entry.timestamp\n    )\n\n    current_time = datetime.now()\n    time_since_update = current_time - last_materialization_time\n\n    # freshness \uc784\uacc4\uac12 (\uc608: 6\uc2dc\uac04)\n    freshness_threshold = timedelta(hours=6)\n\n    if time_since_update > freshness_threshold:\n        context.log.warning(\n            f"Data is stale: last updated {time_since_update} ago"\n        )\n\n        yield RunRequest(\n            run_key=f"freshness_alert_{current_time.isoformat()}",\n            tags={\n                "alert_type": "stale_data",\n                "hours_since_update": str(time_since_update.total_seconds() / 3600)\n            }\n        )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"partition-\uae30\ubc18-asset-sensor",children:"Partition \uae30\ubc18 Asset Sensor"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import DailyPartitionsDefinition\n\ndaily_partitions = DailyPartitionsDefinition(start_date="2024-01-01")\n\n@asset(partitions_def=daily_partitions)\ndef daily_data(context):\n    """\uc77c\uc77c \ud30c\ud2f0\uc158 \ub370\uc774\ud130"""\n    partition_key = context.partition_key\n    return {"date": partition_key, "value": 100}\n\n@asset_sensor(\n    asset_key=AssetKey("daily_data"),\n    job=downstream_job,\n)\ndef partitioned_asset_sensor(context: SensorEvaluationContext, asset_event: EventLogEntry):\n    """\ud30c\ud2f0\uc158\ub41c asset\uc744 \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n\n    # \ud30c\ud2f0\uc158 \ud0a4 \ucd94\ucd9c\n    materialization = asset_event.dagster_event.event_specific_data.materialization\n    partition = materialization.partition\n\n    if partition:\n        context.log.info(f"New partition materialized: {partition}")\n\n        yield RunRequest(\n            run_key=f"downstream_{partition}",\n            tags={\n                "partition": partition,\n                "source": "daily_data"\n            }\n        )\n'})}),"\n",(0,r.jsx)(e.h2,{id:"36-run-status-sensor",children:"3.6 Run Status Sensor"}),"\n",(0,r.jsx)(e.p,{children:"Run Status Sensor\ub294 job \uc2e4\ud589\uc758 \uc131\uacf5, \uc2e4\ud328 \ub4f1 \uc0c1\ud0dc \ubcc0\ud654\ub97c \uac10\uc9c0\ud558\uc5ec \ud6c4\uc18d \uc791\uc5c5\uc744 \ud2b8\ub9ac\uac70\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\uae30\ubcf8-run-status-sensor",children:"\uae30\ubcf8 Run Status Sensor"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    run_status_sensor,\n    RunStatusSensorContext,\n    DagsterRunStatus,\n    RunRequest,\n)\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    request_job=cleanup_job,\n)\ndef on_success_sensor(context: RunStatusSensorContext):\n    """job \uc131\uacf5 \uc2dc \uc2e4\ud589\ub418\ub294 \uc13c\uc11c"""\n\n    dagster_run = context.dagster_run\n    context.log.info(f"Job {dagster_run.job_name} succeeded")\n\n    yield RunRequest(\n        run_key=f"cleanup_{dagster_run.run_id}",\n        run_config={\n            "ops": {\n                "cleanup": {\n                    "config": {\n                        "source_run_id": dagster_run.run_id,\n                        "job_name": dagster_run.job_name\n                    }\n                }\n            }\n        },\n        tags={\n            "triggered_by": dagster_run.job_name,\n            "source_run_id": dagster_run.run_id\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2e4\ud328-\uac10\uc9c0-\ubc0f-\uc54c\ub9bc",children:"\uc2e4\ud328 \uac10\uc9c0 \ubc0f \uc54c\ub9bc"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@run_status_sensor(\n    run_status=DagsterRunStatus.FAILURE,\n    request_job=alert_job,\n)\ndef on_failure_sensor(context: RunStatusSensorContext):\n    """job \uc2e4\ud328 \uc2dc \uc54c\ub9bc\uc744 \ubcf4\ub0b4\ub294 \uc13c\uc11c"""\n\n    dagster_run = context.dagster_run\n    failure_info = context.dagster_event\n\n    context.log.error(\n        f"Job {dagster_run.job_name} failed: Run ID {dagster_run.run_id}"\n    )\n\n    yield RunRequest(\n        run_key=f"alert_{dagster_run.run_id}",\n        run_config={\n            "ops": {\n                "send_alert": {\n                    "config": {\n                        "job_name": dagster_run.job_name,\n                        "run_id": dagster_run.run_id,\n                        "error_message": str(failure_info),\n                        "alert_channel": "slack",\n                        "severity": "high"\n                    }\n                }\n            }\n        },\n        tags={\n            "alert_type": "job_failure",\n            "failed_job": dagster_run.job_name\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ud2b9\uc815-job-\ubaa8\ub2c8\ud130\ub9c1",children:"\ud2b9\uc815 Job \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    monitored_jobs=[data_ingestion_job, data_processing_job],\n    request_job=downstream_job,\n)\ndef specific_job_sensor(context: RunStatusSensorContext):\n    """\ud2b9\uc815 job\ub4e4\uc758 \uc131\uacf5\uc744 \ubaa8\ub2c8\ud130\ub9c1"""\n\n    dagster_run = context.dagster_run\n    job_name = dagster_run.job_name\n\n    # \ucee4\uc11c\ub97c \uc0ac\uc6a9\ud558\uc5ec \ub450 job\uc774 \ubaa8\ub450 \uc644\ub8cc\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\n    completion_state = {}\n    if context.cursor:\n        completion_state = json.loads(context.cursor)\n\n    # \ud604\uc7ac job \uc644\ub8cc \uae30\ub85d\n    completion_state[job_name] = {\n        "run_id": dagster_run.run_id,\n        "timestamp": datetime.now().isoformat()\n    }\n\n    # \ubaa8\ub4e0 \ud544\uc218 job\uc774 \uc644\ub8cc\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\n    required_jobs = {"data_ingestion_job", "data_processing_job"}\n    completed_jobs = set(completion_state.keys())\n\n    if required_jobs.issubset(completed_jobs):\n        context.log.info("All required jobs completed, triggering downstream job")\n\n        yield RunRequest(\n            run_key=f"downstream_{datetime.now().isoformat()}",\n            tags={\n                "triggered_by": ",".join(required_jobs),\n                "completion_time": datetime.now().isoformat()\n            }\n        )\n\n        # \ucee4\uc11c \ucd08\uae30\ud654\n        context.update_cursor(json.dumps({}))\n    else:\n        # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n        context.update_cursor(json.dumps(completion_state))\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ub2e4\uc911-\uc0c1\ud0dc-\ubaa8\ub2c8\ud130\ub9c1",children:"\ub2e4\uc911 \uc0c1\ud0dc \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    request_job=success_handler_job,\n)\ndef success_handler_sensor(context: RunStatusSensorContext):\n    """\uc131\uacf5 \ucc98\ub9ac \uc13c\uc11c"""\n    dagster_run = context.dagster_run\n\n    yield RunRequest(\n        run_key=f"success_{dagster_run.run_id}",\n        tags={"status": "success", "original_job": dagster_run.job_name}\n    )\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.FAILURE,\n    request_job=failure_handler_job,\n)\ndef failure_handler_sensor(context: RunStatusSensorContext):\n    """\uc2e4\ud328 \ucc98\ub9ac \uc13c\uc11c"""\n    dagster_run = context.dagster_run\n\n    yield RunRequest(\n        run_key=f"failure_{dagster_run.run_id}",\n        tags={"status": "failure", "original_job": dagster_run.job_name}\n    )\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.CANCELED,\n    request_job=cancel_handler_job,\n)\ndef cancel_handler_sensor(context: RunStatusSensorContext):\n    """\ucde8\uc18c \ucc98\ub9ac \uc13c\uc11c"""\n    dagster_run = context.dagster_run\n\n    context.log.warning(f"Job {dagster_run.job_name} was canceled")\n\n    yield RunRequest(\n        run_key=f"cancel_{dagster_run.run_id}",\n        tags={"status": "canceled", "original_job": dagster_run.job_name}\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc7ac\uc2dc\ub3c4-\ub85c\uc9c1\uc774-\ud3ec\ud568\ub41c-run-status-sensor",children:"\uc7ac\uc2dc\ub3c4 \ub85c\uc9c1\uc774 \ud3ec\ud568\ub41c Run Status Sensor"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import SkipReason\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.FAILURE,\n    request_job=retry_job,\n)\ndef retry_sensor(context: RunStatusSensorContext):\n    """\uc2e4\ud328\ud55c job\uc744 \uc790\ub3d9\uc73c\ub85c \uc7ac\uc2dc\ub3c4\ud558\ub294 \uc13c\uc11c"""\n\n    dagster_run = context.dagster_run\n\n    # \ucee4\uc11c\uc5d0\uc11c \uc7ac\uc2dc\ub3c4 \ud69f\uc218 \ud655\uc778\n    retry_count = 0\n    if context.cursor:\n        cursor_data = json.loads(context.cursor)\n        retry_count = cursor_data.get(dagster_run.run_id, 0)\n\n    max_retries = 3\n\n    if retry_count < max_retries:\n        context.log.info(\n            f"Retrying {dagster_run.job_name} (attempt {retry_count + 1}/{max_retries})"\n        )\n\n        # \uc7ac\uc2dc\ub3c4 \uce74\uc6b4\ud2b8 \uc5c5\ub370\uc774\ud2b8\n        cursor_data = json.loads(context.cursor) if context.cursor else {}\n        cursor_data[dagster_run.run_id] = retry_count + 1\n        context.update_cursor(json.dumps(cursor_data))\n\n        yield RunRequest(\n            run_key=f"retry_{dagster_run.run_id}_{retry_count}",\n            run_config=dagster_run.run_config,  # \uc6d0\ub798 \uc124\uc815 \uc7ac\uc0ac\uc6a9\n            tags={\n                "retry_attempt": str(retry_count + 1),\n                "original_run_id": dagster_run.run_id\n            }\n        )\n    else:\n        context.log.error(\n            f"Max retries ({max_retries}) exceeded for {dagster_run.job_name}"\n        )\n        return SkipReason(f"Max retries exceeded for run {dagster_run.run_id}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2e4\ud589-\uc2dc\uac04-\uae30\ubc18-\uc54c\ub9bc",children:"\uc2e4\ud589 \uc2dc\uac04 \uae30\ubc18 \uc54c\ub9bc"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    request_job=performance_alert_job,\n)\ndef performance_sensor(context: RunStatusSensorContext):\n    """\uc2e4\ud589 \uc2dc\uac04\uc774 \uc624\ub798 \uac78\ub9b0 job\uc744 \uac10\uc9c0"""\n\n    dagster_run = context.dagster_run\n\n    # \uc2e4\ud589 \uc2dc\uac04 \uacc4\uc0b0\n    start_time = datetime.fromtimestamp(dagster_run.start_time)\n    end_time = datetime.fromtimestamp(dagster_run.end_time)\n    duration = (end_time - start_time).total_seconds()\n\n    # \uc784\uacc4\uac12 (\uc608: 1\uc2dc\uac04)\n    threshold_seconds = 3600\n\n    if duration > threshold_seconds:\n        context.log.warning(\n            f"Job {dagster_run.job_name} took {duration}s (threshold: {threshold_seconds}s)"\n        )\n\n        yield RunRequest(\n            run_key=f"perf_alert_{dagster_run.run_id}",\n            run_config={\n                "ops": {\n                    "send_performance_alert": {\n                        "config": {\n                            "job_name": dagster_run.job_name,\n                            "duration_seconds": duration,\n                            "threshold_seconds": threshold_seconds,\n                            "run_id": dagster_run.run_id\n                        }\n                    }\n                }\n            },\n            tags={\n                "alert_type": "slow_job",\n                "duration": str(duration)\n            }\n        )\n'})}),"\n",(0,r.jsx)(e.h2,{id:"37-\ucee4\uc2a4\ud140-sensor",children:"3.7 \ucee4\uc2a4\ud140 Sensor"}),"\n",(0,r.jsx)(e.p,{children:"\ucee4\uc2a4\ud140 \uc13c\uc11c\ub97c \ud1b5\ud574 \uc678\ubd80 API, \ub370\uc774\ud130\ubca0\uc774\uc2a4, \uba54\uc2dc\uc9c0 \ud050 \ub4f1 \ub2e4\uc591\ud55c \uc18c\uc2a4\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"api-\uae30\ubc18-\uc13c\uc11c",children:"API \uae30\ubc18 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SkipReason\nimport requests\n\n@sensor(\n    job=api_data_job,\n    minimum_interval_seconds=300,  # 5\ubd84\ub9c8\ub2e4 \uccb4\ud06c\n)\ndef api_sensor(context):\n    """\uc678\ubd80 API\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uc13c\uc11c"""\n\n    api_url = "https://api.example.com/data/status"\n\n    try:\n        response = requests.get(api_url, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n\n        # \uc0c8\ub85c\uc6b4 \ub370\uc774\ud130\uac00 \uc788\ub294\uc9c0 \ud655\uc778\n        latest_id = data.get("latest_id")\n\n        # \ucee4\uc11c\uc5d0\uc11c \ub9c8\uc9c0\ub9c9 \ucc98\ub9ac ID \ud655\uc778\n        last_processed_id = context.cursor\n\n        if latest_id and latest_id != last_processed_id:\n            context.log.info(f"New data available: ID {latest_id}")\n\n            yield RunRequest(\n                run_key=f"api_data_{latest_id}",\n                run_config={\n                    "ops": {\n                        "fetch_api_data": {\n                            "config": {\n                                "data_id": latest_id,\n                                "api_url": api_url\n                            }\n                        }\n                    }\n                },\n                tags={"data_id": str(latest_id)}\n            )\n\n            # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n            context.update_cursor(str(latest_id))\n        else:\n            return SkipReason("No new data available")\n\n    except requests.RequestException as e:\n        context.log.error(f"API request failed: {e}")\n        return SkipReason(f"API error: {str(e)}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ub370\uc774\ud130\ubca0\uc774\uc2a4-\uc13c\uc11c",children:"\ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import sqlite3\nfrom dagster import sensor, RunRequest\n\n@sensor(\n    job=database_sync_job,\n    minimum_interval_seconds=60,\n)\ndef database_sensor(context):\n    """\ub370\uc774\ud130\ubca0\uc774\uc2a4 \ubcc0\uacbd\uc0ac\ud56d\uc744 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uc13c\uc11c"""\n\n    # \ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc5f0\uacb0\n    conn = sqlite3.connect("/data/application.db")\n    cursor = conn.cursor()\n\n    try:\n        # \ub9c8\uc9c0\ub9c9 \uc5c5\ub370\uc774\ud2b8 \uc2dc\uac04 \ud655\uc778\n        last_check_time = context.cursor or "1970-01-01 00:00:00"\n\n        query = """\n            SELECT id, updated_at, table_name\n            FROM change_log\n            WHERE updated_at > ?\n            ORDER BY updated_at ASC\n        """\n\n        cursor.execute(query, (last_check_time,))\n        changes = cursor.fetchall()\n\n        if changes:\n            context.log.info(f"Found {len(changes)} database changes")\n\n            for change_id, updated_at, table_name in changes:\n                yield RunRequest(\n                    run_key=f"db_sync_{change_id}",\n                    run_config={\n                        "ops": {\n                            "sync_table": {\n                                "config": {\n                                    "table_name": table_name,\n                                    "change_id": change_id,\n                                    "updated_at": updated_at\n                                }\n                            }\n                        }\n                    },\n                    tags={\n                        "table": table_name,\n                        "change_id": str(change_id)\n                    }\n                )\n\n            # \ub9c8\uc9c0\ub9c9 \ubcc0\uacbd \uc2dc\uac04\uc73c\ub85c \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n            latest_update = changes[-1][1]\n            context.update_cursor(latest_update)\n        else:\n            return SkipReason("No database changes detected")\n\n    finally:\n        conn.close()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"s3-\ubc84\ud0b7-\uc13c\uc11c",children:"S3 \ubc84\ud0b7 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import boto3\nfrom dagster import sensor, RunRequest\n\n@sensor(\n    job=s3_processing_job,\n    minimum_interval_seconds=120,\n)\ndef s3_sensor(context):\n    """S3 \ubc84\ud0b7\uc758 \uc0c8 \ud30c\uc77c\uc744 \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n\n    bucket_name = "my-data-bucket"\n    prefix = "incoming/"\n\n    # S3 \ud074\ub77c\uc774\uc5b8\ud2b8 \ucd08\uae30\ud654\n    s3_client = boto3.client(\'s3\')\n\n    try:\n        # \ubc84\ud0b7 \ub0b4 \uac1d\uccb4 \ubaa9\ub85d \uc870\ud68c\n        response = s3_client.list_objects_v2(\n            Bucket=bucket_name,\n            Prefix=prefix\n        )\n\n        if \'Contents\' not in response:\n            return SkipReason("No files in bucket")\n\n        # \ucc98\ub9ac\ub41c \ud30c\uc77c \ubaa9\ub85d \ub85c\ub4dc\n        processed_files = set()\n        if context.cursor:\n            processed_files = set(json.loads(context.cursor))\n\n        new_files = []\n        for obj in response[\'Contents\']:\n            key = obj[\'Key\']\n\n            # \ud30c\uc77c\ub9cc \ucc98\ub9ac (\ud3f4\ub354 \uc81c\uc678)\n            if not key.endswith(\'/\') and key not in processed_files:\n                new_files.append({\n                    \'key\': key,\n                    \'size\': obj[\'Size\'],\n                    \'last_modified\': obj[\'LastModified\'].isoformat()\n                })\n\n        if new_files:\n            context.log.info(f"Found {len(new_files)} new files in S3")\n\n            for file_info in new_files:\n                yield RunRequest(\n                    run_key=f"s3_{file_info[\'key\'].replace(\'/\', \'_\')}",\n                    run_config={\n                        "ops": {\n                            "process_s3_file": {\n                                "config": {\n                                    "bucket": bucket_name,\n                                    "key": file_info[\'key\'],\n                                    "size": file_info[\'size\']\n                                }\n                            }\n                        }\n                    },\n                    tags={\n                        "source": "s3",\n                        "bucket": bucket_name,\n                        "file": file_info[\'key\']\n                    }\n                )\n\n            # \ucc98\ub9ac\ub41c \ud30c\uc77c \ubaa9\ub85d \uc5c5\ub370\uc774\ud2b8\n            processed_files.update(f[\'key\'] for f in new_files)\n            context.update_cursor(json.dumps(list(processed_files)))\n        else:\n            return SkipReason("No new files in S3")\n\n    except Exception as e:\n        context.log.error(f"S3 sensor error: {e}")\n        return SkipReason(f"S3 error: {str(e)}")\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uba54\uc2dc\uc9c0-\ud050-\uc13c\uc11c",children:"\uba54\uc2dc\uc9c0 \ud050 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import json\nfrom dagster import sensor, RunRequest\n# RabbitMQ \ub610\ub294 \ub2e4\ub978 \uba54\uc2dc\uc9c0 \ud050 \ub77c\uc774\ube0c\ub7ec\ub9ac \uc0ac\uc6a9 \uac00\uc815\n\n@sensor(\n    job=message_processing_job,\n    minimum_interval_seconds=10,\n)\ndef message_queue_sensor(context):\n    """\uba54\uc2dc\uc9c0 \ud050\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uc13c\uc11c"""\n\n    queue_name = "data_events"\n    max_messages = 10  # \ud55c \ubc88\uc5d0 \ucc98\ub9ac\ud560 \ucd5c\ub300 \uba54\uc2dc\uc9c0 \uc218\n\n    try:\n        # \uba54\uc2dc\uc9c0 \ud050 \uc5f0\uacb0 (\uc608\uc2dc)\n        messages = fetch_messages_from_queue(queue_name, max_messages)\n\n        if not messages:\n            return SkipReason("No messages in queue")\n\n        context.log.info(f"Processing {len(messages)} messages from queue")\n\n        for message in messages:\n            message_id = message.get(\'id\')\n            message_data = message.get(\'data\')\n\n            yield RunRequest(\n                run_key=f"message_{message_id}",\n                run_config={\n                    "ops": {\n                        "process_message": {\n                            "config": {\n                                "message_id": message_id,\n                                "message_data": json.dumps(message_data)\n                            }\n                        }\n                    }\n                },\n                tags={\n                    "source": "message_queue",\n                    "queue": queue_name,\n                    "message_id": str(message_id)\n                }\n            )\n\n            # \uba54\uc2dc\uc9c0 \ud655\uc778 \ucc98\ub9ac (acknowledge)\n            acknowledge_message(queue_name, message_id)\n\n    except Exception as e:\n        context.log.error(f"Message queue sensor error: {e}")\n        return SkipReason(f"Queue error: {str(e)}")\n\ndef fetch_messages_from_queue(queue_name, max_count):\n    """\uba54\uc2dc\uc9c0 \ud050\uc5d0\uc11c \uba54\uc2dc\uc9c0\ub97c \uac00\uc838\uc624\ub294 \ud5ec\ud37c \ud568\uc218"""\n    # \uc2e4\uc81c \uad6c\ud604\uc740 \uc0ac\uc6a9\ud558\ub294 \uba54\uc2dc\uc9c0 \ud050\uc5d0 \ub530\ub77c \ub2e4\ub984\n    return []\n\ndef acknowledge_message(queue_name, message_id):\n    """\uba54\uc2dc\uc9c0 \ucc98\ub9ac \uc644\ub8cc\ub97c \ud655\uc778\ud558\ub294 \ud5ec\ud37c \ud568\uc218"""\n    pass\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc6f9\ud6c5-\uae30\ubc18-\uc13c\uc11c",children:"\uc6f9\ud6c5 \uae30\ubc18 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest\nfrom pathlib import Path\nimport json\n\n@sensor(\n    job=webhook_handler_job,\n    minimum_interval_seconds=5,\n)\ndef webhook_sensor(context):\n    """\uc6f9\ud6c5 \uc774\ubca4\ud2b8\ub97c \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n\n    # \uc6f9\ud6c5 \uc774\ubca4\ud2b8\uac00 \ud30c\uc77c\ub85c \uc800\uc7a5\ub41c\ub2e4\uace0 \uac00\uc815\n    webhook_dir = Path("/tmp/webhooks")\n\n    if not webhook_dir.exists():\n        return SkipReason("Webhook directory does not exist")\n\n    # \ucc98\ub9ac\ub41c \uc6f9\ud6c5 \ucd94\uc801\n    processed_webhooks = set()\n    if context.cursor:\n        processed_webhooks = set(json.loads(context.cursor))\n\n    # \uc0c8 \uc6f9\ud6c5 \ud30c\uc77c \ud655\uc778\n    webhook_files = list(webhook_dir.glob("*.json"))\n    new_webhooks = [\n        f for f in webhook_files\n        if f.name not in processed_webhooks\n    ]\n\n    if not new_webhooks:\n        return SkipReason("No new webhook events")\n\n    context.log.info(f"Processing {len(new_webhooks)} webhook events")\n\n    for webhook_file in new_webhooks:\n        try:\n            with open(webhook_file, \'r\') as f:\n                webhook_data = json.load(f)\n\n            event_type = webhook_data.get(\'event_type\')\n            event_id = webhook_data.get(\'event_id\')\n\n            yield RunRequest(\n                run_key=f"webhook_{event_id}",\n                run_config={\n                    "ops": {\n                        "handle_webhook": {\n                            "config": {\n                                "event_type": event_type,\n                                "event_data": json.dumps(webhook_data)\n                            }\n                        }\n                    }\n                },\n                tags={\n                    "source": "webhook",\n                    "event_type": event_type,\n                    "event_id": str(event_id)\n                }\n            )\n\n            processed_webhooks.add(webhook_file.name)\n\n        except Exception as e:\n            context.log.error(f"Error processing webhook {webhook_file}: {e}")\n\n    # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n    context.update_cursor(json.dumps(list(processed_webhooks)))\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc870\uac74\ubd80-\uc2e4\ud589-\uc13c\uc11c",children:"\uc870\uac74\ubd80 \uc2e4\ud589 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SkipReason\nfrom datetime import datetime, time\n\n@sensor(\n    job=conditional_job,\n    minimum_interval_seconds=60,\n)\ndef conditional_sensor(context):\n    """\ub2e4\uc591\ud55c \uc870\uac74\uc744 \uccb4\ud06c\ud558\ub294 \uc13c\uc11c"""\n\n    current_time = datetime.now()\n\n    # \uc5c5\ubb34 \uc2dc\uac04 \uccb4\ud06c (\uc624\uc804 9\uc2dc ~ \uc624\ud6c4 6\uc2dc)\n    business_start = time(9, 0)\n    business_end = time(18, 0)\n    current_time_only = current_time.time()\n\n    if not (business_start <= current_time_only <= business_end):\n        return SkipReason("Outside business hours")\n\n    # \uc8fc\ub9d0 \uccb4\ud06c\n    if current_time.weekday() >= 5:  # \ud1a0\uc694\uc77c, \uc77c\uc694\uc77c\n        return SkipReason("Weekend - skipping")\n\n    # \uc2dc\uc2a4\ud15c \ub9ac\uc18c\uc2a4 \uccb4\ud06c\n    cpu_usage = get_cpu_usage()\n    if cpu_usage > 80:\n        return SkipReason(f"High CPU usage: {cpu_usage}%")\n\n    # \uc678\ubd80 \uc870\uac74 \uccb4\ud06c\n    if not check_external_condition():\n        return SkipReason("External condition not met")\n\n    # \ubaa8\ub4e0 \uc870\uac74\uc774 \ucda9\uc871\ub418\uba74 \uc2e4\ud589\n    context.log.info("All conditions met, triggering job")\n\n    yield RunRequest(\n        run_key=f"conditional_{current_time.isoformat()}",\n        tags={\n            "trigger_time": current_time.isoformat(),\n            "cpu_usage": str(cpu_usage)\n        }\n    )\n\ndef check_external_condition():\n    """\uc678\ubd80 \uc870\uac74\uc744 \ud655\uc778\ud558\ub294 \ud5ec\ud37c \ud568\uc218"""\n    # \uc2e4\uc81c \uad6c\ud604\uc740 \uc694\uad6c\uc0ac\ud56d\uc5d0 \ub530\ub77c \ub2e4\ub984\n    return True\n'})}),"\n",(0,r.jsx)(e.h2,{id:"38-sensor-\ud3c9\uac00",children:"3.8 Sensor \ud3c9\uac00"}),"\n",(0,r.jsx)(e.p,{children:"\uc13c\uc11c\ub294 \uc815\uae30\uc801\uc73c\ub85c \ud3c9\uac00\ub418\uba70, \uac01 \ud3c9\uac00\ub9c8\ub2e4 \uc2e4\ud589 \uc5ec\ubd80\ub97c \uacb0\uc815\ud569\ub2c8\ub2e4. \uc13c\uc11c \ud3c9\uac00\uc758 \ub3d9\uc791 \ubc29\uc2dd\uacfc \ucd5c\uc801\ud654 \ubc29\ubc95\uc744 \uc774\ud574\ud558\ub294 \uac83\uc774 \uc911\uc694\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\ud3c9\uac00-\uac04\uaca9-\uc124\uc815",children:"\ud3c9\uac00 \uac04\uaca9 \uc124\uc815"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest\n\n@sensor(\n    job=frequent_check_job,\n    minimum_interval_seconds=10,  # \ucd5c\uc18c 10\ucd08 \uac04\uaca9\n)\ndef frequent_sensor(context):\n    """\uc790\uc8fc \ud3c9\uac00\ub418\ub294 \uc13c\uc11c"""\n    # \ube60\ub978 \uc751\ub2f5\uc774 \ud544\uc694\ud55c \uacbd\uc6b0\n    return RunRequest()\n\n@sensor(\n    job=infrequent_check_job,\n    minimum_interval_seconds=3600,  # 1\uc2dc\uac04 \uac04\uaca9\n)\ndef infrequent_sensor(context):\n    """\ub4dc\ubb3c\uac8c \ud3c9\uac00\ub418\ub294 \uc13c\uc11c"""\n    # \ub9ac\uc18c\uc2a4\ub97c \uc808\uc57d\ud558\uace0 \uc2f6\uc740 \uacbd\uc6b0\n    return RunRequest()\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc13c\uc11c-\uc131\ub2a5-\ucd5c\uc801\ud654",children:"\uc13c\uc11c \uc131\ub2a5 \ucd5c\uc801\ud654"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SkipReason\nimport time\n\n@sensor(\n    job=optimized_job,\n    minimum_interval_seconds=30,\n)\ndef optimized_sensor(context):\n    """\ucd5c\uc801\ud654\ub41c \uc13c\uc11c - \ube60\ub978 \ud3c9\uac00\ub97c \uc704\ud55c \ud328\ud134"""\n\n    start_time = time.time()\n\n    # 1. \ube60\ub978 \uc0ac\uc804 \uccb4\ud06c\ub85c \ubd88\ud544\uc694\ud55c \uc791\uc5c5 \uac74\ub108\ub6f0\uae30\n    if not quick_pre_check():\n        return SkipReason("Pre-check failed - skipping expensive operations")\n\n    # 2. \uce90\uc2f1 \ud65c\uc6a9\n    cache_key = "sensor_data_cache"\n    cached_data = get_from_cache(cache_key)\n\n    if cached_data and is_cache_valid(cached_data):\n        data = cached_data\n    else:\n        # \ube44\uc6a9\uc774 \ub9ce\uc774 \ub4dc\ub294 \uc791\uc5c5\n        data = expensive_operation()\n        set_cache(cache_key, data, ttl=300)  # 5\ubd84 \uce90\uc2dc\n\n    # 3. \uc870\uac74\ubd80 \uc2e4\ud589\n    if not should_trigger(data):\n        return SkipReason("Condition not met")\n\n    elapsed_time = time.time() - start_time\n    context.log.info(f"Sensor evaluation took {elapsed_time:.2f}s")\n\n    yield RunRequest(\n        run_key=f"optimized_{int(time.time())}",\n        tags={"evaluation_time": str(elapsed_time)}\n    )\n\ndef quick_pre_check():\n    """\ube60\ub978 \uc0ac\uc804 \uac80\uc0ac"""\n    return True\n\ndef expensive_operation():\n    """\ube44\uc6a9\uc774 \ub9ce\uc774 \ub4dc\ub294 \uc791\uc5c5"""\n    return {"result": "data"}\n\ndef should_trigger(data):\n    """\ud2b8\ub9ac\uac70 \uc5ec\ubd80 \uacb0\uc815"""\n    return True\n\n# \uce90\uc2dc \ud5ec\ud37c \ud568\uc218\ub4e4\n_cache = {}\n\ndef get_from_cache(key):\n    return _cache.get(key, {}).get(\'data\')\n\ndef is_cache_valid(cached_data):\n    cache_entry = _cache.get(\'sensor_data_cache\', {})\n    if \'timestamp\' not in cache_entry:\n        return False\n    return time.time() - cache_entry[\'timestamp\'] < cache_entry.get(\'ttl\', 0)\n\ndef set_cache(key, data, ttl):\n    _cache[key] = {\n        \'data\': data,\n        \'timestamp\': time.time(),\n        \'ttl\': ttl\n    }\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\ubc30\uce58-\ucc98\ub9ac-\uc13c\uc11c",children:"\ubc30\uce58 \ucc98\ub9ac \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest\n\n@sensor(\n    job=batch_processing_job,\n    minimum_interval_seconds=60,\n)\ndef batch_sensor(context):\n    """\uc5ec\ub7ec \ud56d\ubaa9\uc744 \ubc30\uce58\ub85c \ucc98\ub9ac\ud558\ub294 \uc13c\uc11c"""\n\n    # \ub300\uae30 \uc911\uc778 \ud56d\ubaa9\ub4e4 \ud655\uc778\n    pending_items = get_pending_items()\n\n    if not pending_items:\n        return SkipReason("No pending items")\n\n    # \ubc30\uce58 \ud06c\uae30 \uc124\uc815\n    batch_size = 10\n\n    # \ubc30\uce58\ub85c \uadf8\ub8f9\ud654\n    batches = [\n        pending_items[i:i + batch_size]\n        for i in range(0, len(pending_items), batch_size)\n    ]\n\n    context.log.info(f"Processing {len(pending_items)} items in {len(batches)} batches")\n\n    for batch_idx, batch in enumerate(batches):\n        yield RunRequest(\n            run_key=f"batch_{batch_idx}_{int(time.time())}",\n            run_config={\n                "ops": {\n                    "process_batch": {\n                        "config": {\n                            "items": [item[\'id\'] for item in batch],\n                            "batch_index": batch_idx,\n                            "total_batches": len(batches)\n                        }\n                    }\n                }\n            },\n            tags={\n                "batch_index": str(batch_idx),\n                "batch_size": str(len(batch))\n            }\n        )\n\ndef get_pending_items():\n    """\ub300\uae30 \uc911\uc778 \ud56d\ubaa9\uc744 \uac00\uc838\uc624\ub294 \ud5ec\ud37c \ud568\uc218"""\n    # \uc2e4\uc81c \uad6c\ud604\n    return []\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc13c\uc11c-\uc0c1\ud0dc-\ucd94\uc801",children:"\uc13c\uc11c \uc0c1\ud0dc \ucd94\uc801"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"from dagster import sensor, RunRequest, SkipReason\nfrom datetime import datetime\nimport json\n\n@sensor(\n    job=stateful_job,\n    minimum_interval_seconds=60,\n)\ndef stateful_sensor(context):\n    \"\"\"\uc0c1\ud0dc\ub97c \ucd94\uc801\ud558\ub294 \uc13c\uc11c\"\"\"\n\n    # \ucee4\uc11c\uc5d0\uc11c \uc0c1\ud0dc \ub85c\ub4dc\n    state = {\n        'last_run': None,\n        'consecutive_skips': 0,\n        'total_runs': 0,\n        'last_error': None\n    }\n\n    if context.cursor:\n        state.update(json.loads(context.cursor))\n\n    try:\n        # \uc5f0\uc18d \uc2a4\ud0b5 \ud69f\uc218 \uccb4\ud06c\n        if state['consecutive_skips'] > 10:\n            context.log.warning(\n                f\"Sensor has been skipped {state['consecutive_skips']} times consecutively\"\n            )\n\n        # \ube44\uc988\ub2c8\uc2a4 \ub85c\uc9c1\n        should_run = check_condition()\n\n        if should_run:\n            state['last_run'] = datetime.now().isoformat()\n            state['consecutive_skips'] = 0\n            state['total_runs'] += 1\n\n            context.update_cursor(json.dumps(state))\n\n            yield RunRequest(\n                run_key=f\"stateful_{state['total_runs']}\",\n                tags={\n                    \"run_number\": str(state['total_runs']),\n                    \"last_run\": state['last_run']\n                }\n            )\n        else:\n            state['consecutive_skips'] += 1\n            context.update_cursor(json.dumps(state))\n\n            return SkipReason(\n                f\"Condition not met (consecutive skips: {state['consecutive_skips']})\"\n            )\n\n    except Exception as e:\n        state['last_error'] = {\n            'message': str(e),\n            'timestamp': datetime.now().isoformat()\n        }\n        context.update_cursor(json.dumps(state))\n        context.log.error(f\"Sensor error: {e}\")\n        return SkipReason(f\"Error: {str(e)}\")\n\ndef check_condition():\n    \"\"\"\uc870\uac74\uc744 \ud655\uc778\ud558\ub294 \ud5ec\ud37c \ud568\uc218\"\"\"\n    return False\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\uc13c\uc11c-\ub85c\uae45-\ubc0f-\ubaa8\ub2c8\ud130\ub9c1",children:"\uc13c\uc11c \ub85c\uae45 \ubc0f \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SkipReason\n\n@sensor(\n    job=monitored_job,\n    minimum_interval_seconds=120,\n)\ndef monitored_sensor(context):\n    """\uc0c1\uc138\ud55c \ub85c\uae45\uacfc \ubaa8\ub2c8\ud130\ub9c1\uc774 \ud3ec\ud568\ub41c \uc13c\uc11c"""\n\n    context.log.info("Starting sensor evaluation")\n\n    # \uba54\ud2b8\ub9ad \uc218\uc9d1\n    metrics = {\n        \'evaluation_start\': datetime.now().isoformat(),\n        \'items_checked\': 0,\n        \'items_triggered\': 0,\n        \'errors\': []\n    }\n\n    try:\n        items_to_check = get_items_to_check()\n        metrics[\'items_checked\'] = len(items_to_check)\n\n        context.log.info(f"Checking {len(items_to_check)} items")\n\n        for item in items_to_check:\n            try:\n                if should_process_item(item):\n                    metrics[\'items_triggered\'] += 1\n\n                    yield RunRequest(\n                        run_key=f"item_{item[\'id\']}",\n                        run_config={\n                            "ops": {\n                                "process_item": {\n                                    "config": {"item_id": item[\'id\']}\n                                }\n                            }\n                        },\n                        tags={"item_id": str(item[\'id\'])}\n                    )\n\n            except Exception as item_error:\n                error_info = {\n                    \'item_id\': item[\'id\'],\n                    \'error\': str(item_error),\n                    \'timestamp\': datetime.now().isoformat()\n                }\n                metrics[\'errors\'].append(error_info)\n                context.log.error(f"Error processing item {item[\'id\']}: {item_error}")\n\n        # \ud3c9\uac00 \uc644\ub8cc \ub85c\uadf8\n        metrics[\'evaluation_end\'] = datetime.now().isoformat()\n        context.log.info(f"Sensor evaluation complete: {json.dumps(metrics)}")\n\n        if metrics[\'items_triggered\'] == 0:\n            return SkipReason(f"No items to process (checked {metrics[\'items_checked\']} items)")\n\n    except Exception as e:\n        context.log.error(f"Sensor evaluation failed: {e}")\n        return SkipReason(f"Evaluation error: {str(e)}")\n\ndef get_items_to_check():\n    """\ud655\uc778\ud560 \ud56d\ubaa9\uc744 \uac00\uc838\uc624\ub294 \ud5ec\ud37c \ud568\uc218"""\n    return []\n\ndef should_process_item(item):\n    """\ud56d\ubaa9 \ucc98\ub9ac \uc5ec\ubd80\ub97c \uacb0\uc815\ud558\ub294 \ud5ec\ud37c \ud568\uc218"""\n    return False\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc13c\uc11c-\ud14c\uc2a4\ud2b8",children:"\uc13c\uc11c \ud14c\uc2a4\ud2b8"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import build_sensor_context, validate_run_config\n\ndef test_file_sensor():\n    """\uc13c\uc11c \ud14c\uc2a4\ud2b8 \uc608\uc81c"""\n\n    # \ud14c\uc2a4\ud2b8 \ucee8\ud14d\uc2a4\ud2b8 \uc0dd\uc131\n    context = build_sensor_context(\n        cursor="initial_cursor",\n    )\n\n    # \uc13c\uc11c \uc2e4\ud589\n    result = list(new_file_sensor(context))\n\n    # \uacb0\uacfc \uac80\uc99d\n    assert len(result) > 0\n    assert isinstance(result[0], RunRequest)\n\n    # RunConfig \uac80\uc99d\n    run_request = result[0]\n    assert run_request.run_key is not None\n    assert "file_path" in run_request.run_config.get("ops", {}).get("process_new_file", {}).get("config", {})\n\ndef test_sensor_with_mock():\n    """\ubaa8\ud0b9\uc744 \uc0ac\uc6a9\ud55c \uc13c\uc11c \ud14c\uc2a4\ud2b8"""\n\n    # \ubaa8\ud0b9 \uc124\uc815 (\uc608: API \ud638\ucd9c \ubaa8\ud0b9)\n    original_function = check_external_condition\n\n    def mock_condition():\n        return True\n\n    # \ud568\uc218 \uad50\uccb4\n    globals()[\'check_external_condition\'] = mock_condition\n\n    try:\n        context = build_sensor_context()\n        result = list(conditional_sensor(context))\n\n        assert len(result) > 0\n        assert isinstance(result[0], RunRequest)\n\n    finally:\n        # \uc6d0\ub798 \ud568\uc218 \ubcf5\uc6d0\n        globals()[\'check_external_condition\'] = original_function\n'})}),"\n",(0,r.jsx)(e.h2,{id:"39-\uc2e4\uc2b5-\uc2a4\ucf00\uc904\uacfc-\uc13c\uc11c-\uad6c\ud604",children:"3.9 \uc2e4\uc2b5: \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c \uad6c\ud604"}),"\n",(0,r.jsx)(e.p,{children:"\uc2e4\uc81c \uc2dc\ub098\ub9ac\uc624\ub97c \ud1b5\ud574 \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c\ub97c \uad6c\ud604\ud558\ub294 \uc2e4\uc2b5\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"\uc2e4\uc2b5-1-\uc77c\uc77c-\ub370\uc774\ud130-\ud30c\uc774\ud504\ub77c\uc778",children:"\uc2e4\uc2b5 1: \uc77c\uc77c \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    asset,\n    define_asset_job,\n    ScheduleDefinition,\n    AssetSelection,\n    DailyPartitionsDefinition,\n)\nfrom datetime import datetime\nimport pandas as pd\n\n# \uc77c\uc77c \ud30c\ud2f0\uc158 \uc815\uc758\ndaily_partition = DailyPartitionsDefinition(\n    start_date="2024-01-01",\n    timezone="Asia/Seoul",\n)\n\n@asset(partitions_def=daily_partition)\ndef raw_sales_data(context):\n    """\uc6d0\uc2dc \ub9e4\ucd9c \ub370\uc774\ud130 \uc218\uc9d1"""\n    partition_date = context.partition_key\n\n    context.log.info(f"Fetching sales data for {partition_date}")\n\n    # \uc2e4\uc81c\ub85c\ub294 \ub370\uc774\ud130\ubca0\uc774\uc2a4\ub098 API\uc5d0\uc11c \uac00\uc838\uc634\n    data = pd.DataFrame({\n        \'date\': [partition_date] * 5,\n        \'product_id\': [1, 2, 3, 4, 5],\n        \'quantity\': [10, 15, 8, 20, 12],\n        \'price\': [1000, 1500, 2000, 800, 1200]\n    })\n\n    # \ub370\uc774\ud130 \uc800\uc7a5\n    file_path = f"/data/raw/sales_{partition_date}.csv"\n    data.to_csv(file_path, index=False)\n\n    context.log.info(f"Saved {len(data)} records to {file_path}")\n\n    return file_path\n\n@asset(partitions_def=daily_partition)\ndef processed_sales_data(context, raw_sales_data):\n    """\ub9e4\ucd9c \ub370\uc774\ud130 \ucc98\ub9ac"""\n    partition_date = context.partition_key\n\n    # \uc6d0\uc2dc \ub370\uc774\ud130 \ub85c\ub4dc\n    df = pd.read_csv(raw_sales_data)\n\n    # \ub370\uc774\ud130 \ucc98\ub9ac\n    df[\'total_amount\'] = df[\'quantity\'] * df[\'price\']\n    df[\'processed_at\'] = datetime.now().isoformat()\n\n    # \ucc98\ub9ac\ub41c \ub370\uc774\ud130 \uc800\uc7a5\n    output_path = f"/data/processed/sales_{partition_date}.csv"\n    df.to_csv(output_path, index=False)\n\n    context.log.info(f"Processed sales data: total amount = {df[\'total_amount\'].sum()}")\n\n    return output_path\n\n@asset(partitions_def=daily_partition)\ndef sales_summary(context, processed_sales_data):\n    """\ub9e4\ucd9c \uc694\uc57d \ub9ac\ud3ec\ud2b8"""\n    partition_date = context.partition_key\n\n    df = pd.read_csv(processed_sales_data)\n\n    summary = {\n        \'date\': partition_date,\n        \'total_sales\': df[\'total_amount\'].sum(),\n        \'total_quantity\': df[\'quantity\'].sum(),\n        \'average_price\': df[\'price\'].mean(),\n        \'product_count\': len(df)\n    }\n\n    # \uc694\uc57d \uc800\uc7a5\n    summary_df = pd.DataFrame([summary])\n    output_path = f"/data/summary/sales_summary_{partition_date}.csv"\n    summary_df.to_csv(output_path, index=False)\n\n    context.log.info(f"Sales summary: {summary}")\n\n    return summary\n\n# Job \uc815\uc758\ndaily_sales_pipeline = define_asset_job(\n    name="daily_sales_pipeline",\n    selection=AssetSelection.all(),\n    partitions_def=daily_partition,\n)\n\n# \uc2a4\ucf00\uc904: \ub9e4\uc77c \uc624\uc804 2\uc2dc\uc5d0 \uc804\ub0a0 \ub370\uc774\ud130 \ucc98\ub9ac\nfrom dagster import build_schedule_from_partitioned_job\n\ndaily_sales_schedule = build_schedule_from_partitioned_job(\n    daily_sales_pipeline,\n    hour_of_day=2,\n    minute_of_day=0,\n    timezone="Asia/Seoul",\n)\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2e4\uc2b5-2-\ud30c\uc77c-\uc5c5\ub85c\ub4dc-\uac10\uc9c0-\uc13c\uc11c",children:"\uc2e4\uc2b5 2: \ud30c\uc77c \uc5c5\ub85c\ub4dc \uac10\uc9c0 \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, SkipReason, op, job\nimport os\nimport shutil\nfrom pathlib import Path\n\n@op\ndef validate_file(context):\n    """\ud30c\uc77c \uc720\ud6a8\uc131 \uac80\uc0ac"""\n    file_path = context.op_config["file_path"]\n\n    context.log.info(f"Validating file: {file_path}")\n\n    # \ud30c\uc77c \uc874\uc7ac \ud655\uc778\n    if not os.path.exists(file_path):\n        raise FileNotFoundError(f"File not found: {file_path}")\n\n    # \ud30c\uc77c \ud06c\uae30 \ud655\uc778\n    file_size = os.path.getsize(file_path)\n    if file_size == 0:\n        raise ValueError("File is empty")\n\n    context.log.info(f"File validation passed: {file_size} bytes")\n\n    return {"file_path": file_path, "size": file_size}\n\n@op\ndef process_uploaded_file(context, file_info):\n    """\uc5c5\ub85c\ub4dc\ub41c \ud30c\uc77c \ucc98\ub9ac"""\n    file_path = file_info["file_path"]\n\n    context.log.info(f"Processing file: {file_path}")\n\n    # \ud30c\uc77c \ucc98\ub9ac \ub85c\uc9c1\n    # \uc608: CSV \ud30c\uc77c \uc77d\uae30 \ubc0f \ubcc0\ud658\n    df = pd.read_csv(file_path)\n\n    # \ub370\uc774\ud130 \ucc98\ub9ac\n    processed_df = df.copy()\n    processed_df[\'processed_at\'] = datetime.now().isoformat()\n\n    # \ucc98\ub9ac\ub41c \ud30c\uc77c \uc800\uc7a5\n    processed_path = file_path.replace(\'/incoming/\', \'/processed/\')\n    os.makedirs(os.path.dirname(processed_path), exist_ok=True)\n    processed_df.to_csv(processed_path, index=False)\n\n    context.log.info(f"File processed: {processed_path}")\n\n    return processed_path\n\n@op\ndef archive_file(context, processed_file):\n    """\ud30c\uc77c \uc544\uce74\uc774\ube0c"""\n    original_file = context.op_config["original_file"]\n\n    # \uc544\uce74\uc774\ube0c \ub514\ub809\ud1a0\ub9ac\n    archive_dir = "/data/archive"\n    os.makedirs(archive_dir, exist_ok=True)\n\n    # \ud30c\uc77c \uc774\ub3d9\n    archive_path = os.path.join(\n        archive_dir,\n        f"{datetime.now().strftime(\'%Y%m%d\')}_{os.path.basename(original_file)}"\n    )\n    shutil.move(original_file, archive_path)\n\n    context.log.info(f"File archived: {archive_path}")\n\n    return archive_path\n\n@job\ndef file_upload_job():\n    """\ud30c\uc77c \uc5c5\ub85c\ub4dc \ucc98\ub9ac job"""\n    file_info = validate_file()\n    processed_file = process_uploaded_file(file_info)\n    archive_file(processed_file)\n\n@sensor(\n    job=file_upload_job,\n    minimum_interval_seconds=30,\n)\ndef file_upload_sensor(context):\n    """\ud30c\uc77c \uc5c5\ub85c\ub4dc\ub97c \uac10\uc9c0\ud558\ub294 \uc13c\uc11c"""\n\n    incoming_dir = Path("/data/incoming")\n\n    # \ub514\ub809\ud1a0\ub9ac\uac00 \uc5c6\uc73c\uba74 \uc0dd\uc131\n    incoming_dir.mkdir(parents=True, exist_ok=True)\n\n    # \ucc98\ub9ac\ub41c \ud30c\uc77c \ubaa9\ub85d \ub85c\ub4dc\n    processed_files = set()\n    if context.cursor:\n        processed_files = set(json.loads(context.cursor))\n\n    # CSV \ud30c\uc77c \ud655\uc778\n    csv_files = list(incoming_dir.glob("*.csv"))\n\n    if not csv_files:\n        return SkipReason("No CSV files found")\n\n    # \uc0c8 \ud30c\uc77c\ub9cc \ud544\ud130\ub9c1\n    new_files = [f for f in csv_files if f.name not in processed_files]\n\n    if not new_files:\n        return SkipReason("No new files to process")\n\n    context.log.info(f"Found {len(new_files)} new files")\n\n    # \uac01 \ud30c\uc77c\uc5d0 \ub300\ud574 RunRequest \uc0dd\uc131\n    for file_path in new_files:\n        yield RunRequest(\n            run_key=f"upload_{file_path.stem}_{int(time.time())}",\n            run_config={\n                "ops": {\n                    "validate_file": {\n                        "config": {"file_path": str(file_path)}\n                    },\n                    "archive_file": {\n                        "config": {"original_file": str(file_path)}\n                    }\n                }\n            },\n            tags={\n                "file_name": file_path.name,\n                "file_size": str(file_path.stat().st_size),\n                "upload_detected_at": datetime.now().isoformat()\n            }\n        )\n\n    # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n    processed_files.update(f.name for f in new_files)\n    context.update_cursor(json.dumps(list(processed_files)))\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2e4\uc2b5-3-\ub370\uc774\ud130-\ud488\uc9c8-\ubaa8\ub2c8\ud130\ub9c1",children:"\uc2e4\uc2b5 3: \ub370\uc774\ud130 \ud488\uc9c8 \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import asset, asset_sensor, AssetKey, define_asset_job, AssetSelection\n\n@asset\ndef user_data():\n    """\uc0ac\uc6a9\uc790 \ub370\uc774\ud130"""\n    return pd.DataFrame({\n        \'user_id\': range(1, 101),\n        \'age\': [20 + i % 50 for i in range(100)],\n        \'signup_date\': pd.date_range(\'2024-01-01\', periods=100),\n        \'status\': [\'active\'] * 90 + [\'inactive\'] * 10\n    })\n\n@asset\ndef data_quality_check(user_data):\n    """\ub370\uc774\ud130 \ud488\uc9c8 \uccb4\ud06c"""\n    df = user_data\n\n    quality_metrics = {\n        \'total_rows\': len(df),\n        \'null_count\': df.isnull().sum().sum(),\n        \'duplicate_count\': df.duplicated().sum(),\n        \'active_users\': (df[\'status\'] == \'active\').sum(),\n        \'average_age\': df[\'age\'].mean(),\n        \'check_timestamp\': datetime.now().isoformat()\n    }\n\n    # \ud488\uc9c8 \uae30\uc900 \uac80\uc99d\n    quality_passed = (\n        quality_metrics[\'null_count\'] == 0 and\n        quality_metrics[\'duplicate_count\'] == 0 and\n        quality_metrics[\'active_users\'] > 50\n    )\n\n    quality_metrics[\'quality_passed\'] = quality_passed\n\n    return quality_metrics\n\n@asset\ndef quality_alert(data_quality_check):\n    """\ud488\uc9c8 \uc54c\ub9bc"""\n    if not data_quality_check[\'quality_passed\']:\n        alert_message = f"""\n        \ub370\uc774\ud130 \ud488\uc9c8 \uacbd\uace0!\n        - Null \uac12: {data_quality_check[\'null_count\']}\n        - \uc911\ubcf5 \uac12: {data_quality_check[\'duplicate_count\']}\n        - \ud65c\uc131 \uc0ac\uc6a9\uc790: {data_quality_check[\'active_users\']}\n        """\n\n        # \uc2e4\uc81c\ub85c\ub294 \uc774\uba54\uc77c\uc774\ub098 Slack\uc73c\ub85c \uc804\uc1a1\n        print(alert_message)\n\n        return {"alert_sent": True, "message": alert_message}\n\n    return {"alert_sent": False}\n\n# Quality check job\nquality_check_job = define_asset_job(\n    name="quality_check_job",\n    selection=AssetSelection.assets(data_quality_check, quality_alert),\n)\n\n# user_data\uac00 \uc5c5\ub370\uc774\ud2b8\ub418\uba74 \uc790\ub3d9\uc73c\ub85c \ud488\uc9c8 \uccb4\ud06c\n@asset_sensor(\n    asset_key=AssetKey("user_data"),\n    job=quality_check_job,\n)\ndef quality_check_sensor(context, asset_event):\n    """\ub370\uc774\ud130 \uc5c5\ub370\uc774\ud2b8 \uc2dc \ud488\uc9c8 \uccb4\ud06c \ud2b8\ub9ac\uac70"""\n\n    context.log.info("User data updated, triggering quality check")\n\n    yield RunRequest(\n        run_key=f"quality_check_{int(time.time())}",\n        tags={\n            "triggered_by": "user_data_update",\n            "check_type": "automatic"\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2e4\uc2b5-4-\uc2e4\ud328-\uc7ac\uc2dc\ub3c4-\ubc0f-\uc54c\ub9bc-\uc2dc\uc2a4\ud15c",children:"\uc2e4\uc2b5 4: \uc2e4\ud328 \uc7ac\uc2dc\ub3c4 \ubc0f \uc54c\ub9bc \uc2dc\uc2a4\ud15c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    op,\n    job,\n    run_status_sensor,\n    RunStatusSensorContext,\n    DagsterRunStatus,\n)\n\n@op\ndef risky_operation(context):\n    """\uc2e4\ud328\ud560 \uc218 \uc788\ub294 \uc791\uc5c5"""\n    import random\n\n    # 30% \ud655\ub960\ub85c \uc2e4\ud328\n    if random.random() < 0.3:\n        raise Exception("Random failure occurred")\n\n    context.log.info("Operation succeeded")\n    return "success"\n\n@job\ndef risky_job():\n    risky_operation()\n\n@op\ndef send_failure_notification(context):\n    """\uc2e4\ud328 \uc54c\ub9bc \uc804\uc1a1"""\n    failed_job = context.op_config["job_name"]\n    run_id = context.op_config["run_id"]\n    error_message = context.op_config.get("error_message", "Unknown error")\n\n    notification = f"""\n    Job \uc2e4\ud328 \uc54c\ub9bc\n\n    Job: {failed_job}\n    Run ID: {run_id}\n    \uc624\ub958: {error_message}\n    \uc2dc\uac04: {datetime.now().strftime(\'%Y-%m-%d %H:%M:%S\')}\n\n    \ub2f4\ub2f9\uc790\uc5d0\uac8c \ud655\uc778\uc774 \ud544\uc694\ud569\ub2c8\ub2e4.\n    """\n\n    context.log.error(notification)\n\n    # \uc2e4\uc81c\ub85c\ub294 \uc774\uba54\uc77c, Slack \ub4f1\uc73c\ub85c \uc804\uc1a1\n    return {"notification_sent": True}\n\n@job\ndef failure_notification_job():\n    send_failure_notification()\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.FAILURE,\n    monitored_jobs=[risky_job],\n    request_job=failure_notification_job,\n)\ndef failure_notification_sensor(context: RunStatusSensorContext):\n    """\uc2e4\ud328 \uac10\uc9c0 \ubc0f \uc54c\ub9bc"""\n\n    dagster_run = context.dagster_run\n\n    context.log.error(f"Job {dagster_run.job_name} failed (Run: {dagster_run.run_id})")\n\n    yield RunRequest(\n        run_key=f"notification_{dagster_run.run_id}",\n        run_config={\n            "ops": {\n                "send_failure_notification": {\n                    "config": {\n                        "job_name": dagster_run.job_name,\n                        "run_id": dagster_run.run_id,\n                        "error_message": "Job execution failed"\n                    }\n                }\n            }\n        },\n        tags={\n            "alert_type": "job_failure",\n            "failed_job": dagster_run.job_name\n        }\n    )\n\n# \uc7ac\uc2dc\ub3c4 \uc13c\uc11c\n@run_status_sensor(\n    run_status=DagsterRunStatus.FAILURE,\n    monitored_jobs=[risky_job],\n    request_job=risky_job,\n)\ndef auto_retry_sensor(context: RunStatusSensorContext):\n    """\uc790\ub3d9 \uc7ac\uc2dc\ub3c4 \uc13c\uc11c"""\n\n    dagster_run = context.dagster_run\n\n    # \uc7ac\uc2dc\ub3c4 \ud69f\uc218 \ucd94\uc801\n    retry_state = {}\n    if context.cursor:\n        retry_state = json.loads(context.cursor)\n\n    run_id = dagster_run.run_id\n    retry_count = retry_state.get(run_id, 0)\n    max_retries = 3\n\n    if retry_count < max_retries:\n        context.log.info(\n            f"Retrying {dagster_run.job_name} (attempt {retry_count + 1}/{max_retries})"\n        )\n\n        # \uc7ac\uc2dc\ub3c4 \uce74\uc6b4\ud2b8 \uc99d\uac00\n        retry_state[run_id] = retry_count + 1\n        context.update_cursor(json.dumps(retry_state))\n\n        yield RunRequest(\n            run_key=f"retry_{run_id}_{retry_count}",\n            tags={\n                "retry_attempt": str(retry_count + 1),\n                "original_run_id": run_id\n            }\n        )\n    else:\n        context.log.error(\n            f"Max retries ({max_retries}) exceeded for {dagster_run.job_name}"\n        )\n        # \uc7ac\uc2dc\ub3c4 \uc0c1\ud0dc \uc81c\uac70\n        retry_state.pop(run_id, None)\n        context.update_cursor(json.dumps(retry_state))\n'})}),"\n",(0,r.jsx)(e.h2,{id:"310-asset-freshness\uc640-run-coordination",children:"3.10 Asset Freshness\uc640 Run Coordination"}),"\n",(0,r.jsx)(e.p,{children:"Asset freshness\ub294 \ub370\uc774\ud130\uc758 \ucd5c\uc2e0\uc131\uc744 \uad00\ub9ac\ud558\uace0, run coordination\uc740 \uc5ec\ub7ec job \uac04\uc758 \uc2e4\ud589 \uc21c\uc11c\ub97c \uc870\uc728\ud569\ub2c8\ub2e4."}),"\n",(0,r.jsx)(e.h3,{id:"asset-freshness-\uc815\uc758",children:"Asset Freshness \uc815\uc758"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    asset,\n    FreshnessPolicy,\n    AssetSelection,\n    define_asset_job,\n)\nfrom datetime import timedelta\n\n# Freshness \uc815\ucc45\uc774 \uc788\ub294 asset\n@asset(\n    freshness_policy=FreshnessPolicy(\n        maximum_lag_minutes=60  # \ucd5c\ub300 1\uc2dc\uac04\uae4c\uc9c0 \ud5c8\uc6a9\n    )\n)\ndef real_time_metrics():\n    """\uc2e4\uc2dc\uac04 \uba54\ud2b8\ub9ad - 1\uc2dc\uac04 \uc774\ub0b4\uc5d0 \uc5c5\ub370\uc774\ud2b8\ub418\uc5b4\uc57c \ud568"""\n    return {\n        \'timestamp\': datetime.now().isoformat(),\n        \'active_users\': 1000,\n        \'requests_per_minute\': 500\n    }\n\n@asset(\n    freshness_policy=FreshnessPolicy(\n        maximum_lag_minutes=1440,  # \ucd5c\ub300 24\uc2dc\uac04\n        cron_schedule="0 0 * * *",  # \ub9e4\uc77c \uc790\uc815\uc5d0 \uccb4\ud06c\n        cron_schedule_timezone="Asia/Seoul"\n    )\n)\ndef daily_summary():\n    """\uc77c\uc77c \uc694\uc57d - 24\uc2dc\uac04 \uc774\ub0b4\uc5d0 \uc5c5\ub370\uc774\ud2b8\ub418\uc5b4\uc57c \ud568"""\n    return {\n        \'date\': datetime.now().strftime(\'%Y-%m-%d\'),\n        \'total_sales\': 1000000,\n        \'total_orders\': 500\n    }\n\n@asset(\n    freshness_policy=FreshnessPolicy(\n        maximum_lag_minutes=10080,  # \ucd5c\ub300 7\uc77c\n        cron_schedule="0 0 * * 0",  # \ub9e4\uc8fc \uc77c\uc694\uc77c\n        cron_schedule_timezone="Asia/Seoul"\n    )\n)\ndef weekly_report():\n    """\uc8fc\uac04 \ub9ac\ud3ec\ud2b8 - 7\uc77c \uc774\ub0b4\uc5d0 \uc5c5\ub370\uc774\ud2b8\ub418\uc5b4\uc57c \ud568"""\n    return {\n        \'week\': datetime.now().strftime(\'%Y-W%W\'),\n        \'weekly_revenue\': 7000000\n    }\n'})}),"\n",(0,r.jsx)(e.h3,{id:"freshness-\uccb4\ud06c-\uc13c\uc11c",children:"Freshness \uccb4\ud06c \uc13c\uc11c"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import sensor, RunRequest, freshness_policy_sensor_context\n\n@sensor(\n    job=refresh_stale_data_job,\n    minimum_interval_seconds=300,  # 5\ubd84\ub9c8\ub2e4 \uccb4\ud06c\n)\ndef freshness_monitoring_sensor(context):\n    """Asset freshness\ub97c \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uc13c\uc11c"""\n\n    # \ubaa8\ub4e0 asset\uc758 freshness \uc0c1\ud0dc \ud655\uc778\n    from dagster import AssetKey\n\n    assets_to_check = [\n        AssetKey("real_time_metrics"),\n        AssetKey("daily_summary"),\n        AssetKey("weekly_report"),\n    ]\n\n    stale_assets = []\n\n    for asset_key in assets_to_check:\n        # Asset\uc758 \ub9c8\uc9c0\ub9c9 materialization \ud655\uc778\n        # (\uc2e4\uc81c \uad6c\ud604\uc5d0\uc11c\ub294 Dagster API \uc0ac\uc6a9)\n        last_update = check_asset_freshness(asset_key)\n\n        if last_update and is_stale(asset_key, last_update):\n            stale_assets.append(asset_key)\n            context.log.warning(f"Asset {asset_key} is stale")\n\n    if stale_assets:\n        yield RunRequest(\n            run_key=f"refresh_{int(time.time())}",\n            run_config={\n                "ops": {\n                    "refresh_assets": {\n                        "config": {\n                            "asset_keys": [str(k) for k in stale_assets]\n                        }\n                    }\n                }\n            },\n            tags={\n                "stale_asset_count": str(len(stale_assets)),\n                "refresh_reason": "freshness_check"\n            }\n        )\n    else:\n        return SkipReason("All assets are fresh")\n\ndef check_asset_freshness(asset_key):\n    """Asset\uc758 freshness \ud655\uc778"""\n    # \uc2e4\uc81c \uad6c\ud604\n    return datetime.now()\n\ndef is_stale(asset_key, last_update):\n    """Asset\uc774 stale\ud55c\uc9c0 \ud655\uc778"""\n    # \uc2e4\uc81c \uad6c\ud604\n    return False\n'})}),"\n",(0,r.jsx)(e.h3,{id:"run-coordination---sequential-jobs",children:"Run Coordination - Sequential Jobs"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import (\n    op,\n    job,\n    run_status_sensor,\n    RunStatusSensorContext,\n    DagsterRunStatus,\n)\n\n# \uccab \ubc88\uc9f8 job\n@op\ndef extract_data(context):\n    """\ub370\uc774\ud130 \ucd94\ucd9c"""\n    context.log.info("Extracting data from source")\n    return {"records": 1000, "status": "extracted"}\n\n@job\ndef extraction_job():\n    extract_data()\n\n# \ub450 \ubc88\uc9f8 job\n@op\ndef transform_data(context):\n    """\ub370\uc774\ud130 \ubcc0\ud658"""\n    context.log.info("Transforming data")\n    return {"records": 1000, "status": "transformed"}\n\n@job\ndef transformation_job():\n    transform_data()\n\n# \uc138 \ubc88\uc9f8 job\n@op\ndef load_data(context):\n    """\ub370\uc774\ud130 \uc801\uc7ac"""\n    context.log.info("Loading data to target")\n    return {"records": 1000, "status": "loaded"}\n\n@job\ndef loading_job():\n    load_data()\n\n# Coordination: extraction -> transformation\n@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    monitored_jobs=[extraction_job],\n    request_job=transformation_job,\n)\ndef trigger_transformation(context: RunStatusSensorContext):\n    """extraction \uc131\uacf5 \uc2dc transformation \uc2dc\uc791"""\n\n    dagster_run = context.dagster_run\n    context.log.info(f"Extraction completed, starting transformation")\n\n    yield RunRequest(\n        run_key=f"transform_{dagster_run.run_id}",\n        tags={\n            "triggered_by": "extraction_job",\n            "source_run_id": dagster_run.run_id\n        }\n    )\n\n# Coordination: transformation -> loading\n@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    monitored_jobs=[transformation_job],\n    request_job=loading_job,\n)\ndef trigger_loading(context: RunStatusSensorContext):\n    """transformation \uc131\uacf5 \uc2dc loading \uc2dc\uc791"""\n\n    dagster_run = context.dagster_run\n    context.log.info(f"Transformation completed, starting loading")\n\n    yield RunRequest(\n        run_key=f"load_{dagster_run.run_id}",\n        tags={\n            "triggered_by": "transformation_job",\n            "source_run_id": dagster_run.run_id\n        }\n    )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"run-coordination---parallel-jobs",children:"Run Coordination - Parallel Jobs"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'from dagster import multi_asset_sensor, MultiAssetSensorEvaluationContext\n\n# \ubcd1\ub82c job\ub4e4\n@asset\ndef data_source_a():\n    """\ub370\uc774\ud130 \uc18c\uc2a4 A"""\n    return {"source": "A", "records": 500}\n\n@asset\ndef data_source_b():\n    """\ub370\uc774\ud130 \uc18c\uc2a4 B"""\n    return {"source": "B", "records": 600}\n\n@asset\ndef data_source_c():\n    """\ub370\uc774\ud130 \uc18c\uc2a4 C"""\n    return {"source": "C", "records": 700}\n\n# \ubaa8\ub4e0 \uc18c\uc2a4\uac00 \uc900\ube44\ub418\uba74 \uc2e4\ud589\ub418\ub294 job\n@op\ndef merge_all_sources(context):\n    """\ubaa8\ub4e0 \ub370\uc774\ud130 \uc18c\uc2a4 \ubcd1\ud569"""\n    context.log.info("Merging data from all sources")\n    return {"total_records": 1800, "sources": ["A", "B", "C"]}\n\n@job\ndef merge_job():\n    merge_all_sources()\n\n@multi_asset_sensor(\n    monitored_assets=[\n        AssetKey("data_source_a"),\n        AssetKey("data_source_b"),\n        AssetKey("data_source_c"),\n    ],\n    job=merge_job,\n    minimum_interval_seconds=60,\n)\ndef merge_coordinator_sensor(context: MultiAssetSensorEvaluationContext):\n    """\ubaa8\ub4e0 \ub370\uc774\ud130 \uc18c\uc2a4\uac00 \uc900\ube44\ub418\uba74 \ubcd1\ud569 job \uc2dc\uc791"""\n\n    # \uac01 asset\uc758 \ucd5c\uc2e0 materialization \ud655\uc778\n    asset_events = context.latest_materialization_records_by_key()\n\n    required_assets = [\n        AssetKey("data_source_a"),\n        AssetKey("data_source_b"),\n        AssetKey("data_source_c"),\n    ]\n\n    # \ubaa8\ub4e0 asset\uc774 \uc900\ube44\ub418\uc5c8\ub294\uc9c0 \ud655\uc778\n    all_ready = all(asset_key in asset_events for asset_key in required_assets)\n\n    if not all_ready:\n        missing = [k for k in required_assets if k not in asset_events]\n        return SkipReason(f"Waiting for assets: {missing}")\n\n    # \ucee4\uc11c\ub85c \uc774\ubbf8 \ucc98\ub9ac\ud588\ub294\uc9c0 \ud655\uc778\n    current_timestamps = {\n        str(asset_key): event.event_log_entry.timestamp\n        for asset_key, event in asset_events.items()\n    }\n\n    cursor_data = {}\n    if context.cursor:\n        cursor_data = json.loads(context.cursor)\n\n    if current_timestamps == cursor_data:\n        return SkipReason("No new updates to process")\n\n    context.log.info("All data sources ready, starting merge")\n\n    yield RunRequest(\n        run_key=f"merge_{int(time.time())}",\n        tags={\n            "coordinated_run": "true",\n            "source_count": str(len(required_assets))\n        }\n    )\n\n    # \ucee4\uc11c \uc5c5\ub370\uc774\ud2b8\n    context.update_cursor(json.dumps(current_timestamps))\n'})}),"\n",(0,r.jsx)(e.h3,{id:"conditional-run-coordination",children:"Conditional Run Coordination"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    monitored_jobs=[data_validation_job],\n    request_job=conditional_pipeline_job,\n)\ndef conditional_pipeline_sensor(context: RunStatusSensorContext):\n    """\uac80\uc99d \uacb0\uacfc\uc5d0 \ub530\ub77c \uc870\uac74\ubd80\ub85c \ud30c\uc774\ud504\ub77c\uc778 \uc2e4\ud589"""\n\n    dagster_run = context.dagster_run\n\n    # \uac80\uc99d \uacb0\uacfc \ud655\uc778 (tags\ub098 metadata\uc5d0\uc11c \uac00\uc838\uc628\ub2e4\uace0 \uac00\uc815)\n    validation_passed = dagster_run.tags.get("validation_passed") == "true"\n    error_rate = float(dagster_run.tags.get("error_rate", "0"))\n\n    if not validation_passed:\n        context.log.warning("Validation failed, skipping pipeline")\n        return SkipReason("Validation failed")\n\n    if error_rate > 0.05:  # 5% \uc774\uc0c1 \uc624\ub958\uc728\n        context.log.warning(f"High error rate: {error_rate}, using cautious mode")\n\n        yield RunRequest(\n            run_key=f"cautious_{dagster_run.run_id}",\n            run_config={\n                "ops": {\n                    "process_data": {\n                        "config": {\n                            "mode": "cautious",\n                            "batch_size": 100,\n                            "enable_validation": True\n                        }\n                    }\n                }\n            },\n            tags={\n                "mode": "cautious",\n                "error_rate": str(error_rate)\n            }\n        )\n    else:\n        context.log.info("Validation passed with low error rate, normal mode")\n\n        yield RunRequest(\n            run_key=f"normal_{dagster_run.run_id}",\n            run_config={\n                "ops": {\n                    "process_data": {\n                        "config": {\n                            "mode": "normal",\n                            "batch_size": 1000,\n                            "enable_validation": False\n                        }\n                    }\n                }\n            },\n            tags={\n                "mode": "normal",\n                "error_rate": str(error_rate)\n            }\n        )\n'})}),"\n",(0,r.jsx)(e.h3,{id:"\uc2dc\uac04-\uae30\ubc18-coordination",children:"\uc2dc\uac04 \uae30\ubc18 Coordination"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'@sensor(\n    job=time_sensitive_job,\n    minimum_interval_seconds=60,\n)\ndef time_based_coordination_sensor(context):\n    """\uc2dc\uac04\ub300\ubcc4\ub85c \ub2e4\ub978 \uc124\uc815\uc73c\ub85c job \uc2e4\ud589"""\n\n    current_time = datetime.now()\n    current_hour = current_time.hour\n\n    # \uc5c5\ubb34 \uc2dc\uac04 (9-18\uc2dc)\n    if 9 <= current_hour < 18:\n        context.log.info("Business hours - using conservative settings")\n\n        yield RunRequest(\n            run_key=f"business_hours_{int(time.time())}",\n            run_config={\n                "ops": {\n                    "process": {\n                        "config": {\n                            "concurrency": 2,\n                            "batch_size": 100,\n                            "priority": "low"\n                        }\n                    }\n                }\n            },\n            tags={"period": "business_hours"}\n        )\n\n    # \uc57c\uac04 (0-6\uc2dc)\n    elif current_hour < 6:\n        context.log.info("Off-peak hours - using aggressive settings")\n\n        yield RunRequest(\n            run_key=f"off_peak_{int(time.time())}",\n            run_config={\n                "ops": {\n                    "process": {\n                        "config": {\n                            "concurrency": 10,\n                            "batch_size": 1000,\n                            "priority": "high"\n                        }\n                    }\n                }\n            },\n            tags={"period": "off_peak"}\n        )\n\n    else:\n        return SkipReason(f"Outside processing window (current hour: {current_hour})")\n'})}),"\n",(0,r.jsx)(e.h2,{id:"\uc815\ub9ac",children:"\uc815\ub9ac"}),"\n",(0,r.jsx)(e.p,{children:"\uc774 \ubb38\uc11c\uc5d0\uc11c\ub294 Dagster\uc758 \uc2a4\ucf00\uc904\uacfc \uc13c\uc11c\uc5d0 \ub300\ud574 \uc0c1\uc138\ud788 \ub2e4\ub8e8\uc5c8\uc2b5\ub2c8\ub2e4:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Schedule"}),": \uc2dc\uac04 \uae30\ubc18 \uc790\ub3d9\ud654"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Cron \ud45c\ud604\uc2dd\uc744 \uc0ac\uc6a9\ud55c \uc815\uae30 \uc2e4\ud589"}),"\n",(0,r.jsx)(e.li,{children:"\ud30c\ud2f0\uc158\uacfc \uc5f0\ub3d9\ud55c \uc790\ub3d9\ud654"}),"\n",(0,r.jsx)(e.li,{children:"\uc2dc\uac04\ub300\uc640 \uc2e4\ud589 \uc870\uac74 \uc124\uc815"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Sensor"}),": \uc774\ubca4\ud2b8 \uae30\ubc18 \uc790\ub3d9\ud654"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\ud30c\uc77c, API, \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ub4f1 \uc678\ubd80 \uc774\ubca4\ud2b8 \uac10\uc9c0"}),"\n",(0,r.jsx)(e.li,{children:"Asset materialization \uae30\ubc18 \ud2b8\ub9ac\uac70"}),"\n",(0,r.jsx)(e.li,{children:"Run status \uae30\ubc18 \ud6c4\uc18d \uc791\uc5c5 \uc2e4\ud589"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(e.li,{children:["\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\uace0\uae09 \ud328\ud134"}),":"]}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Freshness \uad00\ub9ac\ub85c \ub370\uc774\ud130 \ucd5c\uc2e0\uc131 \ubcf4\uc7a5"}),"\n",(0,r.jsx)(e.li,{children:"Run coordination\uc73c\ub85c \ubcf5\uc7a1\ud55c \uc6cc\ud06c\ud50c\ub85c\uc6b0 \uc870\uc728"}),"\n",(0,r.jsx)(e.li,{children:"\uc870\uac74\ubd80 \uc2e4\ud589\uacfc \uc7ac\uc2dc\ub3c4 \ub85c\uc9c1"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"\uc2a4\ucf00\uc904\uacfc \uc13c\uc11c\ub97c \ud6a8\uacfc\uc801\uc73c\ub85c \ud65c\uc6a9\ud558\uba74 \ub370\uc774\ud130 \ud30c\uc774\ud504\ub77c\uc778\uc744 \uc644\uc804\ud788 \uc790\ub3d9\ud654\ud558\uace0, \uc774\ubca4\ud2b8\uc5d0 \uc989\uac01 \ubc18\uc751\ud558\ub294 \uac15\ub825\ud55c \uc2dc\uc2a4\ud15c\uc744 \uad6c\ucd95\ud560 \uc218 \uc788\uc2b5\ub2c8\ub2e4."})]})}function u(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(l,{...n})}):l(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>a,x:()=>i});var s=t(6540);const r={},o=s.createContext(r);function a(n){const e=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:a(n.components),s.createElement(o.Provider,{value:e},n.children)}}}]);