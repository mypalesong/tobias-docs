"use strict";(globalThis.webpackChunkgithub_docs=globalThis.webpackChunkgithub_docs||[]).push([[8216],{7662:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>i,default:()=>d,frontMatter:()=>l,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"prometheus/alerting","title":"5. Alerting","description":"Prometheus\uc758 \uc54c\ub9bc \uc2dc\uc2a4\ud15c\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uc2a4\ud15c \ubb38\uc81c\ub97c \uc2e4\uc2dc\uac04\uc73c\ub85c \uac10\uc9c0\ud558\uace0 \ub300\uc751\ud558\ub294 \ubc29\ubc95\uc744 \ubc30\uc6cc\ubcf4\uc138\uc694.","source":"@site/docs/prometheus/alerting.md","sourceDirName":"prometheus","slug":"/prometheus/alerting","permalink":"/docs/prometheus/alerting","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/prometheus/alerting.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"prometheusSidebar","previous":{"title":"4. Grafana \uc5f0\ub3d9","permalink":"/docs/prometheus/grafana"},"next":{"title":"6. \uc2e4\uc804 \uc608\uc81c","permalink":"/docs/prometheus/examples"}}');var a=t(4848),s=t(8453);const l={sidebar_position:5},i="5. Alerting",o={},c=[{value:"5.1 Alerting \uac1c\ub150",id:"51-alerting-\uac1c\ub150",level:2},{value:"Alert Rule\uacfc Alertmanager",id:"alert-rule\uacfc-alertmanager",level:3},{value:"Alert \uc0c1\ud0dc",id:"alert-\uc0c1\ud0dc",level:3},{value:"5.2 Alert Rule \uc791\uc131",id:"52-alert-rule-\uc791\uc131",level:2},{value:"\uae30\ubcf8 \uad6c\uc870",id:"\uae30\ubcf8-\uad6c\uc870",level:3},{value:"Alert Rule \uad6c\uc131 \uc694\uc18c",id:"alert-rule-\uad6c\uc131-\uc694\uc18c",level:3},{value:"\ud15c\ud50c\ub9bf \ubcc0\uc218",id:"\ud15c\ud50c\ub9bf-\ubcc0\uc218",level:3},{value:"5.3 Alertmanager \uc124\uce58 \ubc0f \uc124\uc815",id:"53-alertmanager-\uc124\uce58-\ubc0f-\uc124\uc815",level:2},{value:"Docker\ub85c \uc124\uce58",id:"docker\ub85c-\uc124\uce58",level:3},{value:"Alertmanager \uc124\uc815 \ud30c\uc77c",id:"alertmanager-\uc124\uc815-\ud30c\uc77c",level:3},{value:"Prometheus\uc5d0 Alertmanager \uc5f0\uacb0",id:"prometheus\uc5d0-alertmanager-\uc5f0\uacb0",level:3},{value:"5.4 \uc54c\ub9bc \ub77c\uc6b0\ud305",id:"54-\uc54c\ub9bc-\ub77c\uc6b0\ud305",level:2},{value:"Route Tree \uad6c\uc870",id:"route-tree-\uad6c\uc870",level:3},{value:"\uadf8\ub8f9\ud654 \uc635\uc158",id:"\uadf8\ub8f9\ud654-\uc635\uc158",level:3},{value:"5.5 \uc54c\ub9bc \ucc44\ub110",id:"55-\uc54c\ub9bc-\ucc44\ub110",level:2},{value:"Email",id:"email",level:3},{value:"Slack",id:"slack",level:3},{value:"PagerDuty",id:"pagerduty",level:3},{value:"Webhook (\ubc94\uc6a9)",id:"webhook-\ubc94\uc6a9",level:3},{value:"5.6 Silence\uc640 Inhibition",id:"56-silence\uc640-inhibition",level:2},{value:"Silence (\uc77c\uc2dc \uc815\uc9c0)",id:"silence-\uc77c\uc2dc-\uc815\uc9c0",level:3},{value:"Inhibition (\uc5b5\uc81c)",id:"inhibition-\uc5b5\uc81c",level:3},{value:"5.7 Alert \ud15c\ud50c\ub9bf",id:"57-alert-\ud15c\ud50c\ub9bf",level:2},{value:"\ud15c\ud50c\ub9bf \ud30c\uc77c \uc0dd\uc131",id:"\ud15c\ud50c\ub9bf-\ud30c\uc77c-\uc0dd\uc131",level:3},{value:"\ud15c\ud50c\ub9bf \uc801\uc6a9",id:"\ud15c\ud50c\ub9bf-\uc801\uc6a9",level:3},{value:"\ud15c\ud50c\ub9bf \ud568\uc218",id:"\ud15c\ud50c\ub9bf-\ud568\uc218",level:3},{value:"5.8 Python\uc73c\ub85c Webhook \uc218\uc2e0\uae30 \uad6c\ud604",id:"58-python\uc73c\ub85c-webhook-\uc218\uc2e0\uae30-\uad6c\ud604",level:2},{value:"FastAPI Webhook \uc11c\ubc84",id:"fastapi-webhook-\uc11c\ubc84",level:3},{value:"Alert \uc774\ub825 \uad00\ub9ac",id:"alert-\uc774\ub825-\uad00\ub9ac",level:3},{value:"5.9 Python\uc73c\ub85c \ud504\ub85c\uadf8\ub798\ub9e4\ud2f1 \uc54c\ub9bc \ubc1c\uc1a1",id:"59-python\uc73c\ub85c-\ud504\ub85c\uadf8\ub798\ub9e4\ud2f1-\uc54c\ub9bc-\ubc1c\uc1a1",level:2},{value:"Alertmanager API \ud074\ub77c\uc774\uc5b8\ud2b8",id:"alertmanager-api-\ud074\ub77c\uc774\uc5b8\ud2b8",level:3},{value:"\ube44\uc988\ub2c8\uc2a4 \uba54\ud2b8\ub9ad \uae30\ubc18 \uc54c\ub9bc",id:"\ube44\uc988\ub2c8\uc2a4-\uba54\ud2b8\ub9ad-\uae30\ubc18-\uc54c\ub9bc",level:3},{value:"5.10 \uc2e4\uc804 Alert Rule \uc608\uc81c",id:"510-\uc2e4\uc804-alert-rule-\uc608\uc81c",level:2},{value:"High Error Rate",id:"high-error-rate",level:3},{value:"High Latency",id:"high-latency",level:3},{value:"Service Down",id:"service-down",level:3},{value:"Database Alerts",id:"database-alerts",level:3},{value:"Resource Alerts",id:"resource-alerts",level:3},{value:"5.11 Alert \ud53c\ub85c \ubc29\uc9c0 \uc804\ub7b5",id:"511-alert-\ud53c\ub85c-\ubc29\uc9c0-\uc804\ub7b5",level:2},{value:"1. \uc801\uc808\ud55c \uc784\uacc4\uac12 \uc124\uc815",id:"1-\uc801\uc808\ud55c-\uc784\uacc4\uac12-\uc124\uc815",level:3},{value:"2. \uadf8\ub8f9\ud654\ub85c \uc54c\ub9bc \ud1b5\ud569",id:"2-\uadf8\ub8f9\ud654\ub85c-\uc54c\ub9bc-\ud1b5\ud569",level:3},{value:"3. Severity \ub808\ubca8 \ud65c\uc6a9",id:"3-severity-\ub808\ubca8-\ud65c\uc6a9",level:3},{value:"4. Runbook \ub9c1\ud06c \uc81c\uacf5",id:"4-runbook-\ub9c1\ud06c-\uc81c\uacf5",level:3},{value:"5. Alert \uc720\ud6a8\uc131 \uc815\uae30 \uac80\ud1a0",id:"5-alert-\uc720\ud6a8\uc131-\uc815\uae30-\uac80\ud1a0",level:3},{value:"6. \uc5c5\ubb34 \uc2dc\uac04 \uae30\ubc18 \ub77c\uc6b0\ud305",id:"6-\uc5c5\ubb34-\uc2dc\uac04-\uae30\ubc18-\ub77c\uc6b0\ud305",level:3},{value:"5.12 \ubca0\uc2a4\ud2b8 \ud504\ub799\ud2f0\uc2a4",id:"512-\ubca0\uc2a4\ud2b8-\ud504\ub799\ud2f0\uc2a4",level:2},{value:"1. Alert Rule \uc791\uc131",id:"1-alert-rule-\uc791\uc131",level:3},{value:"2. \uc54c\ub9bc \uad6c\uc870\ud654",id:"2-\uc54c\ub9bc-\uad6c\uc870\ud654",level:3},{value:"3. \ub77c\uc6b0\ud305 \uc804\ub7b5",id:"3-\ub77c\uc6b0\ud305-\uc804\ub7b5",level:3},{value:"4. Inhibition \ud65c\uc6a9",id:"4-inhibition-\ud65c\uc6a9",level:3},{value:"5. \uc54c\ub9bc \ud14c\uc2a4\ud2b8",id:"5-\uc54c\ub9bc-\ud14c\uc2a4\ud2b8",level:3},{value:"6. \ubaa8\ub2c8\ud130\ub9c1 \ubc0f \uac1c\uc120",id:"6-\ubaa8\ub2c8\ud130\ub9c1-\ubc0f-\uac1c\uc120",level:3},{value:"\uc5f0\uc2b5 \ubb38\uc81c",id:"\uc5f0\uc2b5-\ubb38\uc81c",level:2},{value:"\ubb38\uc81c 1: Basic Alert Rule",id:"\ubb38\uc81c-1-basic-alert-rule",level:3},{value:"\ubb38\uc81c 2: Webhook \uc218\uc2e0\uae30",id:"\ubb38\uc81c-2-webhook-\uc218\uc2e0\uae30",level:3},{value:"\ubb38\uc81c 3: Silence \uc790\ub3d9\ud654",id:"\ubb38\uc81c-3-silence-\uc790\ub3d9\ud654",level:3}];function m(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"5-alerting",children:"5. Alerting"})}),"\n",(0,a.jsx)(n.p,{children:"Prometheus\uc758 \uc54c\ub9bc \uc2dc\uc2a4\ud15c\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc2dc\uc2a4\ud15c \ubb38\uc81c\ub97c \uc2e4\uc2dc\uac04\uc73c\ub85c \uac10\uc9c0\ud558\uace0 \ub300\uc751\ud558\ub294 \ubc29\ubc95\uc744 \ubc30\uc6cc\ubcf4\uc138\uc694."}),"\n",(0,a.jsx)(n.h2,{id:"51-alerting-\uac1c\ub150",children:"5.1 Alerting \uac1c\ub150"}),"\n",(0,a.jsx)(n.h3,{id:"alert-rule\uacfc-alertmanager",children:"Alert Rule\uacfc Alertmanager"}),"\n",(0,a.jsx)(n.p,{children:"Prometheus\uc758 \uc54c\ub9bc \uc2dc\uc2a4\ud15c\uc740 \ub450 \uac00\uc9c0 \uc8fc\uc694 \ucef4\ud3ec\ub10c\ud2b8\ub85c \uad6c\uc131\ub429\ub2c8\ub2e4:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Prometheus  \u2502\n\u2502   Server     \u2502\n\u2502              \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502 \u2502  Alert   \u2502 \u2502  Alert Rule \ud3c9\uac00\n\u2502 \u2502  Rules   \u2502 \u2502  (PromQL \uae30\ubc18)\n\u2502 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 Firing Alerts\n       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Alertmanager \u2502  \uadf8\ub8f9\ud654, \ub77c\uc6b0\ud305, Silence\n\u2502              \u2502  \uc54c\ub9bc \ucc44\ub110\ub85c \ubc1c\uc1a1\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n   \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u25bc       \u25bc         \u25bc          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Email\u2502 \u2502Slack\u2502 \u2502PagerDuty\u2502 \u2502Webhook\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Prometheus Server:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Alert Rule\uc744 \uc8fc\uae30\uc801\uc73c\ub85c \ud3c9\uac00"}),"\n",(0,a.jsx)(n.li,{children:"\uc870\uac74\uc774 \ucda9\uc871\ub418\uba74 Alert\ub97c Firing \uc0c1\ud0dc\ub85c \uc804\ud658"}),"\n",(0,a.jsx)(n.li,{children:"Alertmanager\ub85c Alert \uc804\uc1a1"}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Alertmanager:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Alert \uc218\uc2e0 \ubc0f \uadf8\ub8f9\ud654"}),"\n",(0,a.jsx)(n.li,{children:"Silence \ubc0f Inhibition \ucc98\ub9ac"}),"\n",(0,a.jsx)(n.li,{children:"\ub77c\uc6b0\ud305 \uaddc\uce59\uc5d0 \ub530\ub77c \uc54c\ub9bc \ucc44\ub110\ub85c \ubc1c\uc1a1"}),"\n",(0,a.jsx)(n.li,{children:"\uc54c\ub9bc \uc911\ubcf5 \uc81c\uac70 (Deduplication)"}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"alert-\uc0c1\ud0dc",children:"Alert \uc0c1\ud0dc"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Inactive \u2502  \uc870\uac74 \ubbf8\ucda9\uc871\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502 \uc870\uac74 \ucda9\uc871\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Pending  \u2502  for \uae30\uac04 \ub300\uae30 \uc911\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502 for \uae30\uac04 \uacbd\uacfc\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Firing   \u2502  Alert \ubc1c\uc1a1\n\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502 \uc870\uac74 \ubbf8\ucda9\uc871\n     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Resolved \u2502  \ubcf5\uad6c\ub428\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.admonition,{title:"for \uc808\uc758 \uc911\uc694\uc131",type:"tip",children:(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"for"})," \uc808\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc77c\uc2dc\uc801\uc778 \uc2a4\ud30c\uc774\ud06c\ub85c \uc778\ud55c \ubd88\ud544\uc694\ud55c \uc54c\ub9bc\uc744 \ubc29\uc9c0\ud558\uc138\uc694.\n\uc608: ",(0,a.jsx)(n.code,{children:"for: 5m"}),"\uc740 \uc870\uac74\uc774 5\ubd84 \uc774\uc0c1 \uc9c0\uc18d\ub420 \ub54c\ub9cc \uc54c\ub9bc\uc744 \ubc1c\uc1a1\ud569\ub2c8\ub2e4."]})}),"\n",(0,a.jsx)(n.h2,{id:"52-alert-rule-\uc791\uc131",children:"5.2 Alert Rule \uc791\uc131"}),"\n",(0,a.jsx)(n.h3,{id:"\uae30\ubcf8-\uad6c\uc870",children:"\uae30\ubcf8 \uad6c\uc870"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'# /etc/prometheus/alerts.yml\ngroups:\n  - name: example_alerts\n    interval: 30s  # \ud3c9\uac00 \uc8fc\uae30 (\uae30\ubcf8\uac12: 1m)\n    rules:\n      - alert: HighErrorRate\n        expr: |\n          rate(http_requests_total{status=~"5.."}[5m])\n          / rate(http_requests_total[5m]) > 0.05\n        for: 5m\n        labels:\n          severity: critical\n          team: backend\n        annotations:\n          summary: "\ub192\uc740 \uc5d0\ub7ec\uc728 \uac10\uc9c0"\n          description: "{{ $labels.instance }}\uc5d0\uc11c \uc5d0\ub7ec\uc728\uc774 {{ $value | humanizePercentage }}\uc785\ub2c8\ub2e4."\n'})}),"\n",(0,a.jsx)(n.h3,{id:"alert-rule-\uad6c\uc131-\uc694\uc18c",children:"Alert Rule \uad6c\uc131 \uc694\uc18c"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"- alert: AlertName          # Alert \uc774\ub984 (PascalCase \uad8c\uc7a5)\n  expr: <PromQL>            # PromQL \ud45c\ud604\uc2dd (boolean \uacb0\uacfc)\n  for: <duration>           # Pending \uc9c0\uc18d \uc2dc\uac04 (\uc120\ud0dd)\n  labels:                   # \ub77c\uc6b0\ud305\uc6a9 \ub808\uc774\ube14\n    <label_name>: <value>\n  annotations:              # \uc54c\ub9bc \uba54\uc2dc\uc9c0\uc6a9 \uc815\ubcf4\n    <annotation_name>: <template>\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uc8fc\uc694 \ud544\ub4dc:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"expr"}),": Alert \uc870\uac74\uc744 \uc815\uc758\ud558\ub294 PromQL \ucffc\ub9ac"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"for"}),": Alert\uac00 Firing\ub418\uae30 \uc804 \ub300\uae30 \uc2dc\uac04"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"labels"}),": \ub77c\uc6b0\ud305 \ubc0f \uadf8\ub8f9\ud654\uc5d0 \uc0ac\uc6a9"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"annotations"}),": \uc54c\ub9bc \uba54\uc2dc\uc9c0\uc5d0 \ud3ec\ud568\ub420 \uc0c1\uc138 \uc815\ubcf4"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"\ud15c\ud50c\ub9bf-\ubcc0\uc218",children:"\ud15c\ud50c\ub9bf \ubcc0\uc218"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'annotations:\n  summary: "{{ $labels.instance }}\uc5d0\uc11c \ubb38\uc81c \ubc1c\uc0dd"\n  description: |\n    \ud604\uc7ac \uac12: {{ $value }}\n    \uc778\uc2a4\ud134\uc2a4: {{ $labels.instance }}\n    \uc791\uc5c5: {{ $labels.job }}\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uc0ac\uc6a9 \uac00\ub2a5\ud55c \ubcc0\uc218:"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"{{ $labels.<label_name> }}"}),": Alert\uc758 \ub808\uc774\ube14 \uac12"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"{{ $value }}"}),": PromQL \ud45c\ud604\uc2dd \uacb0\uacfc\uac12"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"{{ $externalLabels }}"}),": Prometheus \uc678\ubd80 \ub808\uc774\ube14"]}),"\n"]}),"\n",(0,a.jsx)(n.admonition,{title:"\ub808\uc774\ube14 vs \uc5b4\ub178\ud14c\uc774\uc158",type:"warning",children:(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Labels"}),": \ub77c\uc6b0\ud305, \uadf8\ub8f9\ud654, Silence\uc5d0 \uc0ac\uc6a9 (\uac04\uacb0\ud558\uac8c)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Annotations"}),": \uc0ac\ub78c\uc774 \uc77d\uc744 \uc815\ubcf4 (\uc0c1\uc138\ud558\uac8c)"]}),"\n"]})}),"\n",(0,a.jsx)(n.h2,{id:"53-alertmanager-\uc124\uce58-\ubc0f-\uc124\uc815",children:"5.3 Alertmanager \uc124\uce58 \ubc0f \uc124\uc815"}),"\n",(0,a.jsx)(n.h3,{id:"docker\ub85c-\uc124\uce58",children:"Docker\ub85c \uc124\uce58"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Alertmanager \uc2e4\ud589\ndocker run -d \\\n  --name alertmanager \\\n  -p 9093:9093 \\\n  -v /path/to/alertmanager.yml:/etc/alertmanager/alertmanager.yml \\\n  prom/alertmanager:latest\n"})}),"\n",(0,a.jsx)(n.h3,{id:"alertmanager-\uc124\uc815-\ud30c\uc77c",children:"Alertmanager \uc124\uc815 \ud30c\uc77c"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# alertmanager.yml\nglobal:\n  # \uae30\ubcf8 \uc124\uc815\n  resolve_timeout: 5m\n  smtp_smarthost: 'smtp.gmail.com:587'\n  smtp_from: 'alertmanager@example.com'\n  smtp_auth_username: 'alertmanager@example.com'\n  smtp_auth_password: 'password'\n\n# \ud15c\ud50c\ub9bf \ud30c\uc77c \uacbd\ub85c\ntemplates:\n  - '/etc/alertmanager/templates/*.tmpl'\n\n# \ub77c\uc6b0\ud305 \uaddc\uce59\nroute:\n  group_by: ['alertname', 'cluster', 'service']\n  group_wait: 10s\n  group_interval: 10s\n  repeat_interval: 12h\n  receiver: 'team-default'\n\n  routes:\n    - match:\n        severity: critical\n      receiver: 'team-pager'\n      continue: true\n\n    - match:\n        severity: warning\n      receiver: 'team-slack'\n\n# \uc218\uc2e0\uc790 \uc124\uc815\nreceivers:\n  - name: 'team-default'\n    email_configs:\n      - to: 'team@example.com'\n\n  - name: 'team-pager'\n    pagerduty_configs:\n      - service_key: '<pagerduty-key>'\n\n  - name: 'team-slack'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXX'\n        channel: '#alerts'\n\n# Inhibition rules\ninhibit_rules:\n  - source_match:\n      severity: 'critical'\n    target_match:\n      severity: 'warning'\n    equal: ['alertname', 'instance']\n"})}),"\n",(0,a.jsx)(n.h3,{id:"prometheus\uc5d0-alertmanager-\uc5f0\uacb0",children:"Prometheus\uc5d0 Alertmanager \uc5f0\uacb0"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# prometheus.yml\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n            - 'alertmanager:9093'\n\n# Alert Rule \ud30c\uc77c \ub85c\ub4dc\nrule_files:\n  - '/etc/prometheus/alerts/*.yml'\n"})}),"\n",(0,a.jsx)(n.h2,{id:"54-\uc54c\ub9bc-\ub77c\uc6b0\ud305",children:"5.4 \uc54c\ub9bc \ub77c\uc6b0\ud305"}),"\n",(0,a.jsx)(n.h3,{id:"route-tree-\uad6c\uc870",children:"Route Tree \uad6c\uc870"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"route:\n  receiver: 'default-receiver'\n  group_by: ['alertname']\n\n  routes:\n    # Database \ud300\n    - match:\n        team: database\n      receiver: 'database-team'\n      group_by: ['alertname', 'instance']\n\n      routes:\n        # Critical alerts\ub294 PagerDuty\ub85c\n        - match:\n            severity: critical\n          receiver: 'database-pager'\n\n        # Warning alerts\ub294 Slack\uc73c\ub85c\n        - match:\n            severity: warning\n          receiver: 'database-slack'\n\n    # Backend \ud300\n    - match:\n        team: backend\n      receiver: 'backend-team'\n\n      routes:\n        - match_re:\n            service: ^(api|web)$\n          receiver: 'backend-web-team'\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\uadf8\ub8f9\ud654-\uc635\uc158",children:"\uadf8\ub8f9\ud654 \uc635\uc158"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"route:\n  # \uadf8\ub8f9\ud654 \uae30\uc900\n  group_by: ['alertname', 'cluster', 'service']\n\n  # \uccab \uc54c\ub9bc \uc804 \ub300\uae30 \uc2dc\uac04 (\uac19\uc740 \uadf8\ub8f9\uc758 \ub2e4\ub978 \uc54c\ub9bc \uc218\uc9d1)\n  group_wait: 10s\n\n  # \uadf8\ub8f9\uc5d0 \uc0c8 \uc54c\ub9bc \ucd94\uac00 \uc2dc \ub300\uae30 \uc2dc\uac04\n  group_interval: 5m\n\n  # \ub3d9\uc77c \uc54c\ub9bc \uc7ac\uc804\uc1a1 \uac04\uaca9\n  repeat_interval: 4h\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uadf8\ub8f9\ud654 \uc804\ub7b5:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# \uc804\ub7b5 1: \uc11c\ube44\uc2a4\ubcc4 \uadf8\ub8f9\ud654\ngroup_by: ['service']\n# \u2192 \uc11c\ube44\uc2a4 \ub2e8\uc704\ub85c \ubaa8\ub4e0 \uc54c\ub9bc\uc744 \ud558\ub098\ub85c \ubb36\uc74c\n\n# \uc804\ub7b5 2: \uc54c\ub9bc \uc774\ub984\ubcc4 \uadf8\ub8f9\ud654\ngroup_by: ['alertname']\n# \u2192 \uac19\uc740 \uc885\ub958\uc758 \uc54c\ub9bc\ub07c\ub9ac \ubb36\uc74c\n\n# \uc804\ub7b5 3: \ub2e4\ucc28\uc6d0 \uadf8\ub8f9\ud654\ngroup_by: ['alertname', 'cluster', 'namespace']\n# \u2192 \uc54c\ub9bc \uc885\ub958 + \ud074\ub7ec\uc2a4\ud130 + \ub124\uc784\uc2a4\ud398\uc774\uc2a4\ub85c \uc138\ubd84\ud654\n"})}),"\n",(0,a.jsx)(n.h2,{id:"55-\uc54c\ub9bc-\ucc44\ub110",children:"5.5 \uc54c\ub9bc \ucc44\ub110"}),"\n",(0,a.jsx)(n.h3,{id:"email",children:"Email"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'email-team'\n    email_configs:\n      - to: 'team@example.com'\n        from: 'alertmanager@example.com'\n        smarthost: 'smtp.gmail.com:587'\n        auth_username: 'alertmanager@example.com'\n        auth_password: 'app-password'\n        headers:\n          Subject: '[ALERT] {{ .GroupLabels.alertname }}'\n        html: |\n          <!DOCTYPE html>\n          <html>\n          <body>\n            <h2>Alert: {{ .GroupLabels.alertname }}</h2>\n            <p><b>Severity:</b> {{ .CommonLabels.severity }}</p>\n            <h3>Firing Alerts:</h3>\n            <ul>\n            {{ range .Alerts.Firing }}\n              <li>{{ .Labels.instance }}: {{ .Annotations.summary }}</li>\n            {{ end }}\n            </ul>\n          </body>\n          </html>\n"})}),"\n",(0,a.jsx)(n.h3,{id:"slack",children:"Slack"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'slack-alerts'\n    slack_configs:\n      - api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'\n        channel: '#alerts'\n        username: 'Alertmanager'\n        icon_emoji: ':warning:'\n        title: 'Alert: {{ .GroupLabels.alertname }}'\n        text: |\n          {{ range .Alerts }}\n          *Severity:* {{ .Labels.severity }}\n          *Summary:* {{ .Annotations.summary }}\n          *Description:* {{ .Annotations.description }}\n          {{ end }}\n        send_resolved: true\n        color: '{{ if eq .Status \"firing\" }}danger{{ else }}good{{ end }}'\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Slack Webhook \uc0dd\uc131:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# 1. Slack\uc5d0\uc11c Incoming Webhook \uc0dd\uc131\n# https://api.slack.com/messaging/webhooks\n\n# 2. Webhook URL \ubc1b\uae30\n# https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXX\n\n# 3. \ud14c\uc2a4\ud2b8\ncurl -X POST -H 'Content-type: application/json' \\\n  --data '{\"text\":\"Test alert from Alertmanager\"}' \\\n  YOUR_WEBHOOK_URL\n"})}),"\n",(0,a.jsx)(n.h3,{id:"pagerduty",children:"PagerDuty"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'pagerduty-critical'\n    pagerduty_configs:\n      - service_key: '<integration-key>'\n        severity: 'critical'\n        description: '{{ .CommonAnnotations.summary }}'\n        details:\n          firing: '{{ .Alerts.Firing | len }}'\n          resolved: '{{ .Alerts.Resolved | len }}'\n          instance: '{{ .CommonLabels.instance }}'\n"})}),"\n",(0,a.jsx)(n.h3,{id:"webhook-\ubc94\uc6a9",children:"Webhook (\ubc94\uc6a9)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"receivers:\n  - name: 'custom-webhook'\n    webhook_configs:\n      - url: 'http://localhost:8000/alerts'\n        send_resolved: true\n        http_config:\n          basic_auth:\n            username: 'admin'\n            password: 'secret'\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Webhook \ud398\uc774\ub85c\ub4dc \uad6c\uc870:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-json",children:'{\n  "receiver": "custom-webhook",\n  "status": "firing",\n  "alerts": [\n    {\n      "status": "firing",\n      "labels": {\n        "alertname": "HighErrorRate",\n        "instance": "web-1",\n        "severity": "critical"\n      },\n      "annotations": {\n        "summary": "\ub192\uc740 \uc5d0\ub7ec\uc728 \uac10\uc9c0",\n        "description": "web-1\uc5d0\uc11c \uc5d0\ub7ec\uc728\uc774 5.2%\uc785\ub2c8\ub2e4."\n      },\n      "startsAt": "2024-01-15T10:00:00Z",\n      "endsAt": "0001-01-01T00:00:00Z",\n      "generatorURL": "http://prometheus:9090/graph?g0.expr=..."\n    }\n  ],\n  "groupLabels": {\n    "alertname": "HighErrorRate"\n  },\n  "commonLabels": {\n    "alertname": "HighErrorRate",\n    "severity": "critical"\n  },\n  "commonAnnotations": {\n    "summary": "\ub192\uc740 \uc5d0\ub7ec\uc728 \uac10\uc9c0"\n  },\n  "externalURL": "http://alertmanager:9093"\n}\n'})}),"\n",(0,a.jsx)(n.h2,{id:"56-silence\uc640-inhibition",children:"5.6 Silence\uc640 Inhibition"}),"\n",(0,a.jsx)(n.h3,{id:"silence-\uc77c\uc2dc-\uc815\uc9c0",children:"Silence (\uc77c\uc2dc \uc815\uc9c0)"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"UI\uc5d0\uc11c Silence \uc0dd\uc131:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:'1. http://alertmanager:9093 \uc811\uc18d\n2. "Silences" \ud0ed \ud074\ub9ad\n3. "New Silence" \ubc84\ud2bc \ud074\ub9ad\n4. Matcher \uc124\uc815 (\uc608: alertname="HighCPU", instance="web-1")\n5. \uae30\uac04 \uc124\uc815 (\uc608: 2\uc2dc\uac04)\n6. \uc0dd\uc131\uc790 \ubc0f \ucf54\uba58\ud2b8 \uc785\ub825\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"API\ub85c Silence \uc0dd\uc131:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'# Silence \uc0dd\uc131\ncurl -X POST http://alertmanager:9093/api/v2/silences \\\n  -H \'Content-Type: application/json\' \\\n  -d \'{\n    "matchers": [\n      {\n        "name": "alertname",\n        "value": "HighCPU",\n        "isRegex": false\n      },\n      {\n        "name": "instance",\n        "value": "web-1",\n        "isRegex": false\n      }\n    ],\n    "startsAt": "2024-01-15T10:00:00Z",\n    "endsAt": "2024-01-15T12:00:00Z",\n    "createdBy": "admin",\n    "comment": "\uc11c\ubc84 \uc720\uc9c0\ubcf4\uc218 \uc791\uc5c5 \uc911"\n  }\'\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Python\uc73c\ub85c Silence \uad00\ub9ac:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import requests\nfrom datetime import datetime, timedelta\n\nclass AlertmanagerSilence:\n    def __init__(self, alertmanager_url: str):\n        self.url = alertmanager_url\n\n    def create_silence(\n        self,\n        matchers: dict,\n        duration_hours: int,\n        created_by: str,\n        comment: str\n    ) -> str:\n        """Silence \uc0dd\uc131"""\n        start = datetime.utcnow()\n        end = start + timedelta(hours=duration_hours)\n\n        silence = {\n            "matchers": [\n                {\n                    "name": k,\n                    "value": v,\n                    "isRegex": False\n                }\n                for k, v in matchers.items()\n            ],\n            "startsAt": start.isoformat() + "Z",\n            "endsAt": end.isoformat() + "Z",\n            "createdBy": created_by,\n            "comment": comment\n        }\n\n        response = requests.post(\n            f"{self.url}/api/v2/silences",\n            json=silence\n        )\n        response.raise_for_status()\n\n        silence_id = response.json()["silenceID"]\n        print(f"Silence created: {silence_id}")\n        return silence_id\n\n    def delete_silence(self, silence_id: str):\n        """Silence \uc0ad\uc81c"""\n        response = requests.delete(\n            f"{self.url}/api/v2/silence/{silence_id}"\n        )\n        response.raise_for_status()\n        print(f"Silence deleted: {silence_id}")\n\n    def list_silences(self) -> list:\n        """\ud65c\uc131 Silence \ubaa9\ub85d"""\n        response = requests.get(f"{self.url}/api/v2/silences")\n        response.raise_for_status()\n        return response.json()\n\n# \uc0ac\uc6a9 \uc608\uc81c\nam = AlertmanagerSilence("http://localhost:9093")\n\n# \uc720\uc9c0\ubcf4\uc218\ub97c \uc704\ud55c Silence \uc0dd\uc131\nsilence_id = am.create_silence(\n    matchers={"instance": "web-1"},\n    duration_hours=2,\n    created_by="ops-team",\n    comment="\uc11c\ubc84 \ud328\uce58 \uc791\uc5c5"\n)\n\n# \uc791\uc5c5 \uc644\ub8cc \ud6c4 Silence \ud574\uc81c\nam.delete_silence(silence_id)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"inhibition-\uc5b5\uc81c",children:"Inhibition (\uc5b5\uc81c)"}),"\n",(0,a.jsx)(n.p,{children:"Critical alert\uac00 \ubc1c\uc0dd\ud558\uba74 \uad00\ub828\ub41c warning alert \uc5b5\uc81c:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# alertmanager.yml\ninhibit_rules:\n  # Critical\uc774\uba74 Warning \uc5b5\uc81c\n  - source_match:\n      severity: critical\n    target_match:\n      severity: warning\n    equal: ['alertname', 'instance']\n\n  # \uc11c\ube44\uc2a4 Down\uc774\uba74 \ubaa8\ub4e0 \uc54c\ub9bc \uc5b5\uc81c\n  - source_match:\n      alertname: ServiceDown\n    target_match_re:\n      alertname: (HighLatency|HighErrorRate)\n    equal: ['service']\n\n  # \ub178\ub4dc Down\uc774\uba74 \ud574\ub2f9 \ub178\ub4dc\uc758 \ubaa8\ub4e0 \uc54c\ub9bc \uc5b5\uc81c\n  - source_match:\n      alertname: NodeDown\n    target_match_re:\n      alertname: .*\n    equal: ['instance']\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"Inhibition \ub3d9\uc791 \ubc29\uc2dd:"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Critical Alert      \u2502\n\u2502  (source)            \u2502\n\u2502  - alertname: NodeDown\n\u2502  - instance: web-1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502 inhibits\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Warning Alerts      \u2502\n\u2502  (target)            \u2502\n\u2502  - alertname: HighCPU\n\u2502  - instance: web-1   \u2502 \u2190 \uc5b5\uc81c\ub428\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,a.jsx)(n.h2,{id:"57-alert-\ud15c\ud50c\ub9bf",children:"5.7 Alert \ud15c\ud50c\ub9bf"}),"\n",(0,a.jsx)(n.h3,{id:"\ud15c\ud50c\ub9bf-\ud30c\uc77c-\uc0dd\uc131",children:"\ud15c\ud50c\ub9bf \ud30c\uc77c \uc0dd\uc131"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'{{ define "slack.title" }}\n[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.alertname }}\n{{ end }}\n\n{{ define "slack.text" }}\n{{ range .Alerts }}\n*Alert:* {{ .Labels.alertname }}\n*Severity:* {{ .Labels.severity }}\n*Instance:* {{ .Labels.instance }}\n*Summary:* {{ .Annotations.summary }}\n*Description:* {{ .Annotations.description }}\n*Graph:* <{{ .GeneratorURL }}|View in Prometheus>\n{{ end }}\n{{ end }}\n\n{{ define "email.subject" }}\n[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }} ({{ .Alerts.Firing | len }})\n{{ end }}\n\n{{ define "email.html" }}\n<!DOCTYPE html>\n<html>\n<head>\n  <style>\n    body { font-family: Arial, sans-serif; }\n    .alert { margin: 20px 0; padding: 15px; border-left: 4px solid #f44336; }\n    .critical { border-left-color: #f44336; background: #ffebee; }\n    .warning { border-left-color: #ff9800; background: #fff3e0; }\n    .info { border-left-color: #2196f3; background: #e3f2fd; }\n  </style>\n</head>\n<body>\n  <h2>{{ .GroupLabels.alertname }}</h2>\n  <p><strong>Status:</strong> {{ .Status }}</p>\n  <p><strong>Firing:</strong> {{ .Alerts.Firing | len }} alerts</p>\n\n  <h3>Details:</h3>\n  {{ range .Alerts }}\n  <div class="alert {{ .Labels.severity }}">\n    <h4>{{ .Labels.instance }}</h4>\n    <p><strong>Summary:</strong> {{ .Annotations.summary }}</p>\n    <p><strong>Description:</strong> {{ .Annotations.description }}</p>\n    <p><strong>Started:</strong> {{ .StartsAt }}</p>\n    <p><a href="{{ .GeneratorURL }}">View in Prometheus</a></p>\n  </div>\n  {{ end }}\n</body>\n</html>\n{{ end }}\n'})}),"\n",(0,a.jsx)(n.h3,{id:"\ud15c\ud50c\ub9bf-\uc801\uc6a9",children:"\ud15c\ud50c\ub9bf \uc801\uc6a9"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# alertmanager.yml\nglobal:\n  # \ud15c\ud50c\ub9bf \ud30c\uc77c \uacbd\ub85c\n  templates:\n    - '/etc/alertmanager/templates/*.tmpl'\n\nreceivers:\n  - name: 'slack-custom'\n    slack_configs:\n      - api_url: 'YOUR_WEBHOOK_URL'\n        channel: '#alerts'\n        title: '{{ template \"slack.title\" . }}'\n        text: '{{ template \"slack.text\" . }}'\n\n  - name: 'email-custom'\n    email_configs:\n      - to: 'team@example.com'\n        headers:\n          Subject: '{{ template \"email.subject\" . }}'\n        html: '{{ template \"email.html\" . }}'\n"})}),"\n",(0,a.jsx)(n.h3,{id:"\ud15c\ud50c\ub9bf-\ud568\uc218",children:"\ud15c\ud50c\ub9bf \ud568\uc218"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-go",children:'{{ define "custom.template" }}\n# \ubb38\uc790\uc5f4 \uc870\uc791\n{{ .Labels.alertname | toUpper }}\n{{ .Labels.instance | title }}\n\n# \uc22b\uc790 \ud3ec\ub9f7\n{{ .Value | humanize }}          # 1234.5 \u2192 "1.235k"\n{{ .Value | humanizePercentage }} # 0.05 \u2192 "5%"\n{{ .Value | humanizeDuration }}  # 3661 \u2192 "1h 1m 1s"\n\n# \ub0a0\uc9dc/\uc2dc\uac04\n{{ .StartsAt | date "2006-01-02 15:04:05" }}\n\n# \uc870\uac74\ubb38\n{{ if eq .Status "firing" }}\n  Alert is firing!\n{{ else }}\n  Alert is resolved.\n{{ end }}\n\n# \ubc18\ubcf5\ubb38\n{{ range .Alerts }}\n  - {{ .Labels.instance }}: {{ .Annotations.summary }}\n{{ end }}\n\n# \ubcc0\uc218\n{{ $severity := .Labels.severity }}\nSeverity is {{ $severity }}\n{{ end }}\n'})}),"\n",(0,a.jsx)(n.h2,{id:"58-python\uc73c\ub85c-webhook-\uc218\uc2e0\uae30-\uad6c\ud604",children:"5.8 Python\uc73c\ub85c Webhook \uc218\uc2e0\uae30 \uad6c\ud604"}),"\n",(0,a.jsx)(n.h3,{id:"fastapi-webhook-\uc11c\ubc84",children:"FastAPI Webhook \uc11c\ubc84"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI, Request\nfrom pydantic import BaseModel\nfrom typing import List, Dict, Any\nfrom datetime import datetime\nimport httpx\n\napp = FastAPI(title="Prometheus Alertmanager Webhook Receiver")\n\nclass Alert(BaseModel):\n    status: str\n    labels: Dict[str, str]\n    annotations: Dict[str, str]\n    startsAt: str\n    endsAt: str\n    generatorURL: str\n\nclass AlertWebhook(BaseModel):\n    receiver: str\n    status: str\n    alerts: List[Alert]\n    groupLabels: Dict[str, str]\n    commonLabels: Dict[str, str]\n    commonAnnotations: Dict[str, str]\n    externalURL: str\n\n# \uc54c\ub9bc \ucc98\ub9ac \ud578\ub4e4\ub7ec\nclass AlertHandler:\n    """Alert \ucc98\ub9ac \ub85c\uc9c1"""\n\n    def __init__(self):\n        self.slack_webhook_url = "YOUR_SLACK_WEBHOOK_URL"\n\n    async def handle_alert(self, webhook: AlertWebhook):\n        """Alert \uc218\uc2e0 \ubc0f \ucc98\ub9ac"""\n        if webhook.status == "firing":\n            await self.handle_firing(webhook)\n        else:\n            await self.handle_resolved(webhook)\n\n    async def handle_firing(self, webhook: AlertWebhook):\n        """Firing \uc54c\ub9bc \ucc98\ub9ac"""\n        print(f"\ud83d\udd25 Alert Firing: {webhook.groupLabels.get(\'alertname\')}")\n\n        for alert in webhook.alerts:\n            severity = alert.labels.get(\'severity\', \'unknown\')\n\n            # Critical alert\ub294 \uc989\uc2dc Slack \uc54c\ub9bc\n            if severity == \'critical\':\n                await self.send_slack_notification(alert)\n\n            # \ub370\uc774\ud130\ubca0\uc774\uc2a4\uc5d0 \uc800\uc7a5\n            await self.save_to_database(alert)\n\n            # \uc790\ub3d9 \ub300\uc751 \uc2e4\ud589\n            await self.auto_remediation(alert)\n\n    async def handle_resolved(self, webhook: AlertWebhook):\n        """Resolved \uc54c\ub9bc \ucc98\ub9ac"""\n        print(f"\u2705 Alert Resolved: {webhook.groupLabels.get(\'alertname\')}")\n\n        for alert in webhook.alerts:\n            # \ubcf5\uad6c \uc54c\ub9bc\n            await self.send_resolution_notification(alert)\n\n    async def send_slack_notification(self, alert: Alert):\n        """Slack \uc54c\ub9bc \uc804\uc1a1"""\n        message = {\n            "text": f"\ud83d\udea8 {alert.annotations.get(\'summary\')}",\n            "attachments": [\n                {\n                    "color": "danger",\n                    "fields": [\n                        {\n                            "title": "Severity",\n                            "value": alert.labels.get(\'severity\'),\n                            "short": True\n                        },\n                        {\n                            "title": "Instance",\n                            "value": alert.labels.get(\'instance\'),\n                            "short": True\n                        },\n                        {\n                            "title": "Description",\n                            "value": alert.annotations.get(\'description\'),\n                            "short": False\n                        }\n                    ]\n                }\n            ]\n        }\n\n        async with httpx.AsyncClient() as client:\n            await client.post(self.slack_webhook_url, json=message)\n\n    async def send_resolution_notification(self, alert: Alert):\n        """\ubcf5\uad6c \uc54c\ub9bc"""\n        message = {\n            "text": f"\u2705 Resolved: {alert.annotations.get(\'summary\')}",\n            "attachments": [\n                {\n                    "color": "good",\n                    "text": f"Instance: {alert.labels.get(\'instance\')}"\n                }\n            ]\n        }\n\n        async with httpx.AsyncClient() as client:\n            await client.post(self.slack_webhook_url, json=message)\n\n    async def save_to_database(self, alert: Alert):\n        """Alert\ub97c \ub370\uc774\ud130\ubca0\uc774\uc2a4\uc5d0 \uc800\uc7a5"""\n        # SQLAlchemy, MongoDB \ub4f1 \uc0ac\uc6a9\n        alert_data = {\n            "alertname": alert.labels.get(\'alertname\'),\n            "instance": alert.labels.get(\'instance\'),\n            "severity": alert.labels.get(\'severity\'),\n            "summary": alert.annotations.get(\'summary\'),\n            "starts_at": alert.startsAt,\n            "received_at": datetime.utcnow().isoformat()\n        }\n        print(f"\ud83d\udcbe Saving alert: {alert_data}")\n        # await db.alerts.insert_one(alert_data)\n\n    async def auto_remediation(self, alert: Alert):\n        """\uc790\ub3d9 \ubcf5\uad6c \uc2dc\ub3c4"""\n        alertname = alert.labels.get(\'alertname\')\n        instance = alert.labels.get(\'instance\')\n\n        if alertname == "ServiceDown":\n            print(f"\ud83d\udd27 Auto-restarting service on {instance}")\n            # await restart_service(instance)\n\n        elif alertname == "DiskSpaceHigh":\n            print(f"\ud83d\uddd1\ufe0f Auto-cleaning temp files on {instance}")\n            # await cleanup_disk(instance)\n\n# \uc804\uc5ed \ud578\ub4e4\ub7ec\nhandler = AlertHandler()\n\n@app.post("/alerts")\nasync def receive_alert(webhook: AlertWebhook):\n    """Alertmanager\ub85c\ubd80\ud130 Webhook \uc218\uc2e0"""\n    print(f"\ud83d\udce8 Received webhook: {webhook.receiver}")\n\n    try:\n        await handler.handle_alert(webhook)\n        return {"status": "ok", "message": "Alert processed"}\n    except Exception as e:\n        print(f"\u274c Error processing alert: {e}")\n        return {"status": "error", "message": str(e)}\n\n@app.get("/health")\nasync def health():\n    """\ud5ec\uc2a4\uccb4\ud06c \uc5d4\ub4dc\ud3ec\uc778\ud2b8"""\n    return {"status": "healthy"}\n\nif __name__ == "__main__":\n    import uvicorn\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"alert-\uc774\ub825-\uad00\ub9ac",children:"Alert \uc774\ub825 \uad00\ub9ac"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from sqlalchemy import create_engine, Column, Integer, String, DateTime\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom datetime import datetime\n\nBase = declarative_base()\n\nclass AlertHistory(Base):\n    """Alert \uc774\ub825 \ud14c\uc774\ube14"""\n    __tablename__ = \'alert_history\'\n\n    id = Column(Integer, primary_key=True)\n    alertname = Column(String(100), index=True)\n    instance = Column(String(100), index=True)\n    severity = Column(String(20), index=True)\n    status = Column(String(20))  # firing, resolved\n    summary = Column(String(500))\n    description = Column(String(2000))\n    starts_at = Column(DateTime)\n    ends_at = Column(DateTime, nullable=True)\n    received_at = Column(DateTime, default=datetime.utcnow)\n\n# \ub370\uc774\ud130\ubca0\uc774\uc2a4 \ucd08\uae30\ud654\nengine = create_engine(\'sqlite:///alerts.db\')\nBase.metadata.create_all(engine)\nSession = sessionmaker(bind=engine)\n\nclass AlertRepository:\n    """Alert \uc800\uc7a5\uc18c"""\n\n    def __init__(self):\n        self.session = Session()\n\n    def save_alert(self, alert: Alert, status: str):\n        """Alert \uc800\uc7a5"""\n        history = AlertHistory(\n            alertname=alert.labels.get(\'alertname\'),\n            instance=alert.labels.get(\'instance\'),\n            severity=alert.labels.get(\'severity\'),\n            status=status,\n            summary=alert.annotations.get(\'summary\'),\n            description=alert.annotations.get(\'description\'),\n            starts_at=datetime.fromisoformat(\n                alert.startsAt.replace(\'Z\', \'+00:00\')\n            ),\n            ends_at=datetime.fromisoformat(\n                alert.endsAt.replace(\'Z\', \'+00:00\')\n            ) if alert.endsAt != \'0001-01-01T00:00:00Z\' else None\n        )\n\n        self.session.add(history)\n        self.session.commit()\n\n    def get_active_alerts(self) -> List[AlertHistory]:\n        """\ud604\uc7ac \ubc1c\uc0dd \uc911\uc778 Alert \uc870\ud68c"""\n        return self.session.query(AlertHistory).filter(\n            AlertHistory.status == \'firing\',\n            AlertHistory.ends_at.is_(None)\n        ).all()\n\n    def get_alert_stats(self, hours: int = 24) -> dict:\n        """Alert \ud1b5\uacc4"""\n        from datetime import timedelta\n        cutoff = datetime.utcnow() - timedelta(hours=hours)\n\n        alerts = self.session.query(AlertHistory).filter(\n            AlertHistory.received_at >= cutoff\n        ).all()\n\n        return {\n            "total": len(alerts),\n            "by_severity": {\n                "critical": len([a for a in alerts if a.severity == \'critical\']),\n                "warning": len([a for a in alerts if a.severity == \'warning\']),\n                "info": len([a for a in alerts if a.severity == \'info\'])\n            },\n            "by_alertname": {}\n        }\n'})}),"\n",(0,a.jsx)(n.h2,{id:"59-python\uc73c\ub85c-\ud504\ub85c\uadf8\ub798\ub9e4\ud2f1-\uc54c\ub9bc-\ubc1c\uc1a1",children:"5.9 Python\uc73c\ub85c \ud504\ub85c\uadf8\ub798\ub9e4\ud2f1 \uc54c\ub9bc \ubc1c\uc1a1"}),"\n",(0,a.jsx)(n.h3,{id:"alertmanager-api-\ud074\ub77c\uc774\uc5b8\ud2b8",children:"Alertmanager API \ud074\ub77c\uc774\uc5b8\ud2b8"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import requests\nfrom typing import Dict, List\nfrom datetime import datetime, timedelta\n\nclass AlertmanagerClient:\n    """Alertmanager API \ud074\ub77c\uc774\uc5b8\ud2b8"""\n\n    def __init__(self, base_url: str = "http://localhost:9093"):\n        self.base_url = base_url\n\n    def send_alert(\n        self,\n        alertname: str,\n        labels: Dict[str, str],\n        annotations: Dict[str, str],\n        starts_at: datetime = None,\n        ends_at: datetime = None\n    ):\n        """\ud504\ub85c\uadf8\ub798\ub9e4\ud2f1\ud558\uac8c Alert \ubc1c\uc1a1"""\n        if starts_at is None:\n            starts_at = datetime.utcnow()\n\n        # ends_at\uc774 \uc5c6\uc73c\uba74 5\ubd84 \ud6c4 \uc790\ub3d9 \ud574\uc81c\n        if ends_at is None:\n            ends_at = starts_at + timedelta(minutes=5)\n\n        alert = {\n            "labels": {\n                "alertname": alertname,\n                **labels\n            },\n            "annotations": annotations,\n            "startsAt": starts_at.isoformat() + "Z",\n            "endsAt": ends_at.isoformat() + "Z",\n            "generatorURL": "http://custom-app/alerts"\n        }\n\n        response = requests.post(\n            f"{self.base_url}/api/v2/alerts",\n            json=[alert]\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def get_alerts(self, filters: Dict[str, str] = None) -> List[dict]:\n        """\ud604\uc7ac Alert \ubaa9\ub85d \uc870\ud68c"""\n        params = {}\n        if filters:\n            params[\'filter\'] = \',\'.join(\n                f\'{k}="{v}"\' for k, v in filters.items()\n            )\n\n        response = requests.get(\n            f"{self.base_url}/api/v2/alerts",\n            params=params\n        )\n        response.raise_for_status()\n        return response.json()\n\n# \uc0ac\uc6a9 \uc608\uc81c\nam_client = AlertmanagerClient()\n\n# \ucee4\uc2a4\ud140 Alert \ubc1c\uc1a1\nam_client.send_alert(\n    alertname="CustomBusinessAlert",\n    labels={\n        "severity": "warning",\n        "team": "backend",\n        "service": "payment"\n    },\n    annotations={\n        "summary": "\uacb0\uc81c \uc2e4\ud328\uc728 \uae09\uc99d",\n        "description": "\uc9c0\ub09c 5\ubd84\uac04 \uacb0\uc81c \uc2e4\ud328\uc728\uc774 15%\ub97c \ucd08\uacfc\ud588\uc2b5\ub2c8\ub2e4."\n    }\n)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"\ube44\uc988\ub2c8\uc2a4-\uba54\ud2b8\ub9ad-\uae30\ubc18-\uc54c\ub9bc",children:"\ube44\uc988\ub2c8\uc2a4 \uba54\ud2b8\ub9ad \uae30\ubc18 \uc54c\ub9bc"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from prometheus_client import Gauge, Counter, generate_latest\nfrom datetime import datetime, timedelta\nimport asyncio\n\nclass BusinessAlertManager:\n    """\ube44\uc988\ub2c8\uc2a4 \uba54\ud2b8\ub9ad \ubaa8\ub2c8\ud130\ub9c1 \ubc0f \uc54c\ub9bc"""\n\n    def __init__(self, am_client: AlertmanagerClient):\n        self.am_client = am_client\n\n        # \uba54\ud2b8\ub9ad \uc815\uc758\n        self.payment_failure_rate = Gauge(\n            \'payment_failure_rate\',\n            \'Payment failure rate\'\n        )\n        self.order_processing_time = Gauge(\n            \'order_processing_time_seconds\',\n            \'Order processing time\'\n        )\n\n    async def monitor_payment_failures(self):\n        """\uacb0\uc81c \uc2e4\ud328\uc728 \ubaa8\ub2c8\ud130\ub9c1"""\n        while True:\n            # \uc2e4\uc81c\ub85c\ub294 \ub370\uc774\ud130\ubca0\uc774\uc2a4\ub098 API\uc5d0\uc11c \uac00\uc838\uc634\n            failure_rate = await self.get_payment_failure_rate()\n            self.payment_failure_rate.set(failure_rate)\n\n            # \uc784\uacc4\uac12 \ucd08\uacfc \uc2dc \uc54c\ub9bc\n            if failure_rate > 0.10:  # 10%\n                self.am_client.send_alert(\n                    alertname="HighPaymentFailureRate",\n                    labels={\n                        "severity": "critical",\n                        "team": "payment",\n                        "service": "payment-processor"\n                    },\n                    annotations={\n                        "summary": f"\uacb0\uc81c \uc2e4\ud328\uc728 {failure_rate*100:.1f}%",\n                        "description": (\n                            f"\ud604\uc7ac \uacb0\uc81c \uc2e4\ud328\uc728\uc774 {failure_rate*100:.1f}%\uc785\ub2c8\ub2e4. "\n                            "\uc989\uc2dc \ud655\uc778\uc774 \ud544\uc694\ud569\ub2c8\ub2e4."\n                        ),\n                        "runbook_url": "https://wiki.example.com/runbooks/payment-failures"\n                    }\n                )\n\n            await asyncio.sleep(60)  # 1\ubd84\ub9c8\ub2e4 \uccb4\ud06c\n\n    async def get_payment_failure_rate(self) -> float:\n        """\uacb0\uc81c \uc2e4\ud328\uc728 \uacc4\uc0b0"""\n        # \uc2e4\uc81c \uad6c\ud604\n        return 0.05  # 5%\n\n    async def monitor_order_processing(self):\n        """\uc8fc\ubb38 \ucc98\ub9ac \uc2dc\uac04 \ubaa8\ub2c8\ud130\ub9c1"""\n        while True:\n            avg_time = await self.get_avg_order_processing_time()\n            self.order_processing_time.set(avg_time)\n\n            if avg_time > 30:  # 30\ucd08\n                self.am_client.send_alert(\n                    alertname="SlowOrderProcessing",\n                    labels={\n                        "severity": "warning",\n                        "team": "backend",\n                        "service": "order-service"\n                    },\n                    annotations={\n                        "summary": f"\uc8fc\ubb38 \ucc98\ub9ac \uc9c0\uc5f0 ({avg_time:.1f}\ucd08)",\n                        "description": (\n                            f"\ud3c9\uade0 \uc8fc\ubb38 \ucc98\ub9ac \uc2dc\uac04\uc774 {avg_time:.1f}\ucd08\uc785\ub2c8\ub2e4."\n                        )\n                    }\n                )\n\n            await asyncio.sleep(60)\n\n    async def get_avg_order_processing_time(self) -> float:\n        """\ud3c9\uade0 \uc8fc\ubb38 \ucc98\ub9ac \uc2dc\uac04"""\n        return 15.0\n\n# \uc2e4\ud589\nasync def main():\n    am_client = AlertmanagerClient()\n    manager = BusinessAlertManager(am_client)\n\n    # \ubaa8\ub2c8\ud130\ub9c1 \uc2dc\uc791\n    await asyncio.gather(\n        manager.monitor_payment_failures(),\n        manager.monitor_order_processing()\n    )\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})}),"\n",(0,a.jsx)(n.h2,{id:"510-\uc2e4\uc804-alert-rule-\uc608\uc81c",children:"5.10 \uc2e4\uc804 Alert Rule \uc608\uc81c"}),"\n",(0,a.jsx)(n.h3,{id:"high-error-rate",children:"High Error Rate"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: error_rate_alerts\n    interval: 30s\n    rules:\n      # 5\ubd84 \ud3c9\uade0 \uc5d0\ub7ec\uc728 5% \ucd08\uacfc\n      - alert: HighErrorRate\n        expr: |\n          (\n            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service, instance)\n            /\n            sum(rate(http_requests_total[5m])) by (service, instance)\n          ) > 0.05\n        for: 5m\n        labels:\n          severity: critical\n          team: backend\n        annotations:\n          summary: "\ub192\uc740 HTTP \uc5d0\ub7ec\uc728 \uac10\uc9c0"\n          description: |\n            \uc11c\ube44\uc2a4 {{ $labels.service }}\uc758 \uc778\uc2a4\ud134\uc2a4 {{ $labels.instance }}\uc5d0\uc11c\n            \uc5d0\ub7ec\uc728\uc774 {{ $value | humanizePercentage }}\uc785\ub2c8\ub2e4.\n\n            5\ubd84 \ud3c9\uade0 \uae30\uc900 5%\ub97c \ucd08\uacfc\ud588\uc2b5\ub2c8\ub2e4.\n          runbook_url: "https://wiki.example.com/runbooks/high-error-rate"\n          dashboard_url: "https://grafana.example.com/d/http-metrics"\n\n      # \uae09\uaca9\ud55c \uc5d0\ub7ec\uc728 \uc99d\uac00 (\uc9c0\ub09c 5\ubd84 vs \uc9c0\ub09c 1\uc2dc\uac04)\n      - alert: ErrorRateSpike\n        expr: |\n          (\n            sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)\n            /\n            sum(rate(http_requests_total{status=~"5.."}[1h] offset 1h)) by (service)\n          ) > 5\n        for: 2m\n        labels:\n          severity: warning\n          team: backend\n        annotations:\n          summary: "\uc5d0\ub7ec\uc728 \uae09\uc99d \uac10\uc9c0"\n          description: |\n            \uc11c\ube44\uc2a4 {{ $labels.service }}\uc758 \uc5d0\ub7ec\uc728\uc774 \ud3c9\uc18c \ub300\ube44 {{ $value }}\ubc30 \uc99d\uac00\ud588\uc2b5\ub2c8\ub2e4.\n'})}),"\n",(0,a.jsx)(n.h3,{id:"high-latency",children:"High Latency"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: latency_alerts\n    interval: 30s\n    rules:\n      # P95 \ub808\uc774\ud134\uc2dc\uac00 1\ucd08 \ucd08\uacfc\n      - alert: HighLatencyP95\n        expr: |\n          histogram_quantile(0.95,\n            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service, endpoint)\n          ) > 1\n        for: 5m\n        labels:\n          severity: warning\n          team: backend\n        annotations:\n          summary: "\ub192\uc740 \uc751\ub2f5 \uc2dc\uac04 (P95)"\n          description: |\n            \uc5d4\ub4dc\ud3ec\uc778\ud2b8 {{ $labels.endpoint }}\uc758 P95 \ub808\uc774\ud134\uc2dc\uac00 {{ $value | humanizeDuration }}\uc785\ub2c8\ub2e4.\n            SLA \ubaa9\ud45c(1\ucd08)\ub97c \ucd08\uacfc\ud588\uc2b5\ub2c8\ub2e4.\n\n      # P99 \ub808\uc774\ud134\uc2dc\uac00 3\ucd08 \ucd08\uacfc\n      - alert: HighLatencyP99\n        expr: |\n          histogram_quantile(0.99,\n            sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service, endpoint)\n          ) > 3\n        for: 5m\n        labels:\n          severity: critical\n          team: backend\n        annotations:\n          summary: "\ub9e4\uc6b0 \ub192\uc740 \uc751\ub2f5 \uc2dc\uac04 (P99)"\n          description: |\n            \uc5d4\ub4dc\ud3ec\uc778\ud2b8 {{ $labels.endpoint }}\uc758 P99 \ub808\uc774\ud134\uc2dc\uac00 {{ $value | humanizeDuration }}\uc785\ub2c8\ub2e4.\n            \uc989\uc2dc \uc870\uc0ac\uac00 \ud544\uc694\ud569\ub2c8\ub2e4.\n\n      # \ud3c9\uade0 \ub808\uc774\ud134\uc2dc \uae09\uc99d\n      - alert: LatencySpike\n        expr: |\n          (\n            avg(rate(http_request_duration_seconds_sum[5m])) by (service)\n            / avg(rate(http_request_duration_seconds_count[5m])) by (service)\n          )\n          /\n          (\n            avg(rate(http_request_duration_seconds_sum[1h] offset 1h)) by (service)\n            / avg(rate(http_request_duration_seconds_count[1h] offset 1h)) by (service)\n          ) > 2\n        for: 5m\n        labels:\n          severity: warning\n          team: backend\n        annotations:\n          summary: "\ub808\uc774\ud134\uc2dc \uae09\uc99d"\n          description: |\n            \uc11c\ube44\uc2a4 {{ $labels.service }}\uc758 \ud3c9\uade0 \ub808\uc774\ud134\uc2dc\uac00 \ud3c9\uc18c \ub300\ube44 {{ $value }}\ubc30 \uc99d\uac00\ud588\uc2b5\ub2c8\ub2e4.\n'})}),"\n",(0,a.jsx)(n.h3,{id:"service-down",children:"Service Down"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: availability_alerts\n    interval: 15s\n    rules:\n      # \uc778\uc2a4\ud134\uc2a4 \ub2e4\uc6b4\n      - alert: InstanceDown\n        expr: up == 0\n        for: 1m\n        labels:\n          severity: critical\n          team: ops\n        annotations:\n          summary: "\uc778\uc2a4\ud134\uc2a4 \ub2e4\uc6b4"\n          description: |\n            \uc778\uc2a4\ud134\uc2a4 {{ $labels.instance }} (job: {{ $labels.job }})\uc5d0 \uc5f0\uacb0\ud560 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\n            1\ubd84 \uc774\uc0c1 \uc751\ub2f5\uc774 \uc5c6\uc2b5\ub2c8\ub2e4.\n\n      # \uc11c\ube44\uc2a4\uc758 \ubaa8\ub4e0 \uc778\uc2a4\ud134\uc2a4 \ub2e4\uc6b4\n      - alert: ServiceDown\n        expr: |\n          sum(up) by (job) == 0\n        for: 2m\n        labels:\n          severity: critical\n          team: ops\n          page: "true"  # PagerDuty \ud638\ucd9c\n        annotations:\n          summary: "\uc11c\ube44\uc2a4 \uc644\uc804 \ub2e4\uc6b4"\n          description: |\n            \uc11c\ube44\uc2a4 {{ $labels.job }}\uc758 \ubaa8\ub4e0 \uc778\uc2a4\ud134\uc2a4\uac00 \ub2e4\uc6b4\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n            \uc989\uc2dc \ub300\uc751\uc774 \ud544\uc694\ud569\ub2c8\ub2e4!\n\n      # \uc11c\ube44\uc2a4\uc758 50% \uc774\uc0c1 \uc778\uc2a4\ud134\uc2a4 \ub2e4\uc6b4\n      - alert: ServiceDegraded\n        expr: |\n          (\n            sum(up) by (job)\n            /\n            count(up) by (job)\n          ) < 0.5\n        for: 5m\n        labels:\n          severity: warning\n          team: ops\n        annotations:\n          summary: "\uc11c\ube44\uc2a4 \uc131\ub2a5 \uc800\ud558"\n          description: |\n            \uc11c\ube44\uc2a4 {{ $labels.job }}\uc758 {{ $value | humanizePercentage }}\ub9cc \uc815\uc0c1 \ub3d9\uc791 \uc911\uc785\ub2c8\ub2e4.\n'})}),"\n",(0,a.jsx)(n.h3,{id:"database-alerts",children:"Database Alerts"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: database_alerts\n    interval: 30s\n    rules:\n      # \ub370\uc774\ud130\ubca0\uc774\uc2a4 \uc5f0\uacb0 \ud480 \ubd80\uc871\n      - alert: DatabaseConnectionPoolExhausted\n        expr: |\n          (\n            sum(db_connections_active) by (instance)\n            /\n            sum(db_connections_max) by (instance)\n          ) > 0.9\n        for: 5m\n        labels:\n          severity: critical\n          team: database\n        annotations:\n          summary: "DB \uc5f0\uacb0 \ud480 \uace0\uac08 \uc784\ubc15"\n          description: |\n            {{ $labels.instance }}\uc758 DB \uc5f0\uacb0 \ud480 \uc0ac\uc6a9\ub960\uc774 {{ $value | humanizePercentage }}\uc785\ub2c8\ub2e4.\n\n      # \ub290\ub9b0 \ucffc\ub9ac \uc99d\uac00\n      - alert: SlowQueryRateHigh\n        expr: |\n          rate(mysql_slow_queries[5m]) > 10\n        for: 5m\n        labels:\n          severity: warning\n          team: database\n        annotations:\n          summary: "\ub290\ub9b0 \ucffc\ub9ac \uc99d\uac00"\n          description: |\n            {{ $labels.instance }}\uc5d0\uc11c \ub290\ub9b0 \ucffc\ub9ac\uac00 {{ $value }}\uac74/\ucd08 \ubc1c\uc0dd \uc911\uc785\ub2c8\ub2e4.\n\n      # \ubcf5\uc81c \uc9c0\uc5f0\n      - alert: DatabaseReplicationLag\n        expr: |\n          mysql_slave_lag_seconds > 60\n        for: 5m\n        labels:\n          severity: warning\n          team: database\n        annotations:\n          summary: "DB \ubcf5\uc81c \uc9c0\uc5f0"\n          description: |\n            \uc2ac\ub808\uc774\ube0c {{ $labels.instance }}\uc758 \ubcf5\uc81c\uac00 {{ $value | humanizeDuration }} \uc9c0\uc5f0\ub418\uc5c8\uc2b5\ub2c8\ub2e4.\n'})}),"\n",(0,a.jsx)(n.h3,{id:"resource-alerts",children:"Resource Alerts"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: resource_alerts\n    interval: 30s\n    rules:\n      # \ub192\uc740 CPU \uc0ac\uc6a9\ub960\n      - alert: HighCPUUsage\n        expr: |\n          100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80\n        for: 10m\n        labels:\n          severity: warning\n          team: ops\n        annotations:\n          summary: "\ub192\uc740 CPU \uc0ac\uc6a9\ub960"\n          description: |\n            {{ $labels.instance }}\uc758 CPU \uc0ac\uc6a9\ub960\uc774 {{ $value | printf "%.1f" }}%\uc785\ub2c8\ub2e4.\n\n      # \ub192\uc740 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub960\n      - alert: HighMemoryUsage\n        expr: |\n          (\n            1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)\n          ) * 100 > 85\n        for: 10m\n        labels:\n          severity: warning\n          team: ops\n        annotations:\n          summary: "\ub192\uc740 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub960"\n          description: |\n            {{ $labels.instance }}\uc758 \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub960\uc774 {{ $value | printf "%.1f" }}%\uc785\ub2c8\ub2e4.\n\n      # \ub514\uc2a4\ud06c \uacf5\uac04 \ubd80\uc871\n      - alert: DiskSpaceLow\n        expr: |\n          (\n            1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*"} / node_filesystem_size_bytes)\n          ) * 100 > 80\n        for: 5m\n        labels:\n          severity: warning\n          team: ops\n        annotations:\n          summary: "\ub514\uc2a4\ud06c \uacf5\uac04 \ubd80\uc871"\n          description: |\n            {{ $labels.instance }}\uc758 {{ $labels.mountpoint }} \uc0ac\uc6a9\ub960\uc774 {{ $value | printf "%.1f" }}%\uc785\ub2c8\ub2e4.\n\n      # \ub514\uc2a4\ud06c \uacf5\uac04 \uc784\uacc4\n      - alert: DiskSpaceCritical\n        expr: |\n          (\n            1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|fuse.*"} / node_filesystem_size_bytes)\n          ) * 100 > 90\n        for: 5m\n        labels:\n          severity: critical\n          team: ops\n        annotations:\n          summary: "\ub514\uc2a4\ud06c \uacf5\uac04 \uc784\uacc4"\n          description: |\n            {{ $labels.instance }}\uc758 {{ $labels.mountpoint }} \uc0ac\uc6a9\ub960\uc774 {{ $value | printf "%.1f" }}%\uc785\ub2c8\ub2e4.\n            \uc989\uc2dc \uc815\ub9ac\uac00 \ud544\uc694\ud569\ub2c8\ub2e4!\n'})}),"\n",(0,a.jsx)(n.h2,{id:"511-alert-\ud53c\ub85c-\ubc29\uc9c0-\uc804\ub7b5",children:"5.11 Alert \ud53c\ub85c \ubc29\uc9c0 \uc804\ub7b5"}),"\n",(0,a.jsx)(n.h3,{id:"1-\uc801\uc808\ud55c-\uc784\uacc4\uac12-\uc124\uc815",children:"1. \uc801\uc808\ud55c \uc784\uacc4\uac12 \uc124\uc815"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# \ub098\uc05c \uc608: \ub108\ubb34 \ubbfc\uac10\n- alert: HighErrorRate\n  expr: http_errors_total > 0\n  # \u2192 \uc5d0\ub7ec 1\uac74\ub9cc \ubc1c\uc0dd\ud574\ub3c4 \uc54c\ub9bc\n\n# \uc88b\uc740 \uc608: \ube44\uc728 \uae30\ubc18 + for \uc808\n- alert: HighErrorRate\n  expr: |\n    rate(http_errors_total[5m])\n    / rate(http_requests_total[5m]) > 0.05\n  for: 5m\n  # \u2192 5% \ucd08\uacfc\uac00 5\ubd84 \uc9c0\uc18d\ub420 \ub54c\ub9cc \uc54c\ub9bc\n"})}),"\n",(0,a.jsx)(n.h3,{id:"2-\uadf8\ub8f9\ud654\ub85c-\uc54c\ub9bc-\ud1b5\ud569",children:"2. \uadf8\ub8f9\ud654\ub85c \uc54c\ub9bc \ud1b5\ud569"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# Alertmanager \uc124\uc815\nroute:\n  # \uac19\uc740 \uc11c\ube44\uc2a4\uc758 \uc5ec\ub7ec \uc778\uc2a4\ud134\uc2a4\ub97c \ud558\ub098\ub85c \ubb36\uc74c\n  group_by: ['alertname', 'service']\n  group_wait: 30s\n  group_interval: 5m\n\n  # \ub3d9\uc77c \uc54c\ub9bc\uc744 4\uc2dc\uac04\ub9c8\ub2e4\ub9cc \uc7ac\uc804\uc1a1\n  repeat_interval: 4h\n"})}),"\n",(0,a.jsx)(n.h3,{id:"3-severity-\ub808\ubca8-\ud65c\uc6a9",children:"3. Severity \ub808\ubca8 \ud65c\uc6a9"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'# Critical: \uc989\uc2dc \ub300\uc751 \ud544\uc694 (PagerDuty)\n- alert: ServiceDown\n  labels:\n    severity: critical\n    page: "true"\n\n# Warning: \uc5c5\ubb34 \uc2dc\uac04\uc5d0 \ud655\uc778 (Slack)\n- alert: HighLatency\n  labels:\n    severity: warning\n\n# Info: \ucc38\uace0\uc6a9 (\ub85c\uadf8\ub9cc)\n- alert: HighTraffic\n  labels:\n    severity: info\n'})}),"\n",(0,a.jsx)(n.h3,{id:"4-runbook-\ub9c1\ud06c-\uc81c\uacf5",children:"4. Runbook \ub9c1\ud06c \uc81c\uacf5"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'annotations:\n  summary: "\uc11c\ube44\uc2a4 \ub2e4\uc6b4"\n  description: "{{ $labels.instance }} \uc751\ub2f5 \uc5c6\uc74c"\n  runbook_url: "https://wiki.example.com/runbooks/service-down"\n  # \u2192 \ub2f4\ub2f9\uc790\uac00 \uc989\uc2dc \ub300\uc751 \ubc29\ubc95 \ud655\uc778 \uac00\ub2a5\n'})}),"\n",(0,a.jsx)(n.h3,{id:"5-alert-\uc720\ud6a8\uc131-\uc815\uae30-\uac80\ud1a0",children:"5. Alert \uc720\ud6a8\uc131 \uc815\uae30 \uac80\ud1a0"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class AlertReview:\n    """Alert \uaddc\uce59 \uc720\ud6a8\uc131 \uac80\ud1a0"""\n\n    def __init__(self, prometheus_url: str):\n        self.prom_url = prometheus_url\n\n    def get_alert_statistics(self, days: int = 30) -> dict:\n        """\uc9c0\ub09c N\uc77c\uac04 Alert \ud1b5\uacc4"""\n        # Prometheus API\ub85c Alert \uc774\ub825 \uc870\ud68c\n        stats = {}\n\n        # 1. \ubc1c\uc0dd \ube48\ub3c4\n        # 2. \ud3c9\uade0 \uc9c0\uc18d \uc2dc\uac04\n        # 3. \ud574\uacb0 \uc5ec\ubd80\n\n        return stats\n\n    def identify_noisy_alerts(self, threshold: int = 100) -> List[str]:\n        """\uacfc\ub3c4\ud558\uac8c \ubc1c\uc0dd\ud558\ub294 Alert \uc2dd\ubcc4"""\n        stats = self.get_alert_statistics()\n\n        noisy = []\n        for alertname, count in stats.items():\n            if count > threshold:\n                noisy.append(alertname)\n                print(f"\u26a0\ufe0f {alertname}: {count}\ud68c \ubc1c\uc0dd (\uc784\uacc4\uac12 \uc870\uc815 \ud544\uc694)")\n\n        return noisy\n\n    def identify_ignored_alerts(self) -> List[str]:\n        """\ubb34\uc2dc\ub418\ub294 Alert \uc2dd\ubcc4"""\n        # \ubc1c\uc0dd\uc740 \ub9ce\uc9c0\ub9cc \ud574\uacb0 \uc2dc\uac04\uc774 \uae34 Alert\n        # \u2192 \uc2e4\uc81c\ub85c\ub294 \uc911\uc694\ud558\uc9c0 \uc54a\uc744 \uac00\ub2a5\uc131\n        pass\n'})}),"\n",(0,a.jsx)(n.h3,{id:"6-\uc5c5\ubb34-\uc2dc\uac04-\uae30\ubc18-\ub77c\uc6b0\ud305",children:"6. \uc5c5\ubb34 \uc2dc\uac04 \uae30\ubc18 \ub77c\uc6b0\ud305"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# time_intervals (Alertmanager 0.24+)\ntime_intervals:\n  - name: business_hours\n    time_intervals:\n      - times:\n          - start_time: '09:00'\n            end_time: '18:00'\n        weekdays: ['monday:friday']\n\nroute:\n  routes:\n    # \uc5c5\ubb34 \uc2dc\uac04\uc5d0\ub294 Slack\n    - match:\n        severity: warning\n      receiver: 'slack'\n      active_time_intervals:\n        - business_hours\n\n    # \uc5c5\ubb34 \uc678 \uc2dc\uac04\uc5d0\ub294 \ubb34\uc2dc\n    - match:\n        severity: warning\n      receiver: 'null'\n      mute_time_intervals:\n        - business_hours\n\n    # Critical\uc740 \ud56d\uc0c1 PagerDuty\n    - match:\n        severity: critical\n      receiver: 'pagerduty'\n"})}),"\n",(0,a.jsx)(n.h2,{id:"512-\ubca0\uc2a4\ud2b8-\ud504\ub799\ud2f0\uc2a4",children:"5.12 \ubca0\uc2a4\ud2b8 \ud504\ub799\ud2f0\uc2a4"}),"\n",(0,a.jsx)(n.h3,{id:"1-alert-rule-\uc791\uc131",children:"1. Alert Rule \uc791\uc131"}),"\n",(0,a.jsxs)(n.admonition,{title:"Alert \uc791\uc131 \uc6d0\uce59",type:"tip",children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uc99d\uc0c1 \uae30\ubc18 \uc54c\ub9bc (Symptom-based)"})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'# Good: \uc0ac\uc6a9\uc790\uac00 \uacbd\ud5d8\ud558\ub294 \uc99d\uc0c1\n- alert: HighLatency\n  expr: http_request_duration_seconds{quantile="0.99"} > 1\n\n# Bad: \uc6d0\uc778 \ucd94\uc815\n- alert: HighCPU\n  expr: cpu_usage > 80\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uc2e4\ud589 \uac00\ub2a5\ud55c \uc54c\ub9bc (Actionable)"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"\uc54c\ub9bc\uc744 \ubc1b\uc740 \uc0ac\ub78c\uc774 \ubb34\uc5c7\uc744 \ud574\uc57c \ud558\ub294\uc9c0 \uba85\ud655\ud574\uc57c \ud568"}),"\n",(0,a.jsx)(n.li,{children:"Runbook \ub9c1\ud06c \ud544\uc218"}),"\n"]}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uc758\ubbf8 \uc788\ub294 \uc54c\ub9bc\ub9cc (Meaningful)"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"False positive\uac00 \ub9ce\uc73c\uba74 \ubb34\uc2dc\ub428"}),"\n",(0,a.jsxs)(n.li,{children:["\uc784\uacc4\uac12\uacfc ",(0,a.jsx)(n.code,{children:"for"})," \uc808\uc744 \uc801\uc808\ud788 \uc870\uc815"]}),"\n"]})]}),"\n",(0,a.jsx)(n.h3,{id:"2-\uc54c\ub9bc-\uad6c\uc870\ud654",children:"2. \uc54c\ub9bc \uad6c\uc870\ud654"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'# \ud300\ubcc4 \ub808\uc774\ube14 \uccb4\uacc4\nlabels:\n  severity: critical|warning|info\n  team: backend|frontend|database|ops\n  service: api|web|worker\n  environment: production|staging\n\n# \uc77c\uad00\ub41c \uc5b4\ub178\ud14c\uc774\uc158\nannotations:\n  summary: "\uac04\ub2e8\ud55c \ud55c \uc904 \uc694\uc57d"\n  description: "\uc0c1\uc138\ud55c \uc124\uba85 (\ud604\uc7ac \uac12 \ud3ec\ud568)"\n  runbook_url: "https://wiki.example.com/runbooks/..."\n  dashboard_url: "https://grafana.example.com/d/..."\n  graph_url: "{{ .GeneratorURL }}"\n'})}),"\n",(0,a.jsx)(n.h3,{id:"3-\ub77c\uc6b0\ud305-\uc804\ub7b5",children:"3. \ub77c\uc6b0\ud305 \uc804\ub7b5"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"route:\n  # \uae30\ubcf8 \uc124\uc815\n  receiver: 'default'\n  group_by: ['alertname', 'service']\n  group_wait: 10s\n  group_interval: 5m\n  repeat_interval: 4h\n\n  routes:\n    # Critical \u2192 PagerDuty (24/7)\n    - match:\n        severity: critical\n      receiver: 'pagerduty'\n      continue: true  # \ub2e4\ub978 \uc218\uc2e0\uc790\uc5d0\uac8c\ub3c4 \uc804\uc1a1\n\n    # Critical \u2192 Slack (\uc989\uc2dc \uc54c\ub9bc)\n    - match:\n        severity: critical\n      receiver: 'slack-critical'\n\n    # Warning \u2192 Slack (\ubb36\uc5b4\uc11c \uc804\uc1a1)\n    - match:\n        severity: warning\n      receiver: 'slack-warning'\n      group_wait: 30s\n      group_interval: 10m\n\n    # Info \u2192 \ub85c\uadf8\ub9cc\n    - match:\n        severity: info\n      receiver: 'null'\n"})}),"\n",(0,a.jsx)(n.h3,{id:"4-inhibition-\ud65c\uc6a9",children:"4. Inhibition \ud65c\uc6a9"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"inhibit_rules:\n  # \ub178\ub4dc \ub2e4\uc6b4 \uc2dc \ud574\ub2f9 \ub178\ub4dc\uc758 \ub2e4\ub978 \uc54c\ub9bc \uc5b5\uc81c\n  - source_match:\n      alertname: NodeDown\n    target_match_re:\n      alertname: (HighCPU|HighMemory|DiskSpaceLow)\n    equal: ['instance']\n\n  # \uc11c\ube44\uc2a4 \ub2e4\uc6b4 \uc2dc \uc131\ub2a5 \uc54c\ub9bc \uc5b5\uc81c\n  - source_match:\n      alertname: ServiceDown\n    target_match_re:\n      alertname: (HighLatency|HighErrorRate)\n    equal: ['service']\n"})}),"\n",(0,a.jsx)(n.h3,{id:"5-\uc54c\ub9bc-\ud14c\uc2a4\ud2b8",children:"5. \uc54c\ub9bc \ud14c\uc2a4\ud2b8"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'# Alert Rule \ubb38\ubc95 \uac80\uc0ac\npromtool check rules /etc/prometheus/alerts.yml\n\n# Alertmanager \uc124\uc815 \uac80\uc0ac\namtool check-config /etc/alertmanager/alertmanager.yml\n\n# \ud14c\uc2a4\ud2b8 \uc54c\ub9bc \ubc1c\uc1a1\namtool alert add \\\n  alertname=TestAlert \\\n  severity=warning \\\n  instance=test-instance \\\n  summary="Test alert"\n\n# \ud2b9\uc815 \uc218\uc2e0\uc790\ub85c \ud14c\uc2a4\ud2b8\namtool alert add \\\n  alertname=TestAlert \\\n  severity=critical \\\n  --alertmanager.url=http://localhost:9093\n'})}),"\n",(0,a.jsx)(n.h3,{id:"6-\ubaa8\ub2c8\ud130\ub9c1-\ubc0f-\uac1c\uc120",children:"6. \ubaa8\ub2c8\ud130\ub9c1 \ubc0f \uac1c\uc120"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"class AlertMetrics:\n    \"\"\"Alert \uc131\ub2a5 \uba54\ud2b8\ub9ad\"\"\"\n\n    def __init__(self):\n        from prometheus_client import Counter, Histogram\n\n        self.alerts_fired = Counter(\n            'alertmanager_alerts_fired_total',\n            'Total alerts fired',\n            ['alertname', 'severity']\n        )\n\n        self.alert_duration = Histogram(\n            'alert_duration_seconds',\n            'Alert duration',\n            ['alertname']\n        )\n\n        self.mttr = Histogram(\n            'alert_mttr_seconds',\n            'Mean Time To Resolution',\n            ['alertname']\n        )\n"})}),"\n",(0,a.jsx)(n.h2,{id:"\uc5f0\uc2b5-\ubb38\uc81c",children:"\uc5f0\uc2b5 \ubb38\uc81c"}),"\n",(0,a.jsx)(n.h3,{id:"\ubb38\uc81c-1-basic-alert-rule",children:"\ubb38\uc81c 1: Basic Alert Rule"}),"\n",(0,a.jsx)(n.p,{children:"FastAPI \uc560\ud50c\ub9ac\ucf00\uc774\uc158\uc758 \uc5d0\ub7ec\uc728\uc774 3% \uc774\uc0c1\uc77c \ub54c \uc54c\ub9bc\uc744 \ubcf4\ub0b4\ub294 Alert Rule\uc744 \uc791\uc131\ud558\uc138\uc694."}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"\ud574\ub2f5 \ubcf4\uae30"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'groups:\n  - name: api_alerts\n    interval: 30s\n    rules:\n      - alert: APIHighErrorRate\n        expr: |\n          sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)\n          /\n          sum(rate(http_requests_total[5m])) by (service)\n          > 0.03\n        for: 5m\n        labels:\n          severity: warning\n          team: backend\n          service: api\n        annotations:\n          summary: "API \uc5d0\ub7ec\uc728 \uc0c1\uc2b9"\n          description: |\n            \uc11c\ube44\uc2a4 {{ $labels.service }}\uc758 \uc5d0\ub7ec\uc728\uc774 {{ $value | humanizePercentage }}\uc785\ub2c8\ub2e4.\n            5\ubd84 \ud3c9\uade0 \uae30\uc900 3%\ub97c \ucd08\uacfc\ud588\uc2b5\ub2c8\ub2e4.\n          runbook_url: "https://wiki.example.com/runbooks/api-errors"\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\ud3ec\uc778\ud2b8:"})}),(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.code,{children:"for: 5m"}),"\uc73c\ub85c \uc77c\uc2dc\uc801 \uc2a4\ud30c\uc774\ud06c \ubb34\uc2dc"]}),"\n",(0,a.jsx)(n.li,{children:"\ube44\uc728 \uacc4\uc0b0\uc73c\ub85c \uc815\ud655\ud55c \uc5d0\ub7ec\uc728 \uce21\uc815"}),"\n",(0,a.jsx)(n.li,{children:"Runbook URL \uc81c\uacf5"}),"\n"]})]}),"\n",(0,a.jsx)(n.h3,{id:"\ubb38\uc81c-2-webhook-\uc218\uc2e0\uae30",children:"\ubb38\uc81c 2: Webhook \uc218\uc2e0\uae30"}),"\n",(0,a.jsx)(n.p,{children:"Alertmanager\ub85c\ubd80\ud130 Webhook\uc744 \ubc1b\uc544\uc11c Slack\uc73c\ub85c \ud3ec\ub9f7\ud305\ud558\uc5ec \uc804\uc1a1\ud558\ub294 FastAPI \uc571\uc744 \uc791\uc131\ud558\uc138\uc694."}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"\ud574\ub2f5 \ubcf4\uae30"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from fastapi import FastAPI, Request\nfrom pydantic import BaseModel\nfrom typing import List, Dict\nimport httpx\n\napp = FastAPI()\n\nclass Alert(BaseModel):\n    status: str\n    labels: Dict[str, str]\n    annotations: Dict[str, str]\n    startsAt: str\n\nclass AlertWebhook(BaseModel):\n    status: str\n    alerts: List[Alert]\n    groupLabels: Dict[str, str]\n\nSLACK_WEBHOOK_URL = "YOUR_SLACK_WEBHOOK_URL"\n\ndef format_slack_message(webhook: AlertWebhook) -> dict:\n    """Slack \uba54\uc2dc\uc9c0 \ud3ec\ub9f7"""\n    color = "danger" if webhook.status == "firing" else "good"\n    emoji = "\ud83d\udd25" if webhook.status == "firing" else "\u2705"\n\n    # Alert \ubaa9\ub85d\n    alert_text = ""\n    for alert in webhook.alerts:\n        alert_text += f"\\n\u2022 *{alert.labels.get(\'instance\')}*: {alert.annotations.get(\'summary\')}"\n\n    return {\n        "text": f"{emoji} *{webhook.groupLabels.get(\'alertname\')}*",\n        "attachments": [\n            {\n                "color": color,\n                "fields": [\n                    {\n                        "title": "Status",\n                        "value": webhook.status.upper(),\n                        "short": True\n                    },\n                    {\n                        "title": "Severity",\n                        "value": webhook.alerts[0].labels.get(\'severity\', \'unknown\'),\n                        "short": True\n                    },\n                    {\n                        "title": "Alerts",\n                        "value": alert_text,\n                        "short": False\n                    }\n                ]\n            }\n        ]\n    }\n\n@app.post("/webhook")\nasync def receive_alert(webhook: AlertWebhook):\n    """Webhook \uc218\uc2e0 \ubc0f Slack \uc804\uc1a1"""\n    # Slack \uba54\uc2dc\uc9c0 \uc0dd\uc131\n    slack_msg = format_slack_message(webhook)\n\n    # Slack\uc73c\ub85c \uc804\uc1a1\n    async with httpx.AsyncClient() as client:\n        response = await client.post(SLACK_WEBHOOK_URL, json=slack_msg)\n        response.raise_for_status()\n\n    return {"status": "ok"}\n\nif __name__ == "__main__":\n    import uvicorn\n    uvicorn.run(app, host="0.0.0.0", port=8000)\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\uc2e4\ud589:"})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# \uc11c\ubc84 \uc2e4\ud589\npython webhook_receiver.py\n\n# Alertmanager \uc124\uc815\n# alertmanager.yml\nreceivers:\n  - name: 'webhook'\n    webhook_configs:\n      - url: 'http://localhost:8000/webhook'\n"})})]}),"\n",(0,a.jsx)(n.h3,{id:"\ubb38\uc81c-3-silence-\uc790\ub3d9\ud654",children:"\ubb38\uc81c 3: Silence \uc790\ub3d9\ud654"}),"\n",(0,a.jsx)(n.p,{children:"\ubc30\ud3ec \uc2dc \uc790\ub3d9\uc73c\ub85c 30\ubd84 Silence\ub97c \uc0dd\uc131\ud558\uace0, \ubc30\ud3ec \uc644\ub8cc \uc2dc \ud574\uc81c\ud558\ub294 \uc2a4\ud06c\ub9bd\ud2b8\ub97c \uc791\uc131\ud558\uc138\uc694."}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:"\ud574\ub2f5 \ubcf4\uae30"}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'import requests\nfrom datetime import datetime, timedelta\nfrom contextlib import contextmanager\n\nclass DeploymentSilence:\n    """\ubc30\ud3ec \uc911 Silence \uad00\ub9ac"""\n\n    def __init__(self, alertmanager_url: str):\n        self.url = alertmanager_url\n\n    def create_deployment_silence(\n        self,\n        service: str,\n        environment: str,\n        duration_minutes: int = 30,\n        created_by: str = "deploy-bot"\n    ) -> str:\n        """\ubc30\ud3ec Silence \uc0dd\uc131"""\n        start = datetime.utcnow()\n        end = start + timedelta(minutes=duration_minutes)\n\n        silence = {\n            "matchers": [\n                {"name": "service", "value": service, "isRegex": False},\n                {"name": "environment", "value": environment, "isRegex": False}\n            ],\n            "startsAt": start.isoformat() + "Z",\n            "endsAt": end.isoformat() + "Z",\n            "createdBy": created_by,\n            "comment": f"Automated silence during {service} deployment"\n        }\n\n        response = requests.post(\n            f"{self.url}/api/v2/silences",\n            json=silence\n        )\n        response.raise_for_status()\n\n        silence_id = response.json()["silenceID"]\n        print(f"\u2705 Silence created: {silence_id} (expires in {duration_minutes}m)")\n        return silence_id\n\n    def delete_silence(self, silence_id: str):\n        """Silence \uc0ad\uc81c"""\n        response = requests.delete(\n            f"{self.url}/api/v2/silence/{silence_id}"\n        )\n        response.raise_for_status()\n        print(f"\u2705 Silence deleted: {silence_id}")\n\n    @contextmanager\n    def deployment_silence(self, service: str, environment: str):\n        """Context manager\ub85c \uc790\ub3d9 Silence \uad00\ub9ac"""\n        silence_id = self.create_deployment_silence(service, environment)\n        try:\n            yield silence_id\n        finally:\n            # \ubc30\ud3ec \uc644\ub8cc \ud6c4 \uc790\ub3d9 \ud574\uc81c\n            self.delete_silence(silence_id)\n            print(f"\u2705 Deployment completed, silence removed")\n\n# \uc0ac\uc6a9 \uc608\uc81c\nds = DeploymentSilence("http://localhost:9093")\n\n# Context manager \uc0ac\uc6a9\nwith ds.deployment_silence(service="api", environment="production"):\n    print("\ud83d\ude80 Deploying...")\n    # \uc2e4\uc81c \ubc30\ud3ec \uc791\uc5c5\n    import time\n    time.sleep(5)\n    print("\u2705 Deployment done")\n\n# Silence\uac00 \uc790\ub3d9\uc73c\ub85c \ud574\uc81c\ub428\n'})}),(0,a.jsx)(n.p,{children:(0,a.jsx)(n.strong,{children:"\ubc30\ud3ec \uc2a4\ud06c\ub9bd\ud2b8\uc5d0 \ud1b5\ud569:"})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'#!/bin/bash\n# deploy.sh\n\nSERVICE="api"\nENVIRONMENT="production"\n\n# Python \uc2a4\ud06c\ub9bd\ud2b8\ub85c Silence \uc0dd\uc131\nSILENCE_ID=$(python -c "\nfrom deployment_silence import DeploymentSilence\nds = DeploymentSilence(\'http://localhost:9093\')\nsilence_id = ds.create_deployment_silence(\'$SERVICE\', \'$ENVIRONMENT\')\nprint(silence_id)\n")\n\n# \ubc30\ud3ec \uc2e4\ud589\necho "\ud83d\ude80 Deploying $SERVICE to $ENVIRONMENT..."\ndocker-compose up -d --build\n\n# Health check\necho "\u23f3 Waiting for service to be healthy..."\nsleep 10\n\n# Silence \ud574\uc81c\npython -c "\nfrom deployment_silence import DeploymentSilence\nds = DeploymentSilence(\'http://localhost:9093\')\nds.delete_silence(\'$SILENCE_ID\')\n"\n\necho "\u2705 Deployment complete!"\n'})})]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsxs)(n.p,{children:["\ub2e4\uc74c: ",(0,a.jsx)(n.a,{href:"./examples",children:"\uc2e4\uc804 \uc608\uc81c"})]})]})}function d(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(m,{...e})}):m(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>i});var r=t(6540);const a={},s=r.createContext(a);function l(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function i(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:l(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);