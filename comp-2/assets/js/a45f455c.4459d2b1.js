"use strict";(globalThis.webpackChunkgithub_docs=globalThis.webpackChunkgithub_docs||[]).push([[8012],{5640:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>u});const s=JSON.parse('{"id":"dagster/monitoring","title":"9. \ubaa8\ub2c8\ud130\ub9c1","description":"Dagster \ud30c\uc774\ud504\ub77c\uc778\uc758 \ubaa8\ub2c8\ud130\ub9c1, \ub85c\uae45, \uc54c\ub9bc \uc2dc\uc2a4\ud15c\uc744 \uad6c\ucd95\ud558\ub294 \ubc29\ubc95\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4. \ub370\uc774\ud130 \ud488\uc9c8 \uccb4\ud06c\uc640 \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1\ub3c4 \ub2e4\ub8f9\ub2c8\ub2e4.","source":"@site/docs/dagster/monitoring.md","sourceDirName":"dagster","slug":"/dagster/monitoring","permalink":"/tobias-docs/comp-2/docs/dagster/monitoring","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/dagster/monitoring.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10},"sidebar":"dagsterSidebar","previous":{"title":"8. \ubc30\ud3ec","permalink":"/tobias-docs/comp-2/docs/dagster/deployment"},"next":{"title":"10. \ud1b5\ud569","permalink":"/tobias-docs/comp-2/docs/dagster/integrations"}}');var a=t(4848),r=t(8453);const o={sidebar_position:10},i="9. \ubaa8\ub2c8\ud130\ub9c1",l={},u=[{value:"9.1 Dagit UI",id:"91-dagit-ui",level:2},{value:"9.1.1 Dagit UI \uac1c\uc694",id:"911-dagit-ui-\uac1c\uc694",level:3},{value:"9.1.2 Asset Catalog \ud65c\uc6a9",id:"912-asset-catalog-\ud65c\uc6a9",level:3},{value:"9.1.3 Run \uc0c1\ud0dc \ubaa8\ub2c8\ud130\ub9c1",id:"913-run-\uc0c1\ud0dc-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"9.2 \ub85c\uae45",id:"92-\ub85c\uae45",level:2},{value:"9.2.1 \uad6c\uc870\ud654\ub41c \ub85c\uae45",id:"921-\uad6c\uc870\ud654\ub41c-\ub85c\uae45",level:3},{value:"9.2.2 \ucee4\uc2a4\ud140 Logger",id:"922-\ucee4\uc2a4\ud140-logger",level:3},{value:"9.2.3 \ub85c\uadf8 \uc9d1\uacc4 \ubc0f \ubd84\uc11d",id:"923-\ub85c\uadf8-\uc9d1\uacc4-\ubc0f-\ubd84\uc11d",level:3},{value:"9.3 \uba54\ud2b8\ub9ad",id:"93-\uba54\ud2b8\ub9ad",level:2},{value:"9.3.1 Prometheus \uba54\ud2b8\ub9ad",id:"931-prometheus-\uba54\ud2b8\ub9ad",level:3},{value:"9.3.2 \ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad",id:"932-\ucee4\uc2a4\ud140-\uba54\ud2b8\ub9ad",level:3},{value:"9.4 \uc54c\ub9bc",id:"94-\uc54c\ub9bc",level:2},{value:"9.4.1 Slack \uc54c\ub9bc",id:"941-slack-\uc54c\ub9bc",level:3},{value:"9.4.2 Email \uc54c\ub9bc",id:"942-email-\uc54c\ub9bc",level:3},{value:"9.4.3 PagerDuty \ud1b5\ud569",id:"943-pagerduty-\ud1b5\ud569",level:3},{value:"9.5 \ub370\uc774\ud130 \ud488\uc9c8",id:"95-\ub370\uc774\ud130-\ud488\uc9c8",level:2},{value:"9.5.1 Data Quality Checks",id:"951-data-quality-checks",level:3},{value:"9.5.2 Great Expectations \ud1b5\ud569",id:"952-great-expectations-\ud1b5\ud569",level:3},{value:"9.6 \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1",id:"96-\uc131\ub2a5-\ubaa8\ub2c8\ud130\ub9c1",level:2},{value:"9.6.1 \uc131\ub2a5 \ud504\ub85c\ud30c\uc77c\ub9c1",id:"961-\uc131\ub2a5-\ud504\ub85c\ud30c\uc77c\ub9c1",level:3},{value:"9.6.2 \ucffc\ub9ac \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1",id:"962-\ucffc\ub9ac-\uc131\ub2a5-\ubaa8\ub2c8\ud130\ub9c1",level:3},{value:"9.7 \uc2e4\uc2b5 \ud504\ub85c\uc81d\ud2b8",id:"97-\uc2e4\uc2b5-\ud504\ub85c\uc81d\ud2b8",level:2},{value:"9.7.1 \uc885\ud569 \ubaa8\ub2c8\ud130\ub9c1 \ub300\uc2dc\ubcf4\ub4dc",id:"971-\uc885\ud569-\ubaa8\ub2c8\ud130\ub9c1-\ub300\uc2dc\ubcf4\ub4dc",level:3},{value:"9.7.2 \ubaa8\ub2c8\ud130\ub9c1 \uc124\uc815 \ubaa8\ubc94 \uc0ac\ub840",id:"972-\ubaa8\ub2c8\ud130\ub9c1-\uc124\uc815-\ubaa8\ubc94-\uc0ac\ub840",level:3},{value:"9.8 \uc694\uc57d",id:"98-\uc694\uc57d",level:2},{value:"\ud575\uc2ec \uac1c\ub150",id:"\ud575\uc2ec-\uac1c\ub150",level:3},{value:"Best Practices",id:"best-practices",level:3},{value:"\ub2e4\uc74c \ub2e8\uacc4",id:"\ub2e4\uc74c-\ub2e8\uacc4",level:3}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"9-\ubaa8\ub2c8\ud130\ub9c1",children:"9. \ubaa8\ub2c8\ud130\ub9c1"})}),"\n",(0,a.jsx)(e.p,{children:"Dagster \ud30c\uc774\ud504\ub77c\uc778\uc758 \ubaa8\ub2c8\ud130\ub9c1, \ub85c\uae45, \uc54c\ub9bc \uc2dc\uc2a4\ud15c\uc744 \uad6c\ucd95\ud558\ub294 \ubc29\ubc95\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4. \ub370\uc774\ud130 \ud488\uc9c8 \uccb4\ud06c\uc640 \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1\ub3c4 \ub2e4\ub8f9\ub2c8\ub2e4."}),"\n",(0,a.jsx)(e.h2,{id:"91-dagit-ui",children:"9.1 Dagit UI"}),"\n",(0,a.jsx)(e.h3,{id:"911-dagit-ui-\uac1c\uc694",children:"9.1.1 Dagit UI \uac1c\uc694"}),"\n",(0,a.jsx)(e.p,{children:"Dagit\uc740 Dagster\uc758 \uc6f9 \uae30\ubc18 UI\ub85c, \ud30c\uc774\ud504\ub77c\uc778\uc744 \uc2dc\uac01\ud654\ud558\uace0 \ubaa8\ub2c8\ud130\ub9c1\ud558\ub294 \uac15\ub825\ud55c \ub3c4\uad6c\uc785\ub2c8\ub2e4."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'"""\nDagit UI \uc8fc\uc694 \uae30\ub2a5:\n\n1. Asset Catalog\n   - \ubaa8\ub4e0 Asset\uc758 \ud604\uc7ac \uc0c1\ud0dc \ud655\uc778\n   - \uc758\uc874\uc131 \uadf8\ub798\ud504 \uc2dc\uac01\ud654\n   - Materialization \ud788\uc2a4\ud1a0\ub9ac\n\n2. Runs\n   - \uc2e4\ud589 \uc911\uc778 Run \ubaa8\ub2c8\ud130\ub9c1\n   - \uacfc\uac70 Run \ud788\uc2a4\ud1a0\ub9ac \uc870\ud68c\n   - \uc2e4\ud328\ud55c Run \uc7ac\uc2e4\ud589\n\n3. Schedules & Sensors\n   - \uc2a4\ucf00\uc904 \uc0c1\ud0dc \ud655\uc778\n   - \uc13c\uc11c \ud3c9\uac00 \ub85c\uadf8\n   - \uc218\ub3d9 \uc2e4\ud589 \ud2b8\ub9ac\uac70\n\n4. Logs\n   - \uad6c\uc870\ud654\ub41c \ub85c\uadf8 \ubdf0\uc5b4\n   - \ub85c\uadf8 \ud544\ud130\ub9c1 \ubc0f \uac80\uc0c9\n   - \uc5d0\ub7ec \ucd94\uc801\n\n5. Lineage\n   - \ub370\uc774\ud130 \uacc4\ubcf4 \ucd94\uc801\n   - Asset \uac04 \uc758\uc874\uc131 \ubd84\uc11d\n   - \uc784\ud329\ud2b8 \ubd84\uc11d\n"""\n'})}),"\n",(0,a.jsx)(e.h3,{id:"912-asset-catalog-\ud65c\uc6a9",children:"9.1.2 Asset Catalog \ud65c\uc6a9"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# assets_with_metadata.py\n"""\n\uba54\ud0c0\ub370\uc774\ud130\uac00 \ud48d\ubd80\ud55c Asset \uc815\uc758\n"""\nfrom dagster import (\n    asset,\n    AssetExecutionContext,\n    MetadataValue,\n    Output\n)\nimport pandas as pd\nfrom datetime import datetime\n\n@asset(\n    description="\uace0\uac1d \ub370\uc774\ud130\ub97c \ub85c\ub4dc\ud558\uace0 \uae30\ubcf8 \ud1b5\uacc4\ub97c \uacc4\uc0b0\ud569\ub2c8\ub2e4.",\n    metadata={\n        "owner": "data-team@company.com",\n        "sla": "daily by 9am",\n        "category": "raw_data"\n    }\n)\ndef customers(context: AssetExecutionContext) -> Output[pd.DataFrame]:\n    """\uace0\uac1d \ub370\uc774\ud130 Asset"""\n    # \ub370\uc774\ud130 \ub85c\ub4dc\n    df = pd.DataFrame({\n        "customer_id": range(1, 101),\n        "name": [f"Customer {i}" for i in range(1, 101)],\n        "total_spent": [100 * i for i in range(1, 101)]\n    })\n\n    # \ud1b5\uacc4 \uacc4\uc0b0\n    stats = {\n        "row_count": len(df),\n        "total_revenue": df["total_spent"].sum(),\n        "avg_spent": df["total_spent"].mean(),\n        "max_spent": df["total_spent"].max()\n    }\n\n    # \uba54\ud0c0\ub370\uc774\ud130\uc640 \ud568\uaed8 \ubc18\ud658\n    return Output(\n        df,\n        metadata={\n            "row_count": MetadataValue.int(stats["row_count"]),\n            "total_revenue": MetadataValue.float(stats["total_revenue"]),\n            "avg_spent": MetadataValue.float(stats["avg_spent"]),\n            "preview": MetadataValue.md(df.head(5).to_markdown()),\n            "schema": MetadataValue.md(\n                "\\n".join([f"- {col}: {dtype}" for col, dtype in df.dtypes.items()])\n            ),\n            "last_updated": MetadataValue.text(datetime.now().isoformat())\n        }\n    )\n\n@asset(\n    description="\uace0\uac1d \uc138\uadf8\uba3c\ud2b8 \ubd84\uc11d",\n    metadata={\n        "owner": "analytics-team@company.com",\n        "category": "analytics"\n    }\n)\ndef customer_segments(\n    context: AssetExecutionContext,\n    customers: pd.DataFrame\n) -> Output[pd.DataFrame]:\n    """\uace0\uac1d \uc138\uadf8\uba3c\ud2b8 Asset"""\n    df = customers.copy()\n\n    # \uc138\uadf8\uba3c\ud2b8 \ubd84\ub958\n    df["segment"] = pd.cut(\n        df["total_spent"],\n        bins=[0, 3000, 7000, float(\'inf\')],\n        labels=["Basic", "Standard", "Premium"]\n    )\n\n    # \uc138\uadf8\uba3c\ud2b8\ubcc4 \ud1b5\uacc4\n    segment_stats = df.groupby("segment").agg({\n        "customer_id": "count",\n        "total_spent": ["sum", "mean"]\n    }).round(2)\n\n    return Output(\n        df,\n        metadata={\n            "row_count": MetadataValue.int(len(df)),\n            "segment_distribution": MetadataValue.md(\n                segment_stats.to_markdown()\n            ),\n            "segments": MetadataValue.json({\n                "Basic": len(df[df["segment"] == "Basic"]),\n                "Standard": len(df[df["segment"] == "Standard"]),\n                "Premium": len(df[df["segment"] == "Premium"])\n            })\n        }\n    )\n'})}),"\n",(0,a.jsx)(e.h3,{id:"913-run-\uc0c1\ud0dc-\ubaa8\ub2c8\ud130\ub9c1",children:"9.1.3 Run \uc0c1\ud0dc \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# run_monitoring.py\n"""\nRun \uc0c1\ud0dc \ubaa8\ub2c8\ud130\ub9c1 \ubc0f \uad00\ub9ac\n"""\nfrom dagster import (\n    DagsterInstance,\n    DagsterRunStatus,\n    RunsFilter,\n    DagsterEventType\n)\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Any\n\nclass RunMonitor:\n    """Run \ubaa8\ub2c8\ud130\ub9c1 \uc720\ud2f8\ub9ac\ud2f0"""\n\n    def __init__(self):\n        self.instance = DagsterInstance.get()\n\n    def get_recent_runs(self, hours: int = 24) -> List[Dict[str, Any]]:\n        """\ucd5c\uadfc \uc2e4\ud589\ub41c Run \uc870\ud68c"""\n        cutoff = datetime.now() - timedelta(hours=hours)\n\n        runs = self.instance.get_runs(\n            filters=RunsFilter(\n                created_after=cutoff\n            ),\n            limit=100\n        )\n\n        return [\n            {\n                "run_id": run.run_id,\n                "status": run.status.value,\n                "job_name": run.job_name,\n                "created_at": run.create_time,\n                "updated_at": run.update_time,\n                "duration_seconds": (\n                    (run.end_time - run.start_time).total_seconds()\n                    if run.end_time and run.start_time else None\n                )\n            }\n            for run in runs\n        ]\n\n    def get_failed_runs(self, hours: int = 24) -> List[Dict[str, Any]]:\n        """\uc2e4\ud328\ud55c Run \uc870\ud68c"""\n        cutoff = datetime.now() - timedelta(hours=hours)\n\n        runs = self.instance.get_runs(\n            filters=RunsFilter(\n                statuses=[DagsterRunStatus.FAILURE],\n                created_after=cutoff\n            )\n        )\n\n        failed_runs = []\n        for run in runs:\n            # \uc5d0\ub7ec \uba54\uc2dc\uc9c0 \ucd94\ucd9c\n            events = self.instance.all_logs(run.run_id)\n            error_events = [\n                event for event in events\n                if event.dagster_event_type == DagsterEventType.STEP_FAILURE\n            ]\n\n            error_messages = [\n                event.message for event in error_events\n            ]\n\n            failed_runs.append({\n                "run_id": run.run_id,\n                "job_name": run.job_name,\n                "created_at": run.create_time,\n                "errors": error_messages\n            })\n\n        return failed_runs\n\n    def get_success_rate(self, hours: int = 24) -> Dict[str, float]:\n        """\uc131\uacf5\ub960 \uacc4\uc0b0"""\n        cutoff = datetime.now() - timedelta(hours=hours)\n\n        all_runs = self.instance.get_runs(\n            filters=RunsFilter(created_after=cutoff),\n            limit=1000\n        )\n\n        if not all_runs:\n            return {"success_rate": 0.0, "total_runs": 0}\n\n        success_count = sum(\n            1 for run in all_runs\n            if run.status == DagsterRunStatus.SUCCESS\n        )\n\n        return {\n            "success_rate": (success_count / len(all_runs)) * 100,\n            "total_runs": len(all_runs),\n            "successful_runs": success_count,\n            "failed_runs": sum(\n                1 for run in all_runs\n                if run.status == DagsterRunStatus.FAILURE\n            )\n        }\n\n    def get_average_duration(self, job_name: str, days: int = 7) -> float:\n        """Job\uc758 \ud3c9\uade0 \uc2e4\ud589 \uc2dc\uac04 \uacc4\uc0b0"""\n        cutoff = datetime.now() - timedelta(days=days)\n\n        runs = self.instance.get_runs(\n            filters=RunsFilter(\n                job_name=job_name,\n                statuses=[DagsterRunStatus.SUCCESS],\n                created_after=cutoff\n            )\n        )\n\n        durations = [\n            (run.end_time - run.start_time).total_seconds()\n            for run in runs\n            if run.end_time and run.start_time\n        ]\n\n        if not durations:\n            return 0.0\n\n        return sum(durations) / len(durations)\n\n# \uc0ac\uc6a9 \uc608\uc81c\nif __name__ == "__main__":\n    monitor = RunMonitor()\n\n    print("=== \ucd5c\uadfc 24\uc2dc\uac04 Run \ud1b5\uacc4 ===")\n    stats = monitor.get_success_rate(hours=24)\n    print(f"\ucd1d Run: {stats[\'total_runs\']}")\n    print(f"\uc131\uacf5: {stats[\'successful_runs\']}")\n    print(f"\uc2e4\ud328: {stats[\'failed_runs\']}")\n    print(f"\uc131\uacf5\ub960: {stats[\'success_rate\']:.2f}%")\n\n    print("\\n=== \uc2e4\ud328\ud55c Run ===")\n    failed = monitor.get_failed_runs(hours=24)\n    for run in failed[:5]:  # \ucd5c\uadfc 5\uac1c\ub9cc \ucd9c\ub825\n        print(f"\\nRun ID: {run[\'run_id\']}")\n        print(f"Job: {run[\'job_name\']}")\n        print(f"\uc2dc\uac04: {run[\'created_at\']}")\n        if run[\'errors\']:\n            print(f"\uc5d0\ub7ec: {run[\'errors\'][0][:100]}...")\n'})}),"\n",(0,a.jsx)(e.h2,{id:"92-\ub85c\uae45",children:"9.2 \ub85c\uae45"}),"\n",(0,a.jsx)(e.h3,{id:"921-\uad6c\uc870\ud654\ub41c-\ub85c\uae45",children:"9.2.1 \uad6c\uc870\ud654\ub41c \ub85c\uae45"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# logging_examples.py\n"""\nDagster \ub85c\uae45 \ud328\ud134\n"""\nfrom dagster import (\n    asset,\n    AssetExecutionContext,\n    op,\n    OpExecutionContext,\n    get_dagster_logger\n)\nimport pandas as pd\nfrom typing import Dict, Any\n\n@asset\ndef structured_logging_example(context: AssetExecutionContext) -> pd.DataFrame:\n    """\uad6c\uc870\ud654\ub41c \ub85c\uae45 \uc608\uc81c"""\n    # \uae30\ubcf8 \ub85c\uadf8\n    context.log.info("Starting data processing")\n\n    # \uad6c\uc870\ud654\ub41c \ub85c\uadf8 (\uba54\ud0c0\ub370\uc774\ud130 \ud3ec\ud568)\n    context.log.info(\n        "Loading data from source",\n        extra={\n            "source": "database",\n            "table": "customers",\n            "row_count": 1000\n        }\n    )\n\n    # \ub370\uc774\ud130 \ucc98\ub9ac\n    df = pd.DataFrame({"id": [1, 2, 3], "value": [10, 20, 30]})\n\n    # \uacbd\uace0 \ub85c\uadf8\n    if len(df) < 100:\n        context.log.warning(\n            "Low data volume detected",\n            extra={"row_count": len(df), "expected_minimum": 100}\n        )\n\n    # \ub514\ubc84\uadf8 \ub85c\uadf8\n    context.log.debug(\n        "Data sample",\n        extra={"sample": df.head(2).to_dict()}\n    )\n\n    # \uc644\ub8cc \ub85c\uadf8\n    context.log.info(\n        "Processing completed",\n        extra={\n            "row_count": len(df),\n            "column_count": len(df.columns),\n            "memory_usage_mb": df.memory_usage(deep=True).sum() / 1024 / 1024\n        }\n    )\n\n    return df\n\n@op\ndef process_with_progress_logging(context: OpExecutionContext) -> Dict[str, Any]:\n    """\uc9c4\ud589\ub960 \ub85c\uae45 \uc608\uc81c"""\n    total_items = 100\n\n    context.log.info(f"Processing {total_items} items")\n\n    for i in range(0, total_items, 10):\n        # \uc2e4\uc81c \ucc98\ub9ac \ub85c\uc9c1...\n        progress = ((i + 10) / total_items) * 100\n\n        context.log.info(\n            f"Progress: {progress:.0f}%",\n            extra={\n                "processed": i + 10,\n                "total": total_items,\n                "progress_percent": progress\n            }\n        )\n\n    context.log.info("Processing completed")\n\n    return {"status": "success", "processed": total_items}\n'})}),"\n",(0,a.jsx)(e.h3,{id:"922-\ucee4\uc2a4\ud140-logger",children:"9.2.2 \ucee4\uc2a4\ud140 Logger"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# custom_logger.py\n"""\n\ucee4\uc2a4\ud140 \ub85c\uac70 \uad6c\ud604\n"""\nimport logging\nimport json\nfrom datetime import datetime\nfrom typing import Any, Dict\nfrom dagster import ConfigurableResource\n\nclass StructuredLogger(ConfigurableResource):\n    """\uad6c\uc870\ud654\ub41c JSON \ub85c\uac70"""\n    log_level: str = "INFO"\n    service_name: str = "dagster-pipeline"\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.logger = logging.getLogger(self.service_name)\n        self.logger.setLevel(getattr(logging, self.log_level))\n\n        # JSON \ud3ec\ub9f7 \ud578\ub4e4\ub7ec\n        handler = logging.StreamHandler()\n        handler.setFormatter(JsonFormatter())\n        self.logger.addHandler(handler)\n\n    def log(\n        self,\n        level: str,\n        message: str,\n        **kwargs: Any\n    ):\n        """\ub85c\uadf8 \uba54\uc2dc\uc9c0 \uc791\uc131"""\n        log_data = {\n            "timestamp": datetime.now().isoformat(),\n            "service": self.service_name,\n            "level": level,\n            "message": message,\n            **kwargs\n        }\n\n        log_func = getattr(self.logger, level.lower())\n        log_func(json.dumps(log_data))\n\nclass JsonFormatter(logging.Formatter):\n    """JSON \ud3ec\ub9f7 \ub85c\uac70"""\n\n    def format(self, record: logging.LogRecord) -> str:\n        """\ub85c\uadf8 \ub808\ucf54\ub4dc\ub97c JSON\uc73c\ub85c \ud3ec\ub9f7"""\n        log_data = {\n            "timestamp": datetime.fromtimestamp(record.created).isoformat(),\n            "level": record.levelname,\n            "logger": record.name,\n            "message": record.getMessage(),\n        }\n\n        # \ucd94\uac00 \ud544\ub4dc\n        if hasattr(record, "extra"):\n            log_data.update(record.extra)\n\n        return json.dumps(log_data)\n\n# \uc0ac\uc6a9 \uc608\uc81c\n@asset\ndef asset_with_custom_logger(\n    context: AssetExecutionContext,\n    logger: StructuredLogger\n) -> pd.DataFrame:\n    """\ucee4\uc2a4\ud140 \ub85c\uac70\ub97c \uc0ac\uc6a9\ud558\ub294 Asset"""\n    logger.log(\n        "info",\n        "Starting asset materialization",\n        asset_name="asset_with_custom_logger",\n        run_id=context.run_id\n    )\n\n    df = pd.DataFrame({"id": [1, 2, 3]})\n\n    logger.log(\n        "info",\n        "Asset materialization completed",\n        asset_name="asset_with_custom_logger",\n        row_count=len(df),\n        run_id=context.run_id\n    )\n\n    return df\n'})}),"\n",(0,a.jsx)(e.h3,{id:"923-\ub85c\uadf8-\uc9d1\uacc4-\ubc0f-\ubd84\uc11d",children:"9.2.3 \ub85c\uadf8 \uc9d1\uacc4 \ubc0f \ubd84\uc11d"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# log_analysis.py\n"""\n\ub85c\uadf8 \uc9d1\uacc4 \ubc0f \ubd84\uc11d\n"""\nfrom dagster import DagsterInstance, DagsterEventType\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Any\nfrom collections import Counter\nimport re\n\nclass LogAnalyzer:\n    """\ub85c\uadf8 \ubd84\uc11d \uc720\ud2f8\ub9ac\ud2f0"""\n\n    def __init__(self):\n        self.instance = DagsterInstance.get()\n\n    def analyze_run_logs(self, run_id: str) -> Dict[str, Any]:\n        """Run\uc758 \ub85c\uadf8 \ubd84\uc11d"""\n        events = self.instance.all_logs(run_id)\n\n        # \ub85c\uadf8 \ub808\ubca8\ubcc4 \uce74\uc6b4\ud2b8\n        log_levels = Counter()\n        error_messages = []\n        warning_messages = []\n\n        for event in events:\n            level = event.level\n            log_levels[level] += 1\n\n            if level == "ERROR":\n                error_messages.append(event.message)\n            elif level == "WARNING":\n                warning_messages.append(event.message)\n\n        return {\n            "total_logs": len(events),\n            "log_levels": dict(log_levels),\n            "error_count": log_levels["ERROR"],\n            "warning_count": log_levels["WARNING"],\n            "errors": error_messages[:10],  # \ucd5c\uadfc 10\uac1c\n            "warnings": warning_messages[:10]\n        }\n\n    def find_common_errors(self, hours: int = 24) -> List[Dict[str, Any]]:\n        """\uacf5\ud1b5 \uc5d0\ub7ec \ud328\ud134 \ucc3e\uae30"""\n        cutoff = datetime.now() - timedelta(hours=hours)\n\n        runs = self.instance.get_runs(limit=100)\n        error_patterns = Counter()\n\n        for run in runs:\n            if run.create_time < cutoff:\n                continue\n\n            events = self.instance.all_logs(run.run_id)\n            error_events = [\n                e for e in events\n                if e.dagster_event_type == DagsterEventType.STEP_FAILURE\n            ]\n\n            for event in error_events:\n                # \uc5d0\ub7ec \uba54\uc2dc\uc9c0\uc5d0\uc11c \ud328\ud134 \ucd94\ucd9c (\uac04\ub2e8\ud55c \uc608\uc2dc)\n                message = event.message\n                # \uc22b\uc790, ID \ub4f1\uc744 \uc81c\uac70\ud558\uc5ec \ud328\ud134\ud654\n                pattern = re.sub(r\'\\d+\', \'N\', message)\n                pattern = re.sub(r\'[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}\', \'UUID\', pattern)\n                error_patterns[pattern] += 1\n\n        # \uac00\uc7a5 \ud754\ud55c \uc5d0\ub7ec \ud328\ud134\n        return [\n            {"pattern": pattern, "count": count}\n            for pattern, count in error_patterns.most_common(10)\n        ]\n\n    def get_performance_metrics(self, run_id: str) -> Dict[str, Any]:\n        """\uc131\ub2a5 \uba54\ud2b8\ub9ad \ucd94\ucd9c"""\n        events = self.instance.all_logs(run_id)\n\n        step_durations = {}\n        step_start_times = {}\n\n        for event in events:\n            if not event.dagster_event:\n                continue\n\n            event_type = event.dagster_event_type\n            step_key = event.step_key\n\n            if event_type == DagsterEventType.STEP_START:\n                step_start_times[step_key] = event.timestamp\n\n            elif event_type == DagsterEventType.STEP_SUCCESS:\n                if step_key in step_start_times:\n                    duration = event.timestamp - step_start_times[step_key]\n                    step_durations[step_key] = duration\n\n        return {\n            "step_count": len(step_durations),\n            "total_duration": sum(step_durations.values()),\n            "avg_duration": (\n                sum(step_durations.values()) / len(step_durations)\n                if step_durations else 0\n            ),\n            "slowest_steps": sorted(\n                step_durations.items(),\n                key=lambda x: x[1],\n                reverse=True\n            )[:5]\n        }\n'})}),"\n",(0,a.jsx)(e.h2,{id:"93-\uba54\ud2b8\ub9ad",children:"9.3 \uba54\ud2b8\ub9ad"}),"\n",(0,a.jsx)(e.h3,{id:"931-prometheus-\uba54\ud2b8\ub9ad",children:"9.3.1 Prometheus \uba54\ud2b8\ub9ad"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# metrics.py\n"""\nPrometheus \uba54\ud2b8\ub9ad \uc218\uc9d1\n"""\nfrom prometheus_client import (\n    Counter,\n    Gauge,\n    Histogram,\n    Summary,\n    start_http_server\n)\nfrom dagster import asset, AssetExecutionContext, op, OpExecutionContext\nimport time\nfrom functools import wraps\n\n# \uba54\ud2b8\ub9ad \uc815\uc758\nasset_materializations = Counter(\n    \'dagster_asset_materializations_total\',\n    \'Total number of asset materializations\',\n    [\'asset_name\', \'status\']\n)\n\nasset_duration = Histogram(\n    \'dagster_asset_duration_seconds\',\n    \'Asset materialization duration\',\n    [\'asset_name\'],\n    buckets=[1, 5, 10, 30, 60, 120, 300, 600, 1800, 3600]\n)\n\nasset_row_count = Gauge(\n    \'dagster_asset_row_count\',\n    \'Number of rows in asset\',\n    [\'asset_name\']\n)\n\nop_executions = Counter(\n    \'dagster_op_executions_total\',\n    \'Total number of op executions\',\n    [\'op_name\', \'status\']\n)\n\nclass MetricsCollector:\n    """\uba54\ud2b8\ub9ad \uc218\uc9d1 \uc720\ud2f8\ub9ac\ud2f0"""\n\n    @staticmethod\n    def record_asset_metrics(asset_name: str):\n        """Asset \uba54\ud2b8\ub9ad \uae30\ub85d \ub370\ucf54\ub808\uc774\ud130"""\n        def decorator(func):\n            @wraps(func)\n            def wrapper(*args, **kwargs):\n                start_time = time.time()\n                status = "success"\n\n                try:\n                    result = func(*args, **kwargs)\n\n                    # \uacb0\uacfc\uac00 DataFrame\uc778 \uacbd\uc6b0 \ud589 \uc218 \uae30\ub85d\n                    if hasattr(result, \'__len__\'):\n                        asset_row_count.labels(asset_name=asset_name).set(len(result))\n\n                    return result\n\n                except Exception as e:\n                    status = "failure"\n                    raise\n\n                finally:\n                    # \uc2e4\ud589 \uc2dc\uac04 \uae30\ub85d\n                    duration = time.time() - start_time\n                    asset_duration.labels(asset_name=asset_name).observe(duration)\n\n                    # \uc2e4\ud589 \uce74\uc6b4\ud2b8\n                    asset_materializations.labels(\n                        asset_name=asset_name,\n                        status=status\n                    ).inc()\n\n            return wrapper\n        return decorator\n\n# \uc0ac\uc6a9 \uc608\uc81c\n@asset\n@MetricsCollector.record_asset_metrics("customers_data")\ndef customers_data(context: AssetExecutionContext) -> pd.DataFrame:\n    """\uace0\uac1d \ub370\uc774\ud130 Asset (\uba54\ud2b8\ub9ad \ud3ec\ud568)"""\n    context.log.info("Loading customers data")\n\n    df = pd.DataFrame({\n        "customer_id": range(1, 1001),\n        "name": [f"Customer {i}" for i in range(1, 1001)]\n    })\n\n    return df\n'})}),"\n",(0,a.jsx)(e.h3,{id:"932-\ucee4\uc2a4\ud140-\uba54\ud2b8\ub9ad",children:"9.3.2 \ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# custom_metrics.py\n"""\n\ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc815\uc758 \ubc0f \uc218\uc9d1\n"""\nfrom dagster import (\n    asset,\n    AssetExecutionContext,\n    Output,\n    MetadataValue,\n    AssetObservation\n)\nimport pandas as pd\nfrom typing import Dict, Any\nfrom datetime import datetime\n\nclass DataQualityMetrics:\n    """\ub370\uc774\ud130 \ud488\uc9c8 \uba54\ud2b8\ub9ad"""\n\n    @staticmethod\n    def calculate_completeness(df: pd.DataFrame) -> float:\n        """\uc644\uc804\uc131: \uacb0\uce21\uce58\uac00 \uc5c6\ub294 \ube44\uc728"""\n        total_cells = df.size\n        non_null_cells = df.count().sum()\n        return (non_null_cells / total_cells) * 100 if total_cells > 0 else 0\n\n    @staticmethod\n    def calculate_uniqueness(df: pd.DataFrame, key_columns: list) -> float:\n        """\uc720\uc77c\uc131: \uc911\ubcf5\uc774 \uc5c6\ub294 \ube44\uc728"""\n        total_rows = len(df)\n        unique_rows = len(df.drop_duplicates(subset=key_columns))\n        return (unique_rows / total_rows) * 100 if total_rows > 0 else 0\n\n    @staticmethod\n    def calculate_validity(\n        df: pd.DataFrame,\n        rules: Dict[str, callable]\n    ) -> Dict[str, float]:\n        """\uc720\ud6a8\uc131: \uaddc\uce59\uc744 \ub9cc\uc871\ud558\ub294 \ube44\uc728"""\n        validity_scores = {}\n\n        for column, rule in rules.items():\n            if column in df.columns:\n                valid_count = df[column].apply(rule).sum()\n                validity_scores[column] = (valid_count / len(df)) * 100\n\n        return validity_scores\n\n@asset\ndef quality_checked_data(\n    context: AssetExecutionContext\n) -> Output[pd.DataFrame]:\n    """\ub370\uc774\ud130 \ud488\uc9c8 \uccb4\ud06c\uac00 \ud3ec\ud568\ub41c Asset"""\n    # \ub370\uc774\ud130 \ub85c\ub4dc\n    df = pd.DataFrame({\n        "id": [1, 2, 3, 4, 5],\n        "email": [\n            "user1@example.com",\n            "user2@example.com",\n            None,\n            "invalid_email",\n            "user5@example.com"\n        ],\n        "age": [25, 30, 35, -5, 40]  # -5\ub294 \uc720\ud6a8\ud558\uc9c0 \uc54a\uc74c\n    })\n\n    # \ud488\uc9c8 \uba54\ud2b8\ub9ad \uacc4\uc0b0\n    metrics = DataQualityMetrics()\n\n    completeness = metrics.calculate_completeness(df)\n    uniqueness = metrics.calculate_uniqueness(df, ["id"])\n\n    # \uc720\ud6a8\uc131 \uaddc\uce59\n    validity_rules = {\n        "email": lambda x: pd.notna(x) and "@" in str(x),\n        "age": lambda x: x > 0 if pd.notna(x) else False\n    }\n    validity = metrics.calculate_validity(df, validity_rules)\n\n    # \uc804\uccb4 \ud488\uc9c8 \uc810\uc218\n    quality_score = (\n        completeness * 0.4 +\n        uniqueness * 0.3 +\n        sum(validity.values()) / len(validity) * 0.3\n    )\n\n    # \ud488\uc9c8 \uc774\uc288 \uac80\uc0ac\n    issues = []\n    if completeness < 95:\n        issues.append(f"Low completeness: {completeness:.1f}%")\n    if validity["email"] < 80:\n        issues.append(f"Invalid emails detected: {100 - validity[\'email\']:.1f}%")\n    if validity["age"] < 100:\n        issues.append(f"Invalid ages detected: {100 - validity[\'age\']:.1f}%")\n\n    # \uba54\ud0c0\ub370\uc774\ud130\ub85c \uba54\ud2b8\ub9ad \ubc18\ud658\n    return Output(\n        df,\n        metadata={\n            "quality_score": MetadataValue.float(quality_score),\n            "completeness": MetadataValue.float(completeness),\n            "uniqueness": MetadataValue.float(uniqueness),\n            "email_validity": MetadataValue.float(validity["email"]),\n            "age_validity": MetadataValue.float(validity["age"]),\n            "issues": MetadataValue.md(\n                "\\n".join([f"- {issue}" for issue in issues]) if issues\n                else "No issues detected"\n            ),\n            "timestamp": MetadataValue.text(datetime.now().isoformat())\n        }\n    )\n\n@asset\ndef monitored_asset(context: AssetExecutionContext) -> pd.DataFrame:\n    """\uad00\ucc30(Observation) \ud328\ud134\uc744 \uc0ac\uc6a9\ud55c \ubaa8\ub2c8\ud130\ub9c1"""\n    df = pd.DataFrame({"value": range(100)})\n\n    # AssetObservation\uc744 \uc0ac\uc6a9\ud558\uc5ec \uc911\uac04 \uba54\ud2b8\ub9ad \uae30\ub85d\n    context.log_event(\n        AssetObservation(\n            asset_key=context.asset_key,\n            metadata={\n                "row_count": MetadataValue.int(len(df)),\n                "mean_value": MetadataValue.float(df["value"].mean()),\n                "std_value": MetadataValue.float(df["value"].std())\n            }\n        )\n    )\n\n    return df\n'})}),"\n",(0,a.jsx)(e.h2,{id:"94-\uc54c\ub9bc",children:"9.4 \uc54c\ub9bc"}),"\n",(0,a.jsx)(e.h3,{id:"941-slack-\uc54c\ub9bc",children:"9.4.1 Slack \uc54c\ub9bc"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# alerts/slack.py\n"""\nSlack \uc54c\ub9bc \uc124\uc815\n"""\nfrom dagster import (\n    RunStatusSensorContext,\n    run_status_sensor,\n    run_failure_sensor,\n    DagsterRunStatus,\n    RunRequest,\n    DefaultSensorStatus\n)\nfrom slack_sdk import WebClient\nfrom slack_sdk.errors import SlackApiError\nfrom typing import Optional\nimport os\n\nclass SlackNotifier:\n    """Slack \uc54c\ub9bc \uc804\uc1a1"""\n\n    def __init__(self, token: Optional[str] = None):\n        self.token = token or os.getenv("SLACK_BOT_TOKEN")\n        self.client = WebClient(token=self.token)\n\n    def send_message(\n        self,\n        channel: str,\n        message: str,\n        color: str = "good"\n    ) -> bool:\n        """Slack \uba54\uc2dc\uc9c0 \uc804\uc1a1"""\n        try:\n            response = self.client.chat_postMessage(\n                channel=channel,\n                attachments=[\n                    {\n                        "color": color,\n                        "text": message,\n                        "mrkdwn_in": ["text"]\n                    }\n                ]\n            )\n            return response["ok"]\n\n        except SlackApiError as e:\n            print(f"Slack API Error: {e.response[\'error\']}")\n            return False\n\n    def send_run_failure(\n        self,\n        channel: str,\n        run_id: str,\n        job_name: str,\n        error_message: str\n    ) -> bool:\n        """Run \uc2e4\ud328 \uc54c\ub9bc"""\n        message = f"""\n*\ud83d\udea8 Dagster Run Failed*\n\n*Job:* `{job_name}`\n*Run ID:* `{run_id}`\n*Error:* {error_message}\n\n<http://dagster-ui/runs/{run_id}|View in Dagit>\n        """\n\n        return self.send_message(channel, message, color="danger")\n\n    def send_run_success(\n        self,\n        channel: str,\n        run_id: str,\n        job_name: str,\n        duration: float\n    ) -> bool:\n        """Run \uc131\uacf5 \uc54c\ub9bc"""\n        message = f"""\n*\u2705 Dagster Run Succeeded*\n\n*Job:* `{job_name}`\n*Run ID:* `{run_id}`\n*Duration:* {duration:.2f} seconds\n\n<http://dagster-ui/runs/{run_id}|View in Dagit>\n        """\n\n        return self.send_message(channel, message, color="good")\n\n# Sensor \uc815\uc758\n@run_failure_sensor(\n    name="slack_on_failure",\n    default_status=DefaultSensorStatus.RUNNING\n)\ndef slack_failure_sensor(context: RunStatusSensorContext):\n    """Run \uc2e4\ud328 \uc2dc Slack \uc54c\ub9bc"""\n    notifier = SlackNotifier()\n\n    # \uc5d0\ub7ec \uba54\uc2dc\uc9c0 \ucd94\ucd9c\n    error_message = "Unknown error"\n    if context.dagster_run.job_name:\n        error_message = f"Job {context.dagster_run.job_name} failed"\n\n    # Slack \uc804\uc1a1\n    notifier.send_run_failure(\n        channel="#dagster-alerts",\n        run_id=context.dagster_run.run_id,\n        job_name=context.dagster_run.job_name or "Unknown",\n        error_message=error_message\n    )\n\n@run_status_sensor(\n    run_status=DagsterRunStatus.SUCCESS,\n    name="slack_on_success",\n    default_status=DefaultSensorStatus.STOPPED  # \uae30\ubcf8\uc801\uc73c\ub85c \ube44\ud65c\uc131\ud654\n)\ndef slack_success_sensor(context: RunStatusSensorContext):\n    """Run \uc131\uacf5 \uc2dc Slack \uc54c\ub9bc"""\n    notifier = SlackNotifier()\n\n    # \uc2e4\ud589 \uc2dc\uac04 \uacc4\uc0b0\n    duration = 0.0\n    if context.dagster_run.start_time and context.dagster_run.end_time:\n        duration = (\n            context.dagster_run.end_time - context.dagster_run.start_time\n        ).total_seconds()\n\n    # Slack \uc804\uc1a1\n    notifier.send_run_success(\n        channel="#dagster-notifications",\n        run_id=context.dagster_run.run_id,\n        job_name=context.dagster_run.job_name or "Unknown",\n        duration=duration\n    )\n'})}),"\n",(0,a.jsx)(e.h3,{id:"942-email-\uc54c\ub9bc",children:"9.4.2 Email \uc54c\ub9bc"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# alerts/email.py\n"""\nEmail \uc54c\ub9bc \uc124\uc815\n"""\nfrom dagster import run_failure_sensor, RunStatusSensorContext\nimport smtplib\nfrom email.mime.text import MIMEText\nfrom email.mime.multipart import MIMEMultipart\nfrom typing import List\nimport os\n\nclass EmailNotifier:\n    """Email \uc54c\ub9bc \uc804\uc1a1"""\n\n    def __init__(\n        self,\n        smtp_server: str = None,\n        smtp_port: int = 587,\n        username: str = None,\n        password: str = None\n    ):\n        self.smtp_server = smtp_server or os.getenv("SMTP_SERVER", "smtp.gmail.com")\n        self.smtp_port = smtp_port\n        self.username = username or os.getenv("SMTP_USERNAME")\n        self.password = password or os.getenv("SMTP_PASSWORD")\n\n    def send_email(\n        self,\n        to_emails: List[str],\n        subject: str,\n        body: str,\n        html: bool = False\n    ) -> bool:\n        """Email \uc804\uc1a1"""\n        try:\n            msg = MIMEMultipart("alternative")\n            msg["From"] = self.username\n            msg["To"] = ", ".join(to_emails)\n            msg["Subject"] = subject\n\n            # \ubcf8\ubb38 \ucd94\uac00\n            mime_type = "html" if html else "plain"\n            msg.attach(MIMEText(body, mime_type))\n\n            # SMTP \uc11c\ubc84 \uc5f0\uacb0 \ubc0f \uc804\uc1a1\n            with smtplib.SMTP(self.smtp_server, self.smtp_port) as server:\n                server.starttls()\n                server.login(self.username, self.password)\n                server.send_message(msg)\n\n            return True\n\n        except Exception as e:\n            print(f"Email send error: {e}")\n            return False\n\n    def send_failure_alert(\n        self,\n        to_emails: List[str],\n        run_id: str,\n        job_name: str,\n        error_message: str\n    ) -> bool:\n        """\uc2e4\ud328 \uc54c\ub9bc \uc774\uba54\uc77c"""\n        subject = f"[Dagster] Job Failed: {job_name}"\n\n        body = f"""\n        <html>\n        <body>\n            <h2 style="color: #d32f2f;">\ud83d\udea8 Dagster Job Failed</h2>\n\n            <p><strong>Job Name:</strong> {job_name}</p>\n            <p><strong>Run ID:</strong> <code>{run_id}</code></p>\n\n            <h3>Error Details:</h3>\n            <pre style="background-color: #f5f5f5; padding: 10px; border-radius: 4px;">\n{error_message}\n            </pre>\n\n            <p>\n                <a href="http://dagster-ui/runs/{run_id}"\n                   style="background-color: #1976d2; color: white; padding: 10px 20px;\n                          text-decoration: none; border-radius: 4px;">\n                    View in Dagit\n                </a>\n            </p>\n        </body>\n        </html>\n        """\n\n        return self.send_email(to_emails, subject, body, html=True)\n\n@run_failure_sensor(name="email_on_failure")\ndef email_failure_sensor(context: RunStatusSensorContext):\n    """Run \uc2e4\ud328 \uc2dc Email \uc54c\ub9bc"""\n    notifier = EmailNotifier()\n\n    # \ub2f4\ub2f9\uc790 \uc774\uba54\uc77c (Job \ud0dc\uadf8\uc5d0\uc11c \uac00\uc838\uc624\uae30)\n    tags = context.dagster_run.tags\n    to_emails = tags.get("owner_email", "data-team@company.com").split(",")\n\n    # \uc5d0\ub7ec \uba54\uc2dc\uc9c0 \ucd94\ucd9c\n    error_message = "Unknown error occurred"\n\n    # Email \uc804\uc1a1\n    notifier.send_failure_alert(\n        to_emails=to_emails,\n        run_id=context.dagster_run.run_id,\n        job_name=context.dagster_run.job_name or "Unknown",\n        error_message=error_message\n    )\n'})}),"\n",(0,a.jsx)(e.h3,{id:"943-pagerduty-\ud1b5\ud569",children:"9.4.3 PagerDuty \ud1b5\ud569"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# alerts/pagerduty.py\n"""\nPagerDuty \ud1b5\ud569\n"""\nfrom dagster import run_failure_sensor, RunStatusSensorContext\nimport requests\nfrom typing import Optional\nimport os\n\nclass PagerDutyNotifier:\n    """PagerDuty \uc54c\ub9bc"""\n\n    def __init__(self, integration_key: Optional[str] = None):\n        self.integration_key = integration_key or os.getenv("PAGERDUTY_INTEGRATION_KEY")\n        self.api_url = "https://events.pagerduty.com/v2/enqueue"\n\n    def trigger_incident(\n        self,\n        summary: str,\n        severity: str = "error",\n        source: str = "dagster",\n        custom_details: dict = None\n    ) -> bool:\n        """PagerDuty \uc778\uc2dc\ub358\ud2b8 \uc0dd\uc131"""\n        payload = {\n            "routing_key": self.integration_key,\n            "event_action": "trigger",\n            "payload": {\n                "summary": summary,\n                "severity": severity,\n                "source": source,\n                "custom_details": custom_details or {}\n            }\n        }\n\n        try:\n            response = requests.post(self.api_url, json=payload, timeout=10)\n            response.raise_for_status()\n            return True\n\n        except requests.RequestException as e:\n            print(f"PagerDuty API error: {e}")\n            return False\n\n@run_failure_sensor(name="pagerduty_on_critical_failure")\ndef pagerduty_critical_failure_sensor(context: RunStatusSensorContext):\n    """\uc911\uc694\ud55c Job \uc2e4\ud328 \uc2dc PagerDuty \uc54c\ub9bc"""\n    # "critical" \ud0dc\uadf8\uac00 \uc788\ub294 Job\ub9cc \uc54c\ub9bc\n    tags = context.dagster_run.tags\n    if tags.get("priority") != "critical":\n        return\n\n    notifier = PagerDutyNotifier()\n\n    notifier.trigger_incident(\n        summary=f"Critical Dagster job failed: {context.dagster_run.job_name}",\n        severity="critical",\n        custom_details={\n            "run_id": context.dagster_run.run_id,\n            "job_name": context.dagster_run.job_name,\n            "dagit_url": f"http://dagster-ui/runs/{context.dagster_run.run_id}"\n        }\n    )\n'})}),"\n",(0,a.jsx)(e.h2,{id:"95-\ub370\uc774\ud130-\ud488\uc9c8",children:"9.5 \ub370\uc774\ud130 \ud488\uc9c8"}),"\n",(0,a.jsx)(e.h3,{id:"951-data-quality-checks",children:"9.5.1 Data Quality Checks"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# quality/checks.py\n"""\n\ub370\uc774\ud130 \ud488\uc9c8 \uccb4\ud06c\n"""\nfrom dagster import (\n    asset,\n    AssetExecutionContext,\n    Output,\n    AssetCheckSpec,\n    AssetCheckResult,\n    AssetCheckSeverity\n)\nimport pandas as pd\nfrom typing import List, Callable\n\nclass DataQualityCheck:\n    """\ub370\uc774\ud130 \ud488\uc9c8 \uccb4\ud06c \ud074\ub798\uc2a4"""\n\n    @staticmethod\n    def check_no_nulls(df: pd.DataFrame, columns: List[str]) -> AssetCheckResult:\n        """\uacb0\uce21\uce58 \uccb4\ud06c"""\n        null_counts = df[columns].isnull().sum()\n        has_nulls = null_counts.sum() > 0\n\n        return AssetCheckResult(\n            passed=not has_nulls,\n            metadata={\n                "null_counts": null_counts.to_dict(),\n                "total_nulls": int(null_counts.sum())\n            },\n            severity=AssetCheckSeverity.ERROR if has_nulls else None\n        )\n\n    @staticmethod\n    def check_unique(df: pd.DataFrame, columns: List[str]) -> AssetCheckResult:\n        """\uc720\uc77c\uc131 \uccb4\ud06c"""\n        duplicate_count = df.duplicated(subset=columns).sum()\n        is_unique = duplicate_count == 0\n\n        return AssetCheckResult(\n            passed=is_unique,\n            metadata={\n                "duplicate_count": int(duplicate_count),\n                "unique_ratio": float(1 - duplicate_count / len(df))\n            },\n            severity=AssetCheckSeverity.WARN if not is_unique else None\n        )\n\n    @staticmethod\n    def check_value_range(\n        df: pd.DataFrame,\n        column: str,\n        min_value: float,\n        max_value: float\n    ) -> AssetCheckResult:\n        """\uac12 \ubc94\uc704 \uccb4\ud06c"""\n        out_of_range = df[\n            (df[column] < min_value) | (df[column] > max_value)\n        ]\n        in_range = len(out_of_range) == 0\n\n        return AssetCheckResult(\n            passed=in_range,\n            metadata={\n                "out_of_range_count": len(out_of_range),\n                "min_found": float(df[column].min()),\n                "max_found": float(df[column].max()),\n                "expected_range": f"[{min_value}, {max_value}]"\n            },\n            severity=AssetCheckSeverity.ERROR if not in_range else None\n        )\n\n    @staticmethod\n    def check_freshness(\n        df: pd.DataFrame,\n        date_column: str,\n        max_age_hours: int\n    ) -> AssetCheckResult:\n        """\ub370\uc774\ud130 \uc2e0\uc120\ub3c4 \uccb4\ud06c"""\n        from datetime import datetime, timedelta\n\n        latest_date = pd.to_datetime(df[date_column]).max()\n        age = datetime.now() - latest_date\n        is_fresh = age < timedelta(hours=max_age_hours)\n\n        return AssetCheckResult(\n            passed=is_fresh,\n            metadata={\n                "latest_date": latest_date.isoformat(),\n                "age_hours": float(age.total_seconds() / 3600),\n                "max_age_hours": max_age_hours\n            },\n            severity=AssetCheckSeverity.WARN if not is_fresh else None\n        )\n\n# Asset with checks\n@asset(\n    check_specs=[\n        AssetCheckSpec(name="no_null_ids", asset="validated_customers"),\n        AssetCheckSpec(name="unique_customer_ids", asset="validated_customers"),\n        AssetCheckSpec(name="age_range", asset="validated_customers"),\n    ]\n)\ndef validated_customers(context: AssetExecutionContext) -> Output[pd.DataFrame]:\n    """\ud488\uc9c8 \uccb4\ud06c\uac00 \ud3ec\ud568\ub41c \uace0\uac1d \ub370\uc774\ud130"""\n    df = pd.DataFrame({\n        "customer_id": [1, 2, 3, 4, 5],\n        "name": ["Alice", "Bob", "Charlie", "David", "Eve"],\n        "age": [25, 30, 35, 40, 45],\n        "email": [\n            "alice@example.com",\n            "bob@example.com",\n            None,  # \uacb0\uce21\uce58\n            "david@example.com",\n            "eve@example.com"\n        ]\n    })\n\n    # \ud488\uc9c8 \uccb4\ud06c \uc2e4\ud589\n    checker = DataQualityCheck()\n\n    # 1. NULL \uccb4\ud06c\n    null_check = checker.check_no_nulls(df, ["customer_id", "name"])\n    context.log.info(f"NULL check: {\'PASSED\' if null_check.passed else \'FAILED\'}")\n\n    # 2. \uc720\uc77c\uc131 \uccb4\ud06c\n    unique_check = checker.check_unique(df, ["customer_id"])\n    context.log.info(f"Unique check: {\'PASSED\' if unique_check.passed else \'FAILED\'}")\n\n    # 3. \ubc94\uc704 \uccb4\ud06c\n    range_check = checker.check_value_range(df, "age", min_value=18, max_value=100)\n    context.log.info(f"Range check: {\'PASSED\' if range_check.passed else \'FAILED\'}")\n\n    return Output(df)\n'})}),"\n",(0,a.jsx)(e.h3,{id:"952-great-expectations-\ud1b5\ud569",children:"9.5.2 Great Expectations \ud1b5\ud569"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# quality/great_expectations_integration.py\n"""\nGreat Expectations \ud1b5\ud569\n"""\nfrom dagster import asset, AssetExecutionContext, Output\nfrom dagster_ge import ge_validation_op_factory\nimport pandas as pd\nimport great_expectations as ge\nfrom great_expectations.core import ExpectationSuite\n\n@asset\ndef customers_with_ge(context: AssetExecutionContext) -> Output[pd.DataFrame]:\n    """Great Expectations\ub97c \uc0ac\uc6a9\ud55c \ub370\uc774\ud130 \uac80\uc99d"""\n    # \ub370\uc774\ud130 \ub85c\ub4dc\n    df = pd.DataFrame({\n        "customer_id": range(1, 101),\n        "email": [f"user{i}@example.com" for i in range(1, 101)],\n        "age": [20 + (i % 50) for i in range(1, 101)],\n        "signup_date": pd.date_range("2024-01-01", periods=100)\n    })\n\n    # Great Expectations DataFrame \uc0dd\uc131\n    ge_df = ge.from_pandas(df)\n\n    # Expectations \uc815\uc758\n    expectations = [\n        ge_df.expect_column_to_exist("customer_id"),\n        ge_df.expect_column_values_to_be_unique("customer_id"),\n        ge_df.expect_column_values_to_not_be_null("email"),\n        ge_df.expect_column_values_to_match_regex(\n            "email",\n            r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$"\n        ),\n        ge_df.expect_column_values_to_be_between("age", min_value=18, max_value=120),\n        ge_df.expect_column_values_to_be_of_type("signup_date", "datetime64"),\n    ]\n\n    # \uac80\uc99d \uacb0\uacfc \ud655\uc778\n    all_passed = all(exp.success for exp in expectations)\n\n    if not all_passed:\n        failed = [exp for exp in expectations if not exp.success]\n        context.log.warning(f"{len(failed)} expectations failed")\n        for exp in failed:\n            context.log.warning(f"Failed: {exp.expectation_config.expectation_type}")\n\n    return Output(\n        df,\n        metadata={\n            "total_expectations": len(expectations),\n            "passed_expectations": sum(1 for e in expectations if e.success),\n            "success_rate": sum(1 for e in expectations if e.success) / len(expectations) * 100\n        }\n    )\n'})}),"\n",(0,a.jsx)(e.h2,{id:"96-\uc131\ub2a5-\ubaa8\ub2c8\ud130\ub9c1",children:"9.6 \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,a.jsx)(e.h3,{id:"961-\uc131\ub2a5-\ud504\ub85c\ud30c\uc77c\ub9c1",children:"9.6.1 \uc131\ub2a5 \ud504\ub85c\ud30c\uc77c\ub9c1"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# performance/profiling.py\n"""\n\uc131\ub2a5 \ud504\ub85c\ud30c\uc77c\ub9c1\n"""\nfrom dagster import asset, AssetExecutionContext, Output, MetadataValue\nimport pandas as pd\nimport time\nfrom functools import wraps\nfrom typing import Callable, Any\nimport psutil\nimport os\n\nclass PerformanceProfiler:\n    """\uc131\ub2a5 \ud504\ub85c\ud30c\uc77c\ub7ec"""\n\n    @staticmethod\n    def profile_execution(func: Callable) -> Callable:\n        """\uc2e4\ud589 \uc2dc\uac04 \ubc0f \ub9ac\uc18c\uc2a4 \uc0ac\uc6a9\ub7c9 \ud504\ub85c\ud30c\uc77c\ub9c1"""\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            # \uc2dc\uc791 \uba54\ud2b8\ub9ad\n            start_time = time.time()\n            process = psutil.Process(os.getpid())\n            start_memory = process.memory_info().rss / 1024 / 1024  # MB\n            start_cpu = process.cpu_percent()\n\n            # \ud568\uc218 \uc2e4\ud589\n            result = func(*args, **kwargs)\n\n            # \uc885\ub8cc \uba54\ud2b8\ub9ad\n            end_time = time.time()\n            end_memory = process.memory_info().rss / 1024 / 1024  # MB\n            end_cpu = process.cpu_percent()\n\n            # \ud504\ub85c\ud30c\uc77c \uc815\ubcf4\n            profile = {\n                "duration_seconds": end_time - start_time,\n                "memory_used_mb": end_memory - start_memory,\n                "peak_memory_mb": end_memory,\n                "cpu_percent": end_cpu,\n            }\n\n            # \uacb0\uacfc\uc5d0 \ud504\ub85c\ud30c\uc77c \uc815\ubcf4 \ucd94\uac00\n            if isinstance(result, Output):\n                result.metadata.update({\n                    "execution_time": MetadataValue.float(profile["duration_seconds"]),\n                    "memory_usage_mb": MetadataValue.float(profile["memory_used_mb"]),\n                    "cpu_percent": MetadataValue.float(profile["cpu_percent"])\n                })\n                return result\n            else:\n                return result, profile\n\n        return wrapper\n\n@asset\n@PerformanceProfiler.profile_execution\ndef performance_monitored_asset(\n    context: AssetExecutionContext\n) -> Output[pd.DataFrame]:\n    """\uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1\uc774 \uc801\uc6a9\ub41c Asset"""\n    context.log.info("Starting heavy computation...")\n\n    # \ubb34\uac70\uc6b4 \uc5f0\uc0b0 \uc2dc\ubbac\ub808\uc774\uc158\n    df = pd.DataFrame({\n        "id": range(100000),\n        "value": range(100000)\n    })\n\n    # \ubcf5\uc7a1\ud55c \ubcc0\ud658\n    df["squared"] = df["value"] ** 2\n    df["cubed"] = df["value"] ** 3\n\n    # \uc9d1\uacc4\n    result = df.groupby(df["id"] % 100).agg({\n        "value": ["sum", "mean", "std"],\n        "squared": "sum",\n        "cubed": "sum"\n    })\n\n    return Output(\n        result,\n        metadata={\n            "row_count": len(result),\n            "column_count": len(result.columns)\n        }\n    )\n'})}),"\n",(0,a.jsx)(e.h3,{id:"962-\ucffc\ub9ac-\uc131\ub2a5-\ubaa8\ub2c8\ud130\ub9c1",children:"9.6.2 \ucffc\ub9ac \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# performance/query_monitoring.py\n"""\n\ub370\uc774\ud130\ubca0\uc774\uc2a4 \ucffc\ub9ac \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1\n"""\nfrom dagster import ConfigurableResource, asset, AssetExecutionContext\nimport time\nfrom typing import Any, Dict\nimport pandas as pd\n\nclass MonitoredDatabase(ConfigurableResource):\n    """\ucffc\ub9ac \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1\uc774 \ud3ec\ud568\ub41c \ub370\uc774\ud130\ubca0\uc774\uc2a4"""\n    connection_string: str\n\n    def __init__(self, **kwargs):\n        super().__init__(**kwargs)\n        self.query_stats: Dict[str, list] = {\n            "query": [],\n            "duration": [],\n            "rows_returned": []\n        }\n\n    def execute_query(self, query: str) -> pd.DataFrame:\n        """\ucffc\ub9ac \uc2e4\ud589 \ubc0f \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1"""\n        start_time = time.time()\n\n        # \uc2e4\uc81c \ucffc\ub9ac \uc2e4\ud589 (\uc2dc\ubbac\ub808\uc774\uc158)\n        result = pd.DataFrame({"col1": range(100), "col2": range(100)})\n\n        duration = time.time() - start_time\n\n        # \ud1b5\uacc4 \uae30\ub85d\n        self.query_stats["query"].append(query[:50])  # \ucc98\uc74c 50\uc790\ub9cc\n        self.query_stats["duration"].append(duration)\n        self.query_stats["rows_returned"].append(len(result))\n\n        return result\n\n    def get_performance_report(self) -> Dict[str, Any]:\n        """\uc131\ub2a5 \ub9ac\ud3ec\ud2b8 \uc0dd\uc131"""\n        if not self.query_stats["query"]:\n            return {"message": "No queries executed"}\n\n        return {\n            "total_queries": len(self.query_stats["query"]),\n            "total_duration": sum(self.query_stats["duration"]),\n            "avg_duration": sum(self.query_stats["duration"]) / len(self.query_stats["duration"]),\n            "slowest_query": {\n                "query": self.query_stats["query"][\n                    self.query_stats["duration"].index(max(self.query_stats["duration"]))\n                ],\n                "duration": max(self.query_stats["duration"])\n            },\n            "total_rows": sum(self.query_stats["rows_returned"])\n        }\n\n@asset\ndef query_performance_example(\n    context: AssetExecutionContext,\n    db: MonitoredDatabase\n) -> pd.DataFrame:\n    """\ucffc\ub9ac \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1 \uc608\uc81c"""\n    # \uc5ec\ub7ec \ucffc\ub9ac \uc2e4\ud589\n    queries = [\n        "SELECT * FROM customers",\n        "SELECT * FROM orders WHERE date > \'2024-01-01\'",\n        "SELECT customer_id, SUM(amount) FROM orders GROUP BY customer_id"\n    ]\n\n    results = []\n    for query in queries:\n        result = db.execute_query(query)\n        results.append(result)\n\n    # \uc131\ub2a5 \ub9ac\ud3ec\ud2b8\n    report = db.get_performance_report()\n    context.log.info(f"Query performance: {report}")\n\n    return pd.concat(results, ignore_index=True)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"97-\uc2e4\uc2b5-\ud504\ub85c\uc81d\ud2b8",children:"9.7 \uc2e4\uc2b5 \ud504\ub85c\uc81d\ud2b8"}),"\n",(0,a.jsx)(e.h3,{id:"971-\uc885\ud569-\ubaa8\ub2c8\ud130\ub9c1-\ub300\uc2dc\ubcf4\ub4dc",children:"9.7.1 \uc885\ud569 \ubaa8\ub2c8\ud130\ub9c1 \ub300\uc2dc\ubcf4\ub4dc"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# monitoring/dashboard.py\n"""\n\uc885\ud569 \ubaa8\ub2c8\ud130\ub9c1 \ub300\uc2dc\ubcf4\ub4dc\n"""\nfrom dagster import (\n    asset,\n    AssetExecutionContext,\n    Definitions,\n    ScheduleDefinition,\n    sensor,\n    RunRequest,\n    SensorEvaluationContext\n)\nfrom datetime import datetime, timedelta\nimport pandas as pd\nfrom typing import Dict, Any, List\n\n@asset\ndef monitoring_metrics(context: AssetExecutionContext) -> Dict[str, Any]:\n    """\ubaa8\ub2c8\ud130\ub9c1 \uba54\ud2b8\ub9ad \uc218\uc9d1"""\n    from run_monitoring import RunMonitor\n\n    monitor = RunMonitor()\n\n    # \uc9c0\ub09c 24\uc2dc\uac04 \ud1b5\uacc4\n    success_rate = monitor.get_success_rate(hours=24)\n    recent_runs = monitor.get_recent_runs(hours=24)\n    failed_runs = monitor.get_failed_runs(hours=24)\n\n    metrics = {\n        "timestamp": datetime.now().isoformat(),\n        "success_rate": success_rate,\n        "recent_runs_count": len(recent_runs),\n        "failed_runs_count": len(failed_runs),\n        "avg_duration": (\n            sum(r["duration_seconds"] for r in recent_runs if r["duration_seconds"])\n            / len(recent_runs) if recent_runs else 0\n        )\n    }\n\n    context.log.info(f"Monitoring metrics: {metrics}")\n\n    return metrics\n\n@asset\ndef data_quality_report(context: AssetExecutionContext) -> pd.DataFrame:\n    """\ub370\uc774\ud130 \ud488\uc9c8 \ub9ac\ud3ec\ud2b8"""\n    # \ubaa8\ub4e0 Asset\uc758 \ud488\uc9c8 \uba54\ud2b8\ub9ad \uc218\uc9d1\n    quality_data = []\n\n    # \uc608\uc2dc \ub370\uc774\ud130\n    assets = ["customers", "orders", "products"]\n    for asset_name in assets:\n        quality_data.append({\n            "asset": asset_name,\n            "completeness": 95.0 + (hash(asset_name) % 5),\n            "uniqueness": 98.0 + (hash(asset_name) % 2),\n            "validity": 90.0 + (hash(asset_name) % 10),\n            "timestamp": datetime.now()\n        })\n\n    df = pd.DataFrame(quality_data)\n\n    context.log.info(f"Quality report generated for {len(df)} assets")\n\n    return df\n\n@asset\ndef performance_report(context: AssetExecutionContext) -> pd.DataFrame:\n    """\uc131\ub2a5 \ub9ac\ud3ec\ud2b8"""\n    from run_monitoring import RunMonitor\n\n    monitor = RunMonitor()\n\n    # Job\ubcc4 \ud3c9\uade0 \uc2e4\ud589 \uc2dc\uac04\n    jobs = ["daily_etl", "hourly_sync", "weekly_report"]\n    performance_data = []\n\n    for job in jobs:\n        avg_duration = monitor.get_average_duration(job, days=7)\n        performance_data.append({\n            "job": job,\n            "avg_duration_seconds": avg_duration,\n            "avg_duration_minutes": avg_duration / 60,\n            "timestamp": datetime.now()\n        })\n\n    df = pd.DataFrame(performance_data)\n\n    context.log.info(f"Performance report generated for {len(df)} jobs")\n\n    return df\n\n# \ub9e4\uc2dc\uac04 \ubaa8\ub2c8\ud130\ub9c1 \uba54\ud2b8\ub9ad \uc218\uc9d1\nmonitoring_schedule = ScheduleDefinition(\n    name="hourly_monitoring",\n    cron_schedule="0 * * * *",  # \ub9e4\uc2dc\uac04\n    job_name="collect_monitoring_metrics"\n)\n\n# \ub370\uc774\ud130 \ud488\uc9c8 \uc774\uc0c1 \uac10\uc9c0 \uc13c\uc11c\n@sensor(\n    name="quality_anomaly_detector",\n    minimum_interval_seconds=300  # 5\ubd84\ub9c8\ub2e4\n)\ndef quality_anomaly_sensor(context: SensorEvaluationContext):\n    """\ub370\uc774\ud130 \ud488\uc9c8 \uc774\uc0c1 \uac10\uc9c0"""\n    # \ucd5c\uadfc \ud488\uc9c8 \uba54\ud2b8\ub9ad \uc870\ud68c\n    # (\uc2e4\uc81c\ub85c\ub294 DagsterInstance\uc5d0\uc11c \uc870\ud68c)\n\n    # \uc784\uacc4\uac12 \uccb4\ud06c\n    threshold_completeness = 90.0\n    threshold_validity = 85.0\n\n    # \uc774\uc0c1 \uac10\uc9c0 \uc2dc \uc54c\ub9bc\n    should_alert = False  # \uc2e4\uc81c \ub85c\uc9c1 \uad6c\ud604\n\n    if should_alert:\n        yield RunRequest(\n            run_key=f"quality_alert_{datetime.now().isoformat()}",\n            tags={\n                "alert_type": "quality_anomaly",\n                "severity": "warning"\n            }\n        )\n'})}),"\n",(0,a.jsx)(e.h3,{id:"972-\ubaa8\ub2c8\ud130\ub9c1-\uc124\uc815-\ubaa8\ubc94-\uc0ac\ub840",children:"9.7.2 \ubaa8\ub2c8\ud130\ub9c1 \uc124\uc815 \ubaa8\ubc94 \uc0ac\ub840"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'# monitoring/best_practices.py\n"""\n\ubaa8\ub2c8\ud130\ub9c1 \uc124\uc815 \ubaa8\ubc94 \uc0ac\ub840\n"""\n\nMONITORING_BEST_PRACTICES = """\n# Dagster \ubaa8\ub2c8\ud130\ub9c1 \ubaa8\ubc94 \uc0ac\ub840\n\n## 1. \uba54\ud2b8\ub9ad \uc218\uc9d1\n- \ubaa8\ub4e0 Asset\uc5d0 \uba54\ud0c0\ub370\uc774\ud130 \ucd94\uac00\n- \uc2e4\ud589 \uc2dc\uac04, \ud589 \uc218, \uba54\ubaa8\ub9ac \uc0ac\uc6a9\ub7c9 \uae30\ub85d\n- \ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc815\uc758\n\n## 2. \ub85c\uae45\n- \uad6c\uc870\ud654\ub41c \ub85c\uae45 \uc0ac\uc6a9 (JSON)\n- \uc801\uc808\ud55c \ub85c\uadf8 \ub808\ubca8 \uc124\uc815\n- \ubbfc\uac10\ud55c \uc815\ubcf4 \ub9c8\uc2a4\ud0b9\n\n## 3. \uc54c\ub9bc\n- \uc2e4\ud328 \uc2dc \uc989\uc2dc \uc54c\ub9bc (Slack, Email)\n- \uc911\uc694\ud55c Job\uc740 PagerDuty \uc5f0\ub3d9\n- \uc54c\ub9bc \ud53c\ub85c\ub3c4 \ubc29\uc9c0 (\uc911\ubcf5 \uc54c\ub9bc \uc81c\uac70)\n\n## 4. \ub370\uc774\ud130 \ud488\uc9c8\n- \ubaa8\ub4e0 \ud575\uc2ec Asset\uc5d0 \ud488\uc9c8 \uccb4\ud06c \ucd94\uac00\n- Great Expectations \ud1b5\ud569\n- \ud488\uc9c8 \uba54\ud2b8\ub9ad \ub300\uc2dc\ubcf4\ub4dc\n\n## 5. \uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1\n- \ub290\ub9b0 Asset \uc2dd\ubcc4\n- \ucffc\ub9ac \ucd5c\uc801\ud654\n- \ub9ac\uc18c\uc2a4 \uc0ac\uc6a9\ub7c9 \ucd94\uc801\n\n## 6. \ub300\uc2dc\ubcf4\ub4dc\n- Dagit UI \ud65c\uc6a9\n- Grafana/Prometheus \uc5f0\ub3d9\n- \ube44\uc988\ub2c8\uc2a4 \uba54\ud2b8\ub9ad \uc2dc\uac01\ud654\n\n## 7. \uc54c\ub9bc \uc784\uacc4\uac12 \uc124\uc815\n- \uc2e4\ud328\uc728 > 5%: \uacbd\uace0\n- \uc2e4\ud589 \uc2dc\uac04 > \ud3c9\uade0\uc758 2\ubc30: \uacbd\uace0\n- \ub370\uc774\ud130 \ud488\uc9c8 < 90%: \uacbd\uace0\n- \uc2e0\uc120\ub3c4 > 24\uc2dc\uac04: \uc5d0\ub7ec\n\n## 8. \uc815\uae30 \ub9ac\ubdf0\n- \uc8fc\uac04 \uc131\ub2a5 \ub9ac\ubdf0\n- \uc6d4\uac04 \ub370\uc774\ud130 \ud488\uc9c8 \ubcf4\uace0\n- \ubd84\uae30\ubcc4 \uc2dc\uc2a4\ud15c \ucd5c\uc801\ud654\n"""\n\nprint(MONITORING_BEST_PRACTICES)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"98-\uc694\uc57d",children:"9.8 \uc694\uc57d"}),"\n",(0,a.jsx)(e.p,{children:"\uc774 \uc7a5\uc5d0\uc11c\ub294 Dagster \ud30c\uc774\ud504\ub77c\uc778\uc758 \ubaa8\ub2c8\ud130\ub9c1 \ubc29\ubc95\uc744 \ud559\uc2b5\ud588\uc2b5\ub2c8\ub2e4:"}),"\n",(0,a.jsx)(e.h3,{id:"\ud575\uc2ec-\uac1c\ub150",children:"\ud575\uc2ec \uac1c\ub150"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"Dagit UI"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Asset Catalog\ub85c \uc804\uccb4 \ud604\ud669 \ud30c\uc545"}),"\n",(0,a.jsx)(e.li,{children:"Run \ud788\uc2a4\ud1a0\ub9ac \ubc0f \ub85c\uadf8 \uc870\ud68c"}),"\n",(0,a.jsx)(e.li,{children:"\uc2e4\uc2dc\uac04 \ubaa8\ub2c8\ud130\ub9c1"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"\ub85c\uae45"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"\uad6c\uc870\ud654\ub41c \ub85c\uae45"}),"\n",(0,a.jsx)(e.li,{children:"\ub85c\uadf8 \ub808\ubca8 \uad00\ub9ac"}),"\n",(0,a.jsx)(e.li,{children:"\ub85c\uadf8 \ubd84\uc11d \ubc0f \uc9d1\uacc4"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"\uba54\ud2b8\ub9ad"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Prometheus \ud1b5\ud569"}),"\n",(0,a.jsx)(e.li,{children:"\ucee4\uc2a4\ud140 \uba54\ud2b8\ub9ad \uc815\uc758"}),"\n",(0,a.jsx)(e.li,{children:"\ub370\uc774\ud130 \ud488\uc9c8 \uba54\ud2b8\ub9ad"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"\uc54c\ub9bc"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Slack \ud1b5\ud569"}),"\n",(0,a.jsx)(e.li,{children:"Email \uc54c\ub9bc"}),"\n",(0,a.jsx)(e.li,{children:"PagerDuty \uc5f0\ub3d9"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"\ub370\uc774\ud130 \ud488\uc9c8"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"\uc790\ub3d9 \ud488\uc9c8 \uccb4\ud06c"}),"\n",(0,a.jsx)(e.li,{children:"Great Expectations"}),"\n",(0,a.jsx)(e.li,{children:"\ud488\uc9c8 \uc784\uacc4\uac12 \uc124\uc815"}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsx)(e.p,{children:(0,a.jsx)(e.strong,{children:"\uc131\ub2a5 \ubaa8\ub2c8\ud130\ub9c1"})}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"\uc2e4\ud589 \uc2dc\uac04 \ucd94\uc801"}),"\n",(0,a.jsx)(e.li,{children:"\ub9ac\uc18c\uc2a4 \uc0ac\uc6a9\ub7c9 \ubaa8\ub2c8\ud130\ub9c1"}),"\n",(0,a.jsx)(e.li,{children:"\ucffc\ub9ac \uc131\ub2a5 \ubd84\uc11d"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\ud3ec\uad04\uc801 \ubaa8\ub2c8\ud130\ub9c1"}),": Asset, Job, \uc2dc\uc2a4\ud15c \ub808\ubca8 \ubaa8\ub450 \ubaa8\ub2c8\ud130\ub9c1"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\uc801\uc808\ud55c \uc54c\ub9bc"}),": \uc911\uc694\ud55c \uc774\ubca4\ud2b8\ub9cc \uc54c\ub9bc, \uc54c\ub9bc \ud53c\ub85c\ub3c4 \ubc29\uc9c0"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\ub370\uc774\ud130 \ud488\uc9c8 \uc6b0\uc120"}),": \ubaa8\ub4e0 \ud575\uc2ec Asset\uc5d0 \ud488\uc9c8 \uccb4\ud06c"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\uc131\ub2a5 \ucd94\uc801"}),": \uc815\uae30\uc801\uc778 \uc131\ub2a5 \ub9ac\ubdf0 \ubc0f \ucd5c\uc801\ud654"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"\ubb38\uc11c\ud654"}),": \uc54c\ub9bc \ub300\uc751 \uc808\ucc28 \ubb38\uc11c\ud654"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"\ub2e4\uc74c-\ub2e8\uacc4",children:"\ub2e4\uc74c \ub2e8\uacc4"}),"\n",(0,a.jsx)(e.p,{children:"\ubaa8\ub2c8\ud130\ub9c1 \ubc29\ubc95\uc744 \uc775\ud614\uc73c\ub2c8, \ub2e4\uc74c \uc7a5\uc5d0\uc11c\ub294 Dagster\uc640 \ub2e4\ub978 \uc2dc\uc2a4\ud15c(dbt, Airbyte, AWS, GCP \ub4f1)\uc744 \ud1b5\ud569\ud558\ub294 \ubc29\ubc95\uc744 \ud559\uc2b5\ud569\ub2c8\ub2e4."})]})}function c(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{R:()=>o,x:()=>i});var s=t(6540);const a={},r=s.createContext(a);function o(n){const e=s.useContext(r);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function i(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),s.createElement(r.Provider,{value:e},n.children)}}}]);